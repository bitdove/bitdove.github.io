[{"content":"Preface Any language has three main components: vocabulary, pronunciation, and grammar. In this article, we focus on the grammar of English.\n英语的核心是动词。\n简单句 长句子由简单句组合而来，拆的不能再拆的句子称为简单句。简单句表达的是“什么+怎么样”。而“什么”和“怎么样”分别对应主语和谓语这两种句子成分。即简单句=主语+谓语。主语是人或物，而谓语是广义的动作。\n动作（动词）分类：\n不及物动词：可以独立完成的动作； 单及物动词：有1个动作承受者； 双及物动词：有2个动作承受者； 复杂及物动词：只有1个动作承受者（但需补充）； 系动词：非“动作”，仅赋予主语某种性质或状态。 动词类型 解释 代表结构 例词 例句 解释 不及物动词 可以独立完成的动作 主语+不及物动词 sleep Mason sleeps. / 单及物动词 有1个动作承受者 主语+单及物动词+宾语 like Mason likes you. you为宾语 双及物动词 有2个动作承受者 主语+双及物动词+间接宾语+直接宾语 teach Mason teaches you English. you为间接宾语，English为直接宾语 复杂及物动词 只有1个动作承受者（但需补充说明） 主语+复杂及物动词+宾语+宾语补语 consider Mason considers you smart. you为宾语，smart为宾语补语 系动词 非“动作”，赋予主语某种性质 主语+系动词+主语补语/表语 am/is/are, look Mason is handsome. handsome为表语 谓语 ≠ 谓语动词 句子除去主语，剩下的部分都是谓语，谓语动词只是谓语的一部分。\n句子成分 主语 谓语动词 宾语 宾语补语 主语补语/表语 定语 状语 同位语\n复合句和复杂句 简单句互相组合可成为复合句 Compound Sentence和复杂句 Complex Sentence。 复合句是并列关系。复杂句是主从关系。\n复杂句中的从句就是把简单句修改一下作为主句的句子成分。\n名词性从句： 主语从句 宾语从句 表语从句 同位语从句 定语从句 状语从句 词性（十大词类） 动词 名词 冠词 代词 形容词 数词 副词 介词 叹词 连词\n除了谓语动词是动词，其他句子成分都有可能包含不同的词类。\nVerb Tenses 谓语动词有三大本领：\n表示动作时间 表示动作状态 表示动词语气，如动作的假设、情感等。 1和2合称时态（Verb Tenses）。\n助动词：没有实义，仅帮助谓语动词完成各种本领。如时态、虚拟语气、可能性、否定等等。\n常见助动词：have, be, can, might, must, do。\n注意，助动词也有作实义词的时候，比如have可以是“拥有”，can可以是“易拉罐”。\nSimple 一般 Continuous 进行 Perfect 完成 Perfect continuous 完成进行 Past 过去 did was/were doing had done had been doing Present 现在 do/does am/is/are doing have/has done have/has been doing Future 将来 will do will be doing will have done will have been doing Past future 过去将来 would do would be doing would have done would have been doing Tips：The past future tense is not a standalone tense but rather a way to express future events relative to a point in the past.\n非谓语动词 动词除了做谓语动词外，可以不同的形式作为其他句子成分（如主语、宾语、宾语补语、定语等等），这时候动词叫做非谓语动词。\n有以下形式：\n动词不定式 现在分词 动名词 过去分词 ","date":"2025-09-12T14:03:10+08:00","permalink":"https://bitdove.github.io/posts/wipenglish-learningthe-system-of-english-grammar/","title":"【WIP】【English Learning】The System of English Grammar"},{"content":"引言 上个月家人做了甲状腺手术，在陪诊的过程中了解到了很多甲状腺以及甲状腺疾病相关的知识。于是我想把这些知识整理下来，既是记录，也是分享。\n认识甲状腺 甲状腺\n我们的诊疗过程 体检初见端倪 2022年体检报告2-3类结节，没做处理； 2025年体检报告4a，体检机构提示建议去医院诊治,引起了我们的重视，去了医院诊治。\n彩超与甲功检查 甲状腺结节通常通过彩超发现，超声医生会根据超声表现（比如是否边缘清晰、有没有钙化）来评估风险，如果有结节的话，给出结节的TI-RADS分级标准。所以，超声医生的水平真的很关键。因为超声不仅要看‘有没有结节’，更要判断结节的性质、风险和等级。\n基于上述原因，我们找了知名的超声科专家做了彩超，最终左侧4b，右侧4a。\n另外，门诊医生还让我们抽血查甲功。这个主要看甲状腺功能是否正常，我们查出来是正常的。\n穿刺 病理科医生很关键。\n手术 根据切口位置，手术可以分为传统手术和腔镜手术两大类。\n传统手术：又称开放式手术。切口在脖子上，术后会一个4-5cm的疤痕，不太美观； 腔镜手术：切口位置比较隐蔽，术后的疤痕衣物可以遮挡住，相对美观。有乳晕、腋下、口腔、锁骨四种。 根据切除方案，手术可分为全切和半切两种。\n全切：顾名思义，将两侧甲状腺全部切除。 半切：仅切除一侧甲状腺（即有结节的那侧）。 术前谈话 术后 优甲乐\n","date":"2025-09-05T12:59:00+08:00","permalink":"https://bitdove.github.io/posts/wip%E5%81%A5%E5%BA%B7%E4%B8%80%E5%9C%BA%E6%89%8B%E6%9C%AF%E8%AE%A9%E6%88%91%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86%E7%94%B2%E7%8A%B6%E8%85%BA/","title":"【WIP】【健康】一场手术让我重新认识甲状腺"},{"content":"2025年09月日历 一 二 三 四 五 六 日 1 2× 3 4 5× 6 7 8 9× 10× 11× 12 13 14 15× 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 2025/09/01 今天是出院时间，早上6点多就起来了。8点多医生过来拔引流管。因为要等药房把药送到住院部，等到11点才办出院手续。\n回到家，收拾了一番，给G洗了头发，出门买了些水果、红薯。在家看《万物生》。\n10点睡觉。\n2025/09/02 为期一周的陪护生活结束了，今天恢复上班了。\n硬件身份认证 今天下午3点多，跟沈老师讨论了下树莓派硬件身份识别的工作。通过沟通，我感觉现在从0开始做也可以，他并不了解。现在让我写一个实验方案，把硬件、软件等信息列出来，还有采集的参数等等。\n2025/09/03 游戏 住院的时候为了打发时间，在手机上下载了英雄联盟手游。\n2025/09/04 今天打了8小时英雄联盟手游。\n已提交注销账号申请。15天冷静期，2025年9月20日0:00完成注销。希望坚持住。 2025/09/08更新，2025年9月22日0:00完成注销。\n2025/09/05 米10五周岁 今天是目前在使用的小米10作为主力机服役满5周年的日子。\n2025/09/06 - 2025/09/07 周五G去衢州出差，我下班回家，一个人在家，又把英雄联盟手游下回来玩了一晚上，玩到凌晨，周六白天补觉，顺便看了《仙逆剧场版神临之战》，晚上G就回来了。\n周日和G一起看完了《生万物》，不得不说这剧槽点太多了。\n2025/09/08 研究生开学典礼 昨晚上接到一项工作，学院要面向新入学的研究生做一个PPT，我们这边负责两点：\n目前有哪些顶级的计算机公司， 既要有AI公司，也有芯片公司，还要有像Planner这种应用的公司，包括脑机这些内容，有一个产业的大爆发。 引用一些牛人，关于当前技术浪潮的看法，比如彼得·蒂尔这些人，包括硅谷的大佬。 不需要太细，主要是新、视野广，相关的人和团队业内顶尖，每点5页左右。你帮我先查一下大概的，比如问问ai，查一下知名媒体评出的年度xx，美股市值最大的公司，之类的相关内容，支撑说明科技的爆点。\n2025/09/09 自己做饭 今天起来晚了些，醒来时Grace已经去出差了。起来做了饭热干面做午饭。打了个荷包蛋，但是失败了。蒸了一个红薯，煮了三个白水蛋，洗了点儿阳光玫瑰，装在饭盒里，带到公司作晚饭。\n下班 今天在公司待到了10点多才下班，其实白天纯玩了，到了晚上才开始改开学典礼的PPT。\n2025/09/10 今天9点到公司，主要是为了改PPT，中午之前要发过去。还有以下几点要改：\n名人大咖的观点再填充一些，现在有些少； 名人大咖观点后做一个总结，说说当前的技术趋势； 第一部分的产业大爆发要重新组织一下逻辑。 把Bitwarden极简掉 今天下午突然萌生出把Bitwarden极简掉的想法。其实，Bitwarden是一个很好用的密码管理器，它全平台通用，且在主流浏览器上均有可用的扩展，免费版本已足够使用，我其实想不出它的任何缺点。那我为什么要极简掉它呢？因为不用它，就又少了一个软件。但是问题是：\nBitwarden可以保存部分Passkey，如GitHub、Google、Microsoft，这些passkey保存在Bitwarden，随云端同步，在跨设备登录时非常方便； Bitwarden上还保存了一些SSH Key，比如实验室服务器的私钥、VPS登录的私钥等； 我觉得都可以克服。开搞。直接把这些账号密码存在chrome好了。\nChrome肯定是不如Bitwarden安全，甚至也不那么方便。但是我不想多维护一套密码管理系统了。\n2025/09/11 今天10天出头到公司，改了几页PPT。\n昨天把Bitwarden极简掉了，密码管理采用Google Password Manager。现在存在几个问题。\nGoogle账号的Passkey无法迁移（总不能把google的登陆密码保存在google吧）； 部分SSH密钥Google Password Manager无法保存； 有些国产APP的账号密码Google Password Manager无法保存。 针对上述问题，解决方案如下：\nGoogle账号的Passkey就存一份在Bitwarden好了，以备使用； SSH密钥无非就两个，一个是学校实验室服务器的私钥，一个是VPS登录的私钥，也存在Bitwarden吧； 国产APP越来越依赖手机号验证码以及人脸，密码的作用愈来愈弱，可以考虑密码统一化。 隐私摆烂了，国产APP的密码直接存在微信收藏了。\n弃用GPG GnuPG是不错的加密选择，但是我还是决定弃用了，因为使用场景太少了。现在唯一的用处就是GitHub提交签名，但是也没必要。所以，我决定弃用。\n2025/09/12 今天Grace出差结束，下午要去高铁站接她。3点半离开公司。\nYT Music Revanced Is Dead! 今天早上发现，YouTube Music Revanced用不了了，上网看了下，I\u0026rsquo;m not alone. 应该是Google又出了什么花样要搞我们这帮白嫖怪。The only way is waiting for a new Revanced Patch to fix it.\nActually, there is another option. Metrolist, an open-source and third-party YouTube Music client for Android. But Metrolist can\u0026rsquo;t access songs that you have uploaded to YT Music. In order to listen to English Podcasts that were uploaded to my YT Music, I found Musicolet, an offline music player for Android without ads. I saved the podcast files on my phone, and played them with Musicolet. This is my solution for now.\n2025/09/13 - 2025/09/14 周末两天自己做饭 + 看《扫毒风暴》，还去丰收湖逛了一圈。\n2025/09/15 12点到公司。\n","date":"2025-09-02T09:28:48+08:00","permalink":"https://bitdove.github.io/posts/%E6%97%A5%E8%AE%B02025%E5%B9%B49%E6%9C%88/","title":"【日记】2025年9月"},{"content":" 免责声明： 本文所述内容仅供技术学习和研究使用，不构成任何形式的非法行为指导。请读者严格遵守所在地区的法律法规，自行判断和承担使用相关技术可能带来的风险。作者不对因使用本文内容而产生的任何法律责任承担责任。\n前言 这是一台即将到期的RackNerd的VPS，我已不打算续费。在它生命即将走到尽头之际，我打算用它重新配置一遍Xray-core，并作此记录，以留后用。\n系统选择 仅用作代理的VPS，系统求稳定即可。所以我选择安装了Debian 10 64 Bit。\n换源与更新系统 执行apt update时会遇到错误，这是因为Debian 10（Buster）已经停止官方支持，APT 源被移到 archive.debian.org，所以用原来的地址会 404。要解决这个问题，需要手动改APT源到归档源，然后才能继续更新和安装。\n修改 APT 源 先备份原来的源：\n1 cp /etc/apt/sources.list /etc/apt/sources.list.bak 然后编辑：\n1 nano /etc/apt/sources.list 替换成下面的内容（适用于 Debian 10 Buster）：\n1 2 3 4 5 6 7 8 deb http://archive.debian.org/debian buster main contrib non-free deb-src http://archive.debian.org/debian buster main contrib non-free deb http://archive.debian.org/debian-security buster/updates main contrib non-free deb-src http://archive.debian.org/debian-security buster/updates main contrib non-free deb http://archive.debian.org/debian buster-updates main contrib non-free deb-src http://archive.debian.org/debian buster-updates main contrib non-free 允许使用过期的源\n1 echo \u0026#39;Acquire::Check-Valid-Until \u0026#34;false\u0026#34;;\u0026#39; \u0026gt; /etc/apt/apt.conf.d/99ignore-release-date 更新系统\n1 apt update \u0026amp;\u0026amp; apt upgrade -y 这样就能正常安装后续需要的工具了。\n本部分由ChatGPT生成，经本人验证，可以解决问题。\n配置VPS 这里参考之前写过的文章【Proxy】How to Build Proxy with XRay，此处不再赘述。\n安装Xray-core Xray官方提供了一键安装脚本。\n执行以下命令安装Xray-core\n1 sudo bash -c \u0026#34;$(curl -L https://github.com/XTLS/Xray-install/raw/main/install-release.sh)\u0026#34; @ install 脚本依赖curl。若提示bash: curl: command not found，则执行以下命令安装curl: 1 sudo apt install curl 脚本需要以root身份执行，所以前边要加sudo。 安装完成后，运行xray version，返回如下图所示的版本信息，代表安装成功。\n配置Xray-core 以下以VLESS-TCP-XTLS-Vision-REALITY为例。Xray官方也给出了各种配置示例，详情可以参考GitHub Xray-examples。\n生成uuid 生成一个uuid备用。\n1 xray uuid 本文使用以上图生成的6b22b0d8-4bcb-4c95-b8d8-1a3488d0f460。\nuuid相当于一个令牌(Token)，不要轻易示人，客户端需要配置此id才可使用此梯子。\n生成x25519公私钥 1 xray x25519 本文使用上图生成的公私钥：\nPrivate key: YPus0-HqMBiQpiJ02hpnmJSodGRIhxG-tGlRjKoAV18 Public key: CLQaGhx37ZpcLbNhl5JXRay-5hJwbg7wYQtIDS5R9mc 私钥会写在Xray服务端的配置文件中，而公钥是需要使用此梯子的客户端需要配置的内容。\n生成shortIds shortIds是一个客户端可用的shortId列表，服务端可用此来区分不同的客户端。自己造就好了。规则如下：\n范围是0至f; 长度是2的倍数； 最大长度为16。 本文使用7df26a3cb5。\n客户端需要填上shortIds中的其中之一才可使用该梯子。\n修改Xray配置文件 执行以下命令修改Xray配置文件：\n1 sudo nano /usr/local/etc/xray/config.json 根据VPS的IP地址以及前述步骤生成的各种id、密钥等，本文使用以下配置文件（未使用warp解锁chatGPT客户端）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 { \u0026#34;log\u0026#34;: { \u0026#34;loglevel\u0026#34;: \u0026#34;debug\u0026#34; }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;port\u0026#34;: 443, \u0026#34;protocol\u0026#34;: \u0026#34;vless\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;clients\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;6b22b0d8-4bcb-4c95-b8d8-1a3488d0f460\u0026#34;, // run `xray uuid` to generate \u0026#34;flow\u0026#34;: \u0026#34;xtls-rprx-vision\u0026#34; } ], \u0026#34;decryption\u0026#34;: \u0026#34;none\u0026#34; }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;security\u0026#34;: \u0026#34;reality\u0026#34;, \u0026#34;realitySettings\u0026#34;: { \u0026#34;dest\u0026#34;: \u0026#34;lapl.org:443\u0026#34;, // A website that support TLS1.3 and h2. You can also use `1.1.1.1:443` as dest \u0026#34;serverNames\u0026#34;: [ \u0026#34;lapl.org\u0026#34; // A server name in the cert of dest site. If you use `1.1.1.1:443` as dest, then you can leave `serverNames` empty, it is a possible ways to bypass Iran\u0026#39;s internet speed restrictions. ], \u0026#34;privateKey\u0026#34;: \u0026#34;YPus0-HqMBiQpiJ02hpnmJSodGRIhxG-tGlRjKoAV18\u0026#34;, // run `xray x25519` to generate. Public and private keys need to be corresponding. \u0026#34;shortIds\u0026#34;: [ // Required, list of shortIds available to clients, can be used to distinguish different clients \u0026#34;7df26a3cb5\u0026#34; // If this item exists, client shortId can be empty. 0 to f, length is a multiple of 2, maximum length is 16 ] } }, \u0026#34;sniffing\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;destOverride\u0026#34;: [ \u0026#34;http\u0026#34;, \u0026#34;tls\u0026#34;, \u0026#34;quic\u0026#34; ], \u0026#34;routeOnly\u0026#34;: true } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;tag\u0026#34;: \u0026#34;direct\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34; // Main Outgoing Protocol }, { \u0026#34;tag\u0026#34;: \u0026#34;block\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;blackhole\u0026#34; } ] } 针对VLESS-TCP-XTLS-Vision-REALITY方案,以上配置文件需要注意以下内容：\nid：之前通过xray uuid生成的内容； dest：填一个地址，这就是所谓“reality偷域名”中偷的那个域名，后边加上443端口。上述以洛杉矶图书馆的域名(lapl.org)为例子，填lapl.org:443； serverNames：填“偷”的域名，如lapl.org； privateKey：之前通过xray x25519生成的私钥（PrivateKey）； shortIds：之前编的shortIds，如7df26a3cb5; IP地址：IPv4地址填VPS的公网IPv4地址，IPv6地址填Warp虚拟出的IPv6地址。 关于偷域名有一些讲究，最好是偷自己，其次是偷与VPS IP地址同段的网址或者VPS附近的大学、图书馆、政府网站等等。对被偷域名的要求是支持TLS1.3和H2。详情参考Xray官方解释和REALITY作者在GitHub的回复。 warp解锁ChatGPT客户端参考Warp解锁ChatGPT客户端。 运行Xray-core 以下为Xray-core进程常用管理命令。\n1 2 3 4 5 6 7 8 # Start Xray sudo systemctl start xray # Restart Xray sudo systemctl restart xray # Set XRay to start at boot sudo systemctl enable xray # Check Xray status sudo systemctl status xray 客户端配置 Android 安卓端目前比较好用的客户端是V2RayNG。\n以上述服务端配置为例，在V2RayNG中添加一个VLESS配置，内容如下图：\n需要注意：\nremarks：给该梯子起个名字； address：梯子的IPv4地址； port：Reality使用443端口； id：即服务端的id； flow：与服务端一致，xtls-rprx-vision； encryption：none； network：tcp； TLS：选reality； SNI：即偷的域名； PublicKey：即服务端xray x25519生成的公私钥中的公钥（PublicKey）。 ShortId：即服务端ShortIds中的一个。 Windows Windows目前比较好用的客户端为V2RayN。与安卓端的V2RayNG同作者。\n其实V2RayN是一个跨平台GUI客户端，支持Windows、Linux、macOS。\n以上述服务端配置为例，在V2RayN中添加一个VLESS配置，内容如下图：\n需要注意的内容同安卓端一样。\n别名：给该梯子起个名字； 地址：梯子的IPv4地址； 端口：Reality使用443端口； 用户ID：即服务端的id； 流控：与服务端一致，xtls-rprx-vision； 加密方式：none； 传输协议：tcp； 传输层安全：选reality； SNI：即偷的域名； PublicKey：即服务端xray x25519生成的公私钥中的公钥（PublicKey）。 ShortId：即服务端ShortIds中的一个。 macOS macOS端目前本人没有使用GUI客户端，而是直接命令行跑的Xray-core，详情可参考You Don\u0026rsquo;t Need a GUI Proxy Client。\nReference 【Proxy】How to Build Proxy with XRay Xray官方GitHub Xray官方安装教程 Xray官方配置示例 Xray官方解释 REALITY作者在GitHub的回复 V2RayNG官方GitHub V2RayN官方GitHub You Don\u0026rsquo;t Need a GUI Proxy Client ","date":"2025-08-13T11:13:26+08:00","permalink":"https://bitdove.github.io/posts/%E4%BB%A3%E7%90%86%E5%9C%A8%E4%B8%80%E5%8F%B0%E5%BA%9F%E5%BC%83vps%E4%B8%8A%E9%87%8D%E6%96%B0%E8%B5%B0%E4%B8%80%E9%81%8Dxray-core%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE%E6%B5%81%E7%A8%8B/","title":"【代理】在一台废弃VPS上重新走一遍Xray-core代理配置流程"},{"content":"2025年08月日历 一 二 三 四 五 六 日 1 2 3 4× 5 6× 7 8× 9 10 11× 12 13× 14 15 16 17 18× 19 20× 21 22× 23 24 25× 26 27 28 29× 30 31 2025/08/01 陪G看病 今天早上陪G去做了穿刺，穿刺结果大概下周三/四出来，已经约了下周六去看王医生的门诊。\n从医院回到家，煮了个面，吃完午休了一个小时。下午1点到公司。\n轮胎补气 摩托车和电动车的胎压可能不到额定值了，需要补补气。99元在京东买了一个便携充气泵\nNWG150用户手册规定的胎压值：\n单人乘骑：前轮200kPa，后轮225kPa； 双人乘骑：前轮200kPa，后轮250kPa。 2025/08/04更新： 充气泵到了，今天想着补一补，结果一试：前轮240kPa，后轮170kPa。 前轮不仅不用补，还得往外放点儿气； 最后，前轮调整至205kPa，后轮补到了235kPa。\n那辆小雅迪不清楚该把胎压打到多少，回家找说明书看看，没有的话就看情况打吧。\n前轮200kPa，后轮220kPa？ 1bar = 100kPa\n抛弃苹果 按我的想法，我会逐步抛弃苹果生态，即不再购买新的苹果设备。\nPC选择自己组装Windows台式机，登录Microsoft账号； 手机选择国产3000价位以下的安卓机型，登录Google账号； 平板把目前手头的iPad Air4用完后不再购买； 笔记本电脑目前有一台MacBook Pro 2020和一台RedmiBook Pro 15，用完后不再购买。 关于家庭PC，是在现有基础上做升级，还是直接重新组装一台新的，还有待考虑。目前家里这台台式机是2022年配的一台低配电脑。配置如下表：\n配件 品牌型号 备注 CPU i3-12100 神U，带核显 主板 铭瑄H610M 不带蓝牙和WiFi，仅支持DDR4内存 内存 酷兽8G * 2 DDR4 显卡 RX580 8G 闲鱼二手，疑似故障 硬盘 三星SATA + 三星M.2 可接受 电源 长城400W 功率偏低 散热 普普通通的小风扇 机箱 蓝宝石银角大王 较为满意 显示器 AOC I2490VXH 24英寸+1080P+60Hz 这套配置有几个问题：\n显示器有些差劲。屏幕尺寸是24英寸，分辨率是1080P，刷新率是60Hz。这个肯定是要换； 主板不带蓝牙和WiFi。主要影响是用不了蓝牙耳机，联网必需插网线。倒是也能将就用； 显卡太差劲。目前这块显卡是300块在闲鱼淘的二手，品质不太行； 电源功率低了。当时配的时候用的核显，不需要太高功率。现在看来确实低了。可以按电源功率=CPU+GPU+150的公式来估算； 内存是DDR4的。主板也仅支持DDR4； CPU倒是一颗入门神U，我觉得够用，不过升级下也可以； 硬盘是大学时期给笔记本加装的一块SATA固态，也很古老了。还有一块是一个M.2接口的固态； 散热就是普普通通的，几十块钱的小风扇； 机箱可能是唯一满意的地方。比较小巧，颜值也还可以。 鼠标键盘我倒是没要求，目前用的也是普通的游戏键盘、办公鼠标。 附上铭瑄H610M主板规格参数表： 这样盘点下来，我感觉没太有局部升级的必要了，可以考虑全部重新组一个。这个旧的可以拆开卖二手。\n2025/08/02 - 2025/08/03 周六上午醒来已是9:30，起床洗漱，出门去G公司旁边的一家店吃早饭，结果11点前不营业，最后去吃了淮南牛肉汤。回家看了一两集日剧《请和我老公结婚吧》，去金沙印象城溜达了会儿，又回家做晚饭（排骨）。晚上去江边散步，回家看剧。\n周六上午醒来已是9:30，起床洗漱，出门去G公司旁边的一家店吃早饭，结果周日中午不营业，最后去吃了淮南牛肉汤。摩旅出发去良渚，逛了逛永旺梦乐城，看了之前煎饼的办公楼，回家已是5点。点外卖，看剧，江边散步，看剧至深夜十一点多才睡觉。\n2025/08/04 仙逆第100集——化蝶 红蝶是朱雀星的天才修士，百年化神，天资惊人，拥有先天五行之灵，是名扬朱雀的天之娇女。在这一集中，被王林斩杀。\n百年化神，却止步于化神，被乾风炼成炉鼎，失去神智。如此过活为红蝶所不齿，求王林杀了自己。\n据说红蝶会有转世，希望她在新的一世有个圆满的结局。\n在破与不破之间 今天有些躁动，欲念来得很凶，我能感觉到大脑的某一部分很挣扎，试图夺取身体的控制权。它想操纵这副身体，让我升起邪淫的念头，让我去帮它寻找那些感官刺激。它像一个有毒瘾而不得的人，疯狂地指引我去帮它拿到这一剂“毒品”。\n可我是个人，区别于高级动物。我不会完全顺从身体的本能和冲动，我可以用信念和为人的良知压制这股冲动。我此刻在这里敲下自己的感受，观察自己的欲望，等待它熄灭。\n发愿不看不听不想任何跟邪淫有关的内容！南无地藏王菩萨\n最终还是破了。这些表面手段看来还是不够。\n升一类卡 下午去中国银行把二类账户升级为一类账户，意外的顺利。本以为会很麻烦的。工作人员先是要求用手机银行给任意账户转账1元，然后要了手机号，接着就去智能柜台，扫了个人脸，很轻松就办好了，全程也就三分钟。离开时工作人员特地告知手机银行上会有延迟，但实际已经是一类账户了。\n2025/08/05更新： 手机银行已经显示一类卡了。\n2025/08/05 公积金提取 早上上班之前看到杭州公积金中心下沙分中心是9点上班，就打算在上班之前去把公积金提取办了。\n由于浙里办上查不到异地登记的婚姻信息，所以需要线下办理。\n钱塘政务服务中心6楼，取号等待。先提了一部分，又办理了还贷按月转账。\n回家放下身份证等资料后，10点出头来到公司。\n2025/08/06 奇迹并没有发生 穿刺结果出来了，结果并没有出乎意料。左侧VI类，考虑乳头状癌；右侧V类，疑似乳头状癌。\n以后要提醒G，多运动，少操心，万事看开，身体第一。\n破功 大脑已经适应了短平快的刺激，习惯了即时满足。对于稍微复杂一点的任务，就表现得很急躁，没有耐心。\n我们生活的这个时代，需要对抗太多的诱惑。\n2025/08/07 今日看了一天红楼梦索引，后来看了《扬州十日记》。说不出话。\n后之人幸生太平之世，享无事之乐；不自修省，一味暴殄者，阅此当警惕焉耳！ ——《扬州十日记》\n2025/08/08 命里八尺，难求一丈。\n最近“断网”行动做的不好，坐在电脑前面还是经常打开B站、小红书等。真的好想戒掉信息流，还内心世界一片平静。\n心事太杂，精气神不能聚拢一处。这是曾国藩总结自己屡次戒烟皆失败的原因。他认为，凝神聚气是人脱胎换骨的第一步。曾国藩32岁那年，给自己订了个十二条每日例行功课，曰《日课十二条》，内容如下：\n主敬：整齐严束，无时不惧；无事时心在腔子里，应事时专一不杂，如日之升。 静坐：每日不拘何时，静坐半时，体验静极生阳来复之仁心，正位凝命，如鼎之镇。 早起：黎明即起，醒后勿沾恋。 读书不二：一书未点完，不看他书。东看西阅，徒循外为人。每日以十页为率。 读史：廿三史每日十页，虽有事亦不间断。 日知其所亡：每日记茶余偶谈一则，分为德行门、学问门、经济门、艺术门；写日记，须端楷，凡日间过恶——身过、心过、口过——皆需一一记出。 月无忘其所能：每月作诗文数首，以验积理之多寡，养气之盛否。不可一昧耽著，最易溺心丧志。 谨言：刻刻留心，是功夫第一。 养气：气藏丹田，无不可对人言之事。 保身：谨遵大人手谕，节欲、节劳、节饮食。 作字：早饭后作字半时，凡笔墨应酬，当作功课；不可待明日，愈积愈难清。 夜不出门：旷功疲神，切戒切戒。 2025/08/09 - 2025/08/10 周六陪G去约了手术时间，8.26入院，8.27手术。\n剩余的周末时间做饭、看剧、跟朋友聚餐。\n2025/08/11 9:17到公司。\n奇思妙想 现代人一天要解锁多少次手机？有多少次解锁是必需的，又有多少次解锁纯粹是为了“娱乐”。今天临下班之前，我想到一个idea：或许有这样一个应用程序，每次我们要解锁手机时，它先问我们“本次打开手机是为了什么？”。这样在解锁手机与使用手机之间就又多了一道门槛，一方面加大获取难度，另一方面也能再次提醒我们是为何而解锁手机。\n查了下确实有类似APP（Intenty、One Sec），试用了下，感觉不太满意。看来靠第三方工具还是不太靠谱。\n2025/08/12 9:30来到公司查专家\n2025/08/13 xray-core 早上想在xray服务端屏蔽一个特定网址，不知道为什么，配置之后无效，还是可以访问。\n今天写了【代理】在一台废弃VPS上重新走一遍Xray-core代理配置流程这篇博客。\n2025/08/14 中国城市之我见 不知何时起，各种各样的城市排名充斥在网络上，而且很多排名的分级方式已经不满足于传统的“一二三线”，而是不断往上拔高，出现了类似“中杯、大杯、超大杯”这种夸张的命名方式。超一线、强一线、弱一线、新一线、准一线，只要定语够多，大家都是一线。我的观点，就用一二三线排，以下是我个人的看法。\n首先按一级行政区盘点各省主要城市：\n晋 - 山西：太原 冀 - 河北：石家庄 鲁 - 山东：济南、青岛 豫 - 河南：郑州 黑 - 黑龙江：哈尔滨 吉 - 吉林：长春 辽 - 辽宁：沈阳、大连 京 - 北京：北京 津 - 天津：天津 内蒙- 内蒙古：呼和浩特 陕 - 陕西：西安 甘 - 甘肃：兰州 宁 - 宁夏：银川 江 - 江苏：南京、苏州、无锡 浙 - 浙江：杭州、宁波 沪 - 上海：上海 皖 - 安徽：合肥 鄂 - 湖北：武汉 湘 - 湖南：长沙 赣 - 江西：南昌 云 - 云南：昆明 贵 - 贵州：贵阳 川 - 四川：成都 渝 - 重庆：重庆 粤 - 广东：广州、深圳 桂 - 广西：南宁 琼 - 海南：海口、三亚 闽 - 福建：福州、泉州、厦门 台 - 台湾：台北 港 - 香港：香港 澳 - 澳门：澳门 新 - 新疆：乌鲁木齐 青 - 青海：西宁 藏 - 西藏：拉萨 下面给出我的分级：\n一线：香港、上海、北京 二线：（深圳）、（广州、杭州）、（南京、成都、武汉、重庆）、（天津、苏州） 三线：（青岛、宁波）、济南、西安、合肥、福州、长沙、郑州 其他：所有其他城市 本人自编的中国一级行政区顺口溜：\n晋冀鲁豫黑吉辽 京津内蒙陕甘宁 江浙沪皖鄂湘赣 云贵川渝粤桂琼 闽台港澳新青藏 Warp突然不可用 由于chatGPT对VPS厂商的IP进行封锁，无法使用ChatGPT客户端（网页端是可以正常使用的），所以之前为了用chatGPT APP，使用了Warp虚拟出一个IPv6地址，然后在Xray配置文件里配置访问chatGPT的流量走这个网卡。\n下午突然发现访问不了chatGPT了。登上VPS后台一看，warp虚拟出的IPv6网卡没有了，尝试重新获取也一直失败。索性直接把warp卸载了，无非就是用不了chatGPT客户端嘛。网页端能用就行，手机端直接用Gemini了，现在大模型多的是，不用上赶着OpenAI。\n所以现在服务端配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 { \u0026#34;log\u0026#34;: { \u0026#34;loglevel\u0026#34;: \u0026#34;debug\u0026#34; }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;port\u0026#34;: 443, \u0026#34;protocol\u0026#34;: \u0026#34;vless\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;clients\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;***********************\u0026#34;, // run `xray uuid` to generate \u0026#34;flow\u0026#34;: \u0026#34;xtls-rprx-vision\u0026#34; } ], \u0026#34;decryption\u0026#34;: \u0026#34;none\u0026#34; }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;security\u0026#34;: \u0026#34;reality\u0026#34;, \u0026#34;realitySettings\u0026#34;: { \u0026#34;dest\u0026#34;: \u0026#34;lapl.org:443\u0026#34;, // A website that support TLS1.3 and h2. You can also use `1.1.1.1:443` as dest \u0026#34;serverNames\u0026#34;: [ \u0026#34;lapl.org\u0026#34; // A server name in the cert of dest site. If you use `1.1.1.1:443` as dest, then you can leave `serverNames` empty, it is a possible ways to bypass Iran\u0026#39;s internet speed restrictions. ], \u0026#34;privateKey\u0026#34;: \u0026#34;****************************\u0026#34;, // run `xray x25519` to generate. Public and private keys need to be corresponding. \u0026#34;shortIds\u0026#34;: [ // Required, list of shortIds available to clients, can be used to distinguish different clients \u0026#34;****************\u0026#34; // If this item exists, client shortId can be empty. 0 to f, length is a multiple of 2, maximum length is 16 ] } }, \u0026#34;sniffing\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;destOverride\u0026#34;: [ \u0026#34;http\u0026#34;, \u0026#34;tls\u0026#34;, \u0026#34;quic\u0026#34; ], \u0026#34;routeOnly\u0026#34;: true } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;tag\u0026#34;: \u0026#34;direct\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34; // Main Outgoing Protocol }, { \u0026#34;tag\u0026#34;: \u0026#34;block\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;blackhole\u0026#34; } ] } 2025/08/15 昨晚在江边听到一首好听的歌。《盲童》—— 苏娃\n2025/08/16 - 2025/08/17 周六工地开放日，去看了下房子。 周日去朋友家，游泳、唱歌。\n2025/08/18 这几天摩托车突然声音很大，又把齿轮油和机油换了一遍。\n2025/08/19 今日无事。\n2025/08/20 短暂快乐 = 永久痛苦 今天赖床了。9点醒了在床上玩手机，破功了。11点多到公司。\n2025/08/21 衣物断舍离 昨晚失眠了，三点才睡。10点多起床，重新整理了下衣物。\n2025/08/22 什么都不想写。背一遍《我的楼兰》的歌词吧。\n我的楼兰 想问沙漠借那一根曲线 缝件披风为你御寒 用肺腑去触摸你的灵魂 我就在那只火炉边取暖 想问姻缘借那一根红线 深埋生命血脉相连 用丝绸去润泽你的肌肤 我就在那个怀抱里缠绵 你总是随手把银簪插在太阳上面 万道光芒蓬松着你长发的波澜 我闻着芬芳跋涉着无限远 只为看清你的容颜 你总不小心把倩影靠在月亮上面 万顷月光舞动着你优美的梦幻 我闻着芬芳跋涉着无限远 只为看清你的容颜 谁与美人共浴沙河互为一天地 谁与美人共枕夕阳长醉两千年 从未说出我是你的尘埃 但你却是我的楼兰 想问姻缘借那一根红线 深埋生命血脉相连 用丝绸去润泽你的肌肤 我就在那个怀抱里缠绵 你总是随手把银簪插在太阳上面 万道光芒蓬松着你长发的波澜 我闻着芬芳跋涉着无限远 只为看清你的容颜 你总不小心把倩影靠在月亮上面 万顷月光舞动着你优美的梦幻 我闻着芬芳跋涉着无限远 只为看清你的容颜 谁与美人共浴沙河互为一天地 谁与美人共枕夕阳长醉两千年 从未说出我是你的尘埃 但你却是我的楼兰\n2025/08/23 - 2025/08/24 周六跟朋友一起玩大富翁、看电影、吃饭、散步； 周日唱歌。\n2025/08/25 11点才到公司。发现工位上插座没电，怀疑跳闸。\n打开右侧配电箱，左下角标记为实验台预留的开关是控制我们这一排工位的插座的。\n入院 G明天要住院了。\n2025/08/26-2025/09/01 这一周是G的住院时间。\n","date":"2025-08-01T12:58:00+08:00","permalink":"https://bitdove.github.io/posts/%E6%97%A5%E8%AE%B02025%E5%B9%B48%E6%9C%88/","title":"【日记】2025年8月"},{"content":"床 床的尺寸 床垫尺寸≠床的尺寸。床垫尺寸通常是标准的1.8m*2m、2m*2m等。通常，床的尺寸 \u0026gt; 床垫尺寸。\n床的宽度和长度 床边到墙边预留60cm活动空间； 床边到柜子的距离不能小于45cm，空间局促的卧室尽量选择推拉门衣柜； 根据窗头两边插座的距离选择床的宽度； 床的高度 有背景墙的，床头高度不能超过背景墙高度； 尽量定好床垫高度再去选择床； 床脚高度\u0026gt;14cm可过扫地机器人。 床的分类 从材质上，分为软包、实木、铁艺三种类型，软包和实木较为常见；\n软包床与沙发同根同源，软包床 = 木框架+海绵+羽绒包+皮或布包住。\n选软包床就考虑一个问题：平时靠在床头的时候多不多，多的话可以选。\n如果喜欢靠在床上看书/玩手机等，实木床基本排除；\n实木床选择比较常用的木材：白蜡木、红橡木、白橡木、樱桃木、黑胡桃木、硬枫木、柚木。\n铁艺床便宜简单，可放在次卧/小书房，推荐宜家。\n建议 床和床垫预算建议1:1。 3000以内选国产大品牌；3-5k选工艺好的接触面真皮床；5k以上选比较高端的讲究工艺/全真皮的产品。 床垫真的是消费陷阱； 床板不要选起拱的，选平的，宽度在10cm左右，间隙5cm以内；也可选平板整板。\n","date":"2025-07-16T01:11:32-07:00","permalink":"https://bitdove.github.io/posts/furniture/","title":"【装修】家具选购"},{"content":"2025年考试 浙江省省属事业单位2025年上半年集中公开招聘人员 考试时间：2025年4月26日\n考试科目：\n上午9:00-11:30《综合应用能力》 下午2:00-3:30《职业能力倾向测验》 浙江省省属事业单位2025年下半年集中公开招聘人员 考试时间：2025年9月27日\n考试科目：\n上午9:00-11:30《综合应用能力》 下午2:00-3:30《职业能力倾向测验》 浙江省考 待定\n备考方案 考试 国考一般在11-12月； 省考有小联考、大联考；小联考通常在国考结束一周左右，江浙沪京津鲁川等省份参与；大联考在次年3月份，包括除小联考省份以外的其他省； 事业单位 行测 政治理论：时政和习新思想 常识判断 言语理解与表达 判断推理 数量关系 资料分析 资料分析、判断推理、言语理解与表达是三大重点模块，先学； 再学数量关系； 最后学政治理论； 常识判断平时积累。\n申论 动笔比听课重要\n事业单位 联考每年两次，上半年一次，下半年一次。\n职测+综应，分ABCDE等类。\n自主招生。事业单位自己举行考试，公基、综合知识、职测+综应，要去看大纲具体靠什么。\n","date":"2025-07-14T15:30:32-07:00","permalink":"https://bitdove.github.io/posts/govexams/","title":"【考编】公考备考计划"},{"content":"2025年7月日历 一 二 三 四 五 六 日 1 2 3 4 5 6 7 8 9 10 11 12 13 14 × 15 16 17 × 18 19 20 21 × 22 23 24 25 26 27 28 × 29 30 31× 2025/07/14 今天是失败的一天，来复盘一下发生了什么。\n崭新的一周，我8：45左右来到公司，吃完早餐大约9点。坐到工位上的第一件事是用电脑打开了B站，为了升级到Lv6，最近我每天都会投币三次。完成每日经验任务后，我并没有停下，而是继续看B站，由于最近对手机的关注，开始看各种各样的手机测评视频和网购链接，今天主要看了一加13T。B站大约看到11点。\n也就是说早上一到公司就看了2个小时B站，B站首页尝尝推荐一些软色情视频，即便没有点开，但一眼看过去还是会有一丝邪念在心中升起。\n11点左右，想起刚刚更新的仙逆还没有看，所以又去看仙逆。最新一集的仙逆中，王林在尸阴宗遇到了一漂亮女子，破我道心，这应该算是今天的Trigger。就这样去了厕所，下载了Telegram，打开了jable.tv，做了不该做的事情。\n反思：\n少看B站。每天只点开三个视频，把币投完，不观看内容，10秒钟内完成。 禁止下载Telegram。 罪恶！ 想到今天已然是失败的一天，多来一次也无妨，所以晚上回家之后，一个人在家居然又来了一次！\n2025/07/15 今天7：50出门，8：30吃完早饭坐在工位上了。今天专注力恢复计划的第一天，我一定能够可以的！\n9:00 - 10:00 制定公考备考计划。\n10:00 - 12:30 学习论文《Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems》。\n12:30 - 14:00 午间休息。\n14:00 - 17:00 思考树莓派硬件身份识别工作如何开展。\n工作碎碎念 LLM优化 如果要将LLM应用于自动驾驶，那么LLM的输入是道路场景，包含丰富的信息，即大输入；而输出可能只有一两个token，如刹车、右转等，即小输出。在大输入-小输出的场景，对LLM的优化是否应该聚焦在prefilling阶段呢？ prefiiling和decoding的主要区别是prefilling阶段没有KV cache，所以如果要针对prefilling阶段进行优化，那么与KVcache相关的优化思路的优先级就低一些？\ndecoding阶段的优化在小输出场景收益有限：优化如KV Cache管理、加速单个token生成的技术（如更好的解码算法、小kernel优化）当然也有价值，但由于生成阶段本身耗时占比小，其优化的绝对收益远不如优化Prefilling显著。在小输出场景下，投入过多精力在生成阶段优化上性价比不高。\n树莓派硬件身份识别 我们在空闲、中负载、高负载三种情境下采集涵盖CPU、GPU、内存、SD卡的指标，如温度、时钟周期、执行时间差异等，每次采样的数据组成一条特征向量，每台树莓派采几百条，然后针对每台设备训练一个小模型，学习对应设备的特有运行轨迹。这样再从新设备上采集参数序列，输入到所有设备的模型，理论上，误差应该是全部过大，判定为“未知设备”\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 import subprocess import time import csv import os from datetime import datetime def run_cmd(cmd): result = subprocess.run(cmd, shell=True, capture_output=True, text=True) return result.stdout.strip() def get_temp(): return float(run_cmd(\u0026#34;vcgencmd measure_temp\u0026#34;).split(\u0026#39;=\u0026#39;)[1][:-2]) def get_freq(): return int(run_cmd(\u0026#34;vcgencmd measure_clock arm\u0026#34;).split(\u0026#39;=\u0026#39;)[1]) def get_volts(): return float(run_cmd(\u0026#34;vcgencmd measure_volts core\u0026#34;).split(\u0026#39;=\u0026#39;)[1][:-1]) def get_mem_free(): mem = run_cmd(\u0026#34;free -m\u0026#34;).split(\u0026#39;\\n\u0026#39;)[1].split() return int(mem[3]) # free memory in MB def get_sd_write_speed(): cmd = \u0026#34;dd if=/dev/zero of=tempfile bs=1M count=10 oflag=dsync status=none \u0026amp;\u0026amp; sync\u0026#34; start = time.perf_counter() run_cmd(cmd) elapsed = time.perf_counter() - start os.remove(\u0026#34;tempfile\u0026#34;) return round(10 / elapsed, 2) # MB/s def get_exec_time(): start = time.perf_counter() _ = [x**0.5 for x in range(10000)] # dummy workload return round((time.perf_counter() - start) * 1000, 3) # ms def collect_once(): return [ datetime.now().isoformat(), get_temp(), get_freq(), get_volts(), get_mem_free(), get_sd_write_speed(), get_exec_time() ] def main_loop(outfile=\u0026#34;metrics.csv\u0026#34;, interval=5, rounds=100): with open(outfile, \u0026#34;w\u0026#34;, newline=\u0026#34;\u0026#34;) as f: writer = csv.writer(f) writer.writerow([\u0026#34;timestamp\u0026#34;, \u0026#34;cpu_temp\u0026#34;, \u0026#34;cpu_freq\u0026#34;, \u0026#34;cpu_volts\u0026#34;, \u0026#34;mem_free_MB\u0026#34;, \u0026#34;sd_speed_MBps\u0026#34;, \u0026#34;exec_time_ms\u0026#34;]) for _ in range(rounds): row = collect_once() writer.writerow(row) print(\u0026#34;Collected:\u0026#34;, row) time.sleep(interval) if __name__ == \u0026#34;__main__\u0026#34;: main_loop() 2025/07/16 今天一天没好好工作，而是对家庭财务状况做了一些复盘和规划。\n一是规划了父母养老保险的事宜；二是规划了2026年度家庭年度预算。\n用房用车相当于家里多了一口人 用房指除房贷以外的用房费用，如物业费、车位管理费、水费、电费、燃气费、宽带费。按年计，物业费每年约4000元；车位管理费1200元；水电燃气宽带加起来算2300元。共计7500元；\n用车费用包括油费、保险费、停车费、保养费、违章费、过路费等，依旧按年计，油费按0.6元/公里，每年一万公里计为6000元；保险按每年4000元计算；停车费按照5000元计算；保养按照1000元计算；违章按500元计算；过路费主要为高速费，按照1000元计算。共计17500元\n用房+用车 = 25000元/年，平均每月2000元左右。我读大学的时候生活费就是一个月2000，可不就相当于家里多了一口人嘛！\n还有辆摩托车没算呢，油费大约0.2元/公里，保险每年300左右，保养每次50元左右。合计也得2500元/年左右。\n家庭储蓄小技巧 连续三年，每年存一笔三年期的定期存款，到期后存三年。举个例子，2025年、2026年、2027年分别存一笔三年期的定期存款，这样从2028年开始，每年都有一笔存款到期，到时如果有用就拿去用，暂无用途的话就连本带息再存三年（也可以再加上一些，提高存款额度）。\n2025/07/17 今天10点才到公司。\n意淫也是不被允许的！ 今天下午，小红书查东西看到了杨幂的性感照片，一时间在脑海里YY了，所幸没有付诸行动。要引以为戒。看来小红书、B站这类社交媒体真的要少看，最好戒掉。\n今天意淫太久，要记住一切因果皆有报应，不要再消耗自己本就不多的福报了。\n要学习曾国藩，不为圣贤，便为禽兽。每天反省自己不好的念头，写到日记里去。\n晚上破功了！ 晚上7点左右回到家，一个人在家，破功了！\n反思：\n少一个人在家！Grace加班，那也跟着加班！ 隔绝色情源。 2025/07/18 今天9:50到公司。\n对昨晚的反思 昨晚的破功其实是下午意淫的延续。这表明NoFap计划要戒的不仅仅局限于Fap这个动作，而是包括意淫在内的一切邪淫。\n昨晚破功之后，借着贤者时间的无尽懊悔与自责，做了两件事情。\n注销了某APP账号（注销后同手机号是无法再注册的）。 在VPS代理服务器上屏蔽了色情网站。 当然，这两项不足以切断所有色情源，比如某APP账号还有一些同类产品，而VPS的屏蔽规则仅仅是屏蔽了色情网站，对于Telegram、Twitter这类涉及色情的海外APP，依然可以访问。后边再想办法吧。\n对手机的思考 在现代社会，特别是中国社会，手机的哪些功能是必需的？这个问题我想理清一下。\n手机作为目前普及度、使用率最高的工具，可以说平均人手一部都不止，市面上各种品牌各种设计的手机更是数不胜数。我认为手机的必需功能只有以下几点：\n通信：通信分为基础通信和网络通信。基础通信即电话和短信，这是自功能机时代就已具备的功能。网络通信随着移动互联网而诞生，在中国大陆，主要是微信。 钱包：不同于欧美全民信用卡支付的习惯，中国采用移动支付，普及率已相当高。代表性APP如微信支付、支付宝、云闪付等，另外还有各种银行APP。 导航：城市化使道路系统越来越复杂，即便是本地人也很难熟悉所有路。再加上私家车的普及以及大规模的人口流动，“去外地”成为每个人时常经历的事情，这时候导航软件便成了必需。目前国内两大巨头：高德地图和百度地图。 公共服务：处理政府相关业务，代表性APP如浙里办、交管12123、个人所得税等。 我认为以上4点就是手机必需的功能，也是它的工具属性所囊括的功能。另外有以下这些功能，我认为超出了手机的工具属性，应当减少使用。\n办公：代表性APP如钉钉、飞书、企业微信、WPS、腾讯会议等。 购物：移动互联网的崛起伴随着网购的普及。代表性APP如淘宝、京东、拼多多等。 摄影：拍照和录像。 娱乐：游戏及音视频。游戏诸如王者荣耀、和平精英等，不再一一列举；视频功能特指原本电视的功能，代表性APP如腾讯视频、爱奇艺等；音乐如QQ音乐、网易云音乐等。 信息：信息类是我认为目前手机上的最大毒瘤，它们充斥着碎片化的信息，强调即时满足，会降低人的专注力和耐心。代表性APP如抖音、小红书、微博等等。 国产APP的一大特点是业务聚合、恶性竞争。微信可以刷短视频、小红书可以网购、抖音可以支付，而所有软件都可以贷款。\n未来我使用手机的原则是保留四大必需功能，尽可能摒弃其它功能。办公我基本不需要，购物我用电脑网页端，摄像仅满足日常记录需求，娱乐我完全不要，信息是我需要重点屏蔽的功能。\n那么现在根据上述功能划分，梳理下目前安装的APP：\n通信：微信，这个想删但是删不掉； 钱包：微信、支付宝、中国工商银行、中国农业银行、中国银行、杭州银行； 导航：高德地图； 公共服务：浙里办、交管12123、个人所得税、中国电信、铁路12306； 办公：腾讯会议、飞书； 购物：无。通常使用京东和拼多多的微信小程序，淘宝使用电脑网页端； 摄影：系统自带相机； 娱乐：无； 信息：无; 其他：v2rayNG、Bitwarden、chatGPT、LocalSend、MXPlayer、Moon+ Reader Pro。 这样梳理下来，我感觉我的手机应该是没有可以精简的了，基本都是必备。那么对于手机这方面，接下来是减少使用，非必要不解锁。网络时间分配在手机和电脑上，下一步需要关注日常在电脑上耗费的时间和精力。\n2025/07/19 - 2025/07/20 周六陪Grace去做了体检，然后去摩旅了萧山天路。\n周日洗牙、游泳，晚上吃火锅中途偶遇火锅店停电。\n周六体检时遇到一件趣事，让我生出很多思考，关于“会哭的孩子有奶吃”这个社会规则的思考。后边可以单独写一篇博客。\n2025/07/21 杨幂和范冰冰竟是我的同班同学，而且还被\u0026hellip;\u0026hellip; 有必要记录一下这个离谱的梦。离谱到让我不到7点就起床来到公司。让我们一起进入我昨晚的梦境。\n故事背景：中学班级内（感觉像是高二）。 人物介绍： 主人公：我； 女同学：杨幂、范冰冰、赵丽颖（疑似）；其中赵丽颖是我同桌； 恶霸团伙：大哥和他的众小弟。 大哥是我们班出了名的坏学生，靠着强壮的身体和一帮混混小弟，以及做事狠辣的性格，成了我们班里的王，无人敢惹。因此他在班里为非作歹，百姓苦不堪言。我是心中仍有正义感的好学生，但面对这种恶霸，我也无能为力，只能隐忍度日。\n杨幂和范冰冰是我们班里公认的校花，是所有男生的梦中情人。她们姣好的面容、婀娜的身姿，勾走了所有男生的魂魄。但我们这些“平头百姓”，也只敢想想，在心里与二位女神春风一度。\n可是大哥这个畜生，仗着自己的势力，居然在班里当众强奸杨幂和范冰冰！！！在梦里，我甚至能清楚地看到大幂幂给他口交的场景。大幂幂在课桌下，强忍着泪水，吐弄着大哥那根丑陋龌龊的东西。场面令我非常不适。之后，大哥还没过瘾，居然又对范冰冰同学伸出了魔掌！过程极度不适，不再细述。\n其实还有一位受害者，似乎是谭松韵？但这位应该是没有被强暴，只是衣服被撕烂，肩膀和胸口有抓伤的痕迹，我在梦里可以清晰看到。\n可怜两位女神，就这样，在公共场合，被这样一个恶霸夺取了清白之身。我目睹了一切，心中的正义之火冉冉升起，我怒不可遏，但顾虑大哥的势力，没能发作。转头轻声问我的同桌，与二位女神同为明星的赵丽颖同学：“你们女明星遇到这种事都会忍着吗？为什么不反抗？”。赵丽颖同学如何回复我，我记不清了，大概意思就是没办法，她们也惹不起大哥。\n事情并没有结束，我对教室强奸事件的不满与愤慨被大哥知道了，大哥开始刁难我。这天，他说其他班级的一摞资料放在我们班了，让我给人家送回去。我拿过这摞资料一看，上边没有任何归属人信息。我就问大哥：“大哥，这是哪个班的？”。大哥说他也不知道，让我自己去找。这时候我就知道了，这是故意刁难我呢。可是没办法，我还是出去找了。\n我出去之后，大哥还有他的几个小弟接着跟了出来，把我团团围住。我心想“完了，今天免不了挨一顿揍”，果然，大哥说我多管闲事，接着几个小弟就上来对我拳打脚踢。不过我惊喜地发现，他们打的不是很疼。肉体的惩罚结束之后，大哥决定对我进行精神惩罚。他让我把衣服全部脱掉，只留一个内裤。接着他的小弟们排成队，每人手里都拿着一盆酱料、鸡蛋等，一个一个的全都泼在我身上。\n就在接受酱料攻击的过程中，我醒了。一看时间，6:45。躺在床上，回顾了一下这场梦，感叹一下这梦的荒谬，知道自己再也睡不着了，我就起床了。\n破功 可能始于昨晚的梦，今天下午破功了。由于梯子已经屏蔽了色情网站，这次用了Twitter。\n反思：\nTwitter与Telegram这类信息源，无法通过xray规则屏蔽；这类APP其实有用信息不多，可以考虑注销账号。目前推特账号已全部注销。电报账号待注销。 上次间隔了两天，本次间隔了三天，有所进步，不必为本次破功过于自责，继续加油。 账号梳理 账号太多了，好乱。打算慢慢地整理一下。目标是：\n邮箱留一个Gmail、一个QQ邮箱。 苹果账号只留一个国区即可。 GitHub留一个 2025/07/22 今天整理了一天账号，基本结束。\n2025/07/23 为期三天的网络账号断舍离基本结束，最后总结一下：\n所有的账号密码均存储在Bitwarden，桌面端、移动端、主流浏览器插件齐全，很方便； 邮箱目前有Gmail、QQ、Outlook、163各一个； 谷歌账号只留一个，附带Google Voice； 微软账号一个； Apple账户两个，美区和国区各一个； GitHub账号一个； 先这样吧，今天没时间写了。\n2025/07/24 从上午9点开始找专家，找到下午4点。找了17个学校。\n2025/07/25 又是找专家的一天。\n2025/07/26 - 2025/07/27 周末跑了两天医院。G体检出甲状腺结节，瑞慈给了左侧一个相对较大的，尺寸大概是0.7cm，4A类；右侧一个较小的，尺寸大概0.25cm，3类；余结节2-3类。需要去医院诊治。\n周六先是去了浙二解放路园区，挂了一个普通号，接诊的是王文超医生，开了甲状腺功能检查（抽血）和甲状腺B超。从抽血结果报告单上看，甲状腺功能各指标正常；B超当天没排上号，约了第二天去浙二城东院区做B超。\n周日一早来浙二城东院区做B超，这次两边都给了4A类。立刻约了浙二解放路园区的甲状腺结节报告解读专家门诊（项承）。项承给出的方案是左侧甲状腺需要全部切除，右侧可以术中把结节取下来，做一个冰冻病理，如果是恶性，则把右侧甲状腺也全部切除；若为良性，就只切结节。当时也没想太多，就让他给安排了手术时间（下周六），但是去缴费的过程中，我和G打算再找其他专家看看，确认一下，谨慎一些。\n了解到在甲状腺结节良恶性评估这个阶段，B超医生至关重要。经过查询信息，了解到邵逸夫医院超声科三朵金花（寿金朵、徐海珊、吕江红）在这方面颇有盛名，恰好看到徐海珊当天的号还有，而且还是在邵逸夫钱塘院区，所以就挂了徐海珊医生的超声介入门诊，最后给出的结果两侧都是4B。\n经过两天的奔波，我们对这个病情以及诊治方案也有了一些了解。甲状腺结节整体上分为良性和恶性两种，且良恶性并非根据大小来区分，而是形态等多因素。恶性结节即为甲状腺癌。通常治疗方式有三种：\n观察：就是定期做B超和甲功检查，通常适用于3类及以下且大小小于3cm的结节。因为良性概率大，且未压迫气管等，可先观察； 消融：即用一根温度很高的针去烫结节，把结节烫死，后边靠人体的巨噬细胞把它吞噬掉。通常适用于小的良性/恶性结节，但是对恶性结节，消融无法100%去除病灶，后患大些。 手术：即摘除甲状腺，分为半切和全切，半切就是只摘甲状腺的左叶或右叶，全切是把甲状腺整体切除。甲状腺的主要功能是分泌甲状腺激素。半切后，剩下的一半甲状腺有可能能承担起全部功能，分泌的甲状腺激素够身体使用，这种不需要终身服药；全切由于摘除了整个甲状腺，身体无法在分泌甲状腺激素，需要终身用药物（优甲乐）补充甲状腺激素。 另外还有一项检查：穿刺。即通过一根细针，去取出结节的一些细胞做病理分析，检测结节的良恶性。但是穿刺有两大缺点：\n假阴性。即实际是恶性的，测出来却是良性的。有可能是结节太小，没有穿刺到结节，取到的样本是正常的甲状腺组织，当然是正常的；第二个原因是穿刺只能取出局部细胞检测，无法代表结节的整体情况。 刺激：穿刺有可能会刺激到恶性结节，引起扩散。 总结：穿刺结果是恶性，那就真的是恶性；穿刺结果是良性，实际未必是良性。\n现在约了周二邵逸夫医院王建彪医生的专家号。有一些问题需要问他：\n关于穿刺：右侧结节较小，是否有必要穿刺？如果穿刺为良性（可能是假良性）如何处置？如果穿刺为恶性如何处置？左侧结节是不是必要穿刺？左侧结节良性可能概率有多大？左侧如果不穿刺直接手术，是否有可能在术中检测一下良性还是恶性 关于手术：右侧结节较小，能否在手术中取出结节冰冻检查良性恶性？二刀的风险？ 关于消融：热消融的风险？如果消融不干净扩散如何处置？ 目前结节的状态，恶性是不是还没扩散？ 关于手术的安排：哪种方式？脖子还是腔镜？脖子刀疤肉眼是否明显？费用分别是多少？风险分别是什么样子的？住院需要几天？手术大概什么时间？术前检查有哪些？术前检查需要多久？主刀医生？ 2025/07/28 隔6天破功，继续加油！\n今天给HugoBlog加了一个实用的小脚本newpost.sh，有了它，创建新文章就简单多了。\n根据创建时间自动填入date字段； 提供选择菜单，将新文件放在哪个位置，并根据目录在新文件里填充categories字段； 自定义输入文件名，并根据文件名自动填充title字段； 如果文件名中包含“日记”二字，则自动在md文件插入当月的日历。 我的HugoBlog已经彻底不需要在本地安装Hugo，更换电脑只需要在新设备上配置好Git和GitHub，把HugoBlog这个仓库clone下来，用newpost.sh脚本进行创作，用deploy.sh一键发布即可。\n2025/07/29 杭州医保报销规则 本年个人账户用光+自费起付线，满足这两个条件才可以开始统筹报销。\n自费起付线这一部分，只有医保内的才算。可以用历年账户支付或现金支付。\n下午G要去医院了，希望一切顺利。\n2025/07/30 王医生的意思是还是先做两侧穿刺，探一下良恶性。我觉得还是比较合理的，起码没有上来就让人切除甲状腺。\n王医生对国内的医疗制度颇有看法，他表示穿刺这项检查中，病理科的医生起到很大影响。然后我说“但是病理科的医生患者无法自行选择”，他表示是的，且从医院的角度讲，这样也不好。不然有钱的都去找专家了，专家越做越好，穷人只能找没太多经验的普通医生，进一步加剧医疗不平等。\nTelegram已注销。\n1 2 3 4 警世 吕洞宾 二八佳人体似酥，腰间仗剑斩凡夫。 虽然不见人头落，暗里教君骨髓枯。 2025/07/31 数字极简 今天把手机上的YouTube和YouTube Music也卸载了，现在手机里没有任何娱乐类和信息流APP了。\n破功！ 尽管我为屏蔽网络色情内容已经做了以下事情：\nxray规则添加了block geosite:category-porn； Google Safe Search开启Filter模式； 卸载并注销Twitter、Telegram、Instagram等平台； 但依旧不够全面，在Google搜索中仍能见到色情内容。接下来需要做：\n不主动搜索色情关键字； 偶遇色情链接不点开； 发现疑似内容立刻关掉。 继续加油！\n","date":"2025-07-14T16:30:32+08:00","permalink":"https://bitdove.github.io/posts/%E6%97%A5%E8%AE%B02025%E5%B9%B47%E6%9C%88/","title":"【日记】2025年7月"},{"content":"思路 NWG150总里程即将达到3000km，可以准备进行二保了。\n首保是1050公里时自己做的，换了港版灰壳超凡喜力5W-30机油和速马力80W-90齿轮油。\n二保打算继续使用汽车机油，这次换完使用周期主要在七八九月份，是夏天，天气炎热，所以打算提高一个标号，采用港版灰壳超凡喜力5W-40机油，618活动80两瓶。一瓶机油是1L，NWG150的机油加注量是800ml，齿轮油加注量是120ml。综合各种信息，齿轮油加注同标号机油，应该是没有问题的。PCX的日版说明书对齿轮油的要求和机油的要求一模一样，所以我这次打算直接拿剩的机油当齿轮油换上。至于剩的80ml，就留着用来下次换机油的时候，旧油放完冲刷机油箱。\n踏板车加注汽车机油，除要注意“xW-x0”这个标号外，还要注意所选择机油带有“A3/B4”标志。\n材料准备 车辆 五羊本田NWG150 2025款 机油/齿轮油 港版壳牌全合成机油 灰壳超凡喜力5W-40 API/SP A3/B4级 1L； 工具 12-14-17mm三叉套筒扳手。\n其中，12mm用于拆机油放油螺栓，17mm用于机油拆滤网螺栓。\n12mm烟斗套筒\n用于拆齿轮油放油螺栓和注油螺栓。\n螺栓记号笔\n用于标记螺栓位置，确保更换机油后螺栓拧到位，既不过松也不过禁。可用扭力扳手替代。\n清洁剂\n用于清洗拆下来的各种螺栓和机油滤网。注意，化油器清洗剂对橡胶具有严重腐蚀作用，不要用它清洗橡胶垫片。考虑到对无腐蚀和快挥发的需求，我选择了这款电路板清洁剂。\n接油盆\n用于收集更换下来的废机油。废机油是重度污染物，需无害化处理。\n加油漏斗\n用于加注机油。\n注射器\n用于加注齿轮油。\n抹布、卫生纸、一次性手套等清洁用具\n保养过程 螺栓定位 用油漆笔在机油放油螺栓、机油滤网螺栓、齿轮油放油螺栓、齿轮油加注螺栓处进行标记。\n热车 找一平坦地面，怠速运行3~5分钟（或水温表升至中间刻度）。\n热车可提升机油流动性，排放更彻底；冷车状态杂质沉到油底壳底部，直接放油可能排不干净。热车后杂质随油流动，换油更彻底；\n放齿轮油 用12mm烟斗套筒扳手逆时针拧开齿轮油注油螺栓；\n放好接油盆，用12mm烟斗套筒扳手逆时针拧开齿轮油放油螺栓，齿轮油开始流出。\n可以适度倾斜车辆，让油放得更彻底。\n拆下来的螺栓和垫片要保管好，并且不要弄混。 先拆注油螺栓，再拆放油螺栓。这样放得更快。 放机油与加齿轮油 放完齿轮油，熄火应已有2-3分钟，机油已回流油底壳，可以开始放机油。\n同理，为放油更快，先把机油尺拧下来； 放置好接油盆，用17mm套筒把机油滤网螺栓拧下来； 再用12mm烟斗套筒扳手把机油放油螺栓拧下来，机油开始流出。\n一定要注意： 放油螺栓往车头方向拧是松开。 放油螺栓有个垫片，千万不要弄丢，如果找不到，在废机油里捞一捞。\n在放机油期间，可以去加齿轮油。\n用清洁剂清洗齿轮油放油螺栓、齿轮油注油螺栓及垫片，并擦拭放油及注油螺丝孔周边金属面； 将齿轮油放油螺栓原样安装回去，用扳手将其拧至标线重合。 用注射器抽取120ml新机油，从齿轮油注油口注入； 将齿轮油注油螺栓原样安装回去，用扳手将其拧至标线重合。 加机油 此时机油应该差不多放完了，可以适当晃动车辆，使机油放得更彻底。若新机油有剩余，可将剩余部分通过加油漏斗注入，冲刷一下，彻底排放干净后，开始加机油。\n用清洁剂清洗机油滤网、机油滤网螺栓及垫片，擦干后原样安装回去，用扳手将其拧至标线重合。 用清洁剂清洗机油放油螺栓及垫片，擦干后原样安装回去，用扳手将其拧至标线重合。 用清洁剂清洗机油标尺，擦干备用； 用加油漏斗注入800ml机油； 用机油尺检测机油量，油位应在中等偏上位置，多抽少添。机油量正常后装回机油尺并拧紧。 善后 至此，机油和齿轮油已经全部更换完毕。接下来的工作是收拾战场，把保养过程产生的垃圾适当处理，工具清洁并收纳。\n","date":"2025-06-30T21:01:32-07:00","permalink":"https://bitdove.github.io/posts/how-to-maintain-nwg150/","title":"【摩托保养】五羊本田NWG150更换机油齿轮油"},{"content":"千岛湖小环线 ","date":"2025-06-26T20:17:32-07:00","permalink":"https://bitdove.github.io/posts/ride-to-qiandaolake/","title":"【摩旅】小踏板日行千里——千岛湖环湖之旅"},{"content":"想法 不仅要关注物品的获取成本，还需要关注持有成本； 衣物 衣物的生命流程包括获取、使用、维护、废弃四个阶段。\n获取：主要是购买，另外有些是文化衫等赠送； 使用：即日常穿着的过程； 维护：主要是衣物的洗涤，另外还包括缝补、熨烫等； 废弃：直接扔掉、捐赠等途径。 维护 衣物的洗涤有手洗、机洗、干洗三种方式。干洗通常需要去专门的干洗店，这不符合我的消费观，故直接不予考虑。那么就剩手洗和机洗。\n洗涤剂均采用洗衣粉即可。\n数字极简 智能手机与移动互联网的普及给我的个人生活带来了很多方便。动动手指就可以买遍天下好物，丰富的信息流填充了排队、乘车的无聊时刻，社交软件让我与相隔千里的朋友联系毫无不便。然而，近两年，我越来越关注到互联网与智能手机给生活带来的负面影响。无数的广告充斥着各类手机软件，让我关注到了自己本不存在的需求，进而产生不必要的购物；短视频等信息流占据了大脑，让大脑持续处于兴奋状态，专注力却不断下降；微信连通世界，我却失去了对它说不的权利。\n为了重获专注力，寻得内心的安宁，我要重新审视自己的网络生活。考虑到自己的生活工作现状，彻底弃用互联网并不现实，但我想还是要尽量地脱离网络。而电子设备作为网络的载体，在我看来是互联网的“共犯”，在这里一并梳理。\n账号 各种各样的网络服务充斥着现代生活，每一个平台都要求注册一个账号。\n手机 手机是现代生活最常见的终端联网设备，也是各种信息流最猖獗的地方。无数厂商都开发了自己的APP，试图攻占我们的手机，进而夺取我们的时间。这背后无数的资本家苦思冥想，盼望用户在自家的APP上驻足更多时间。这是一个主要战场，是一块难啃的骨头。但是，我们还是要干掉它，通向极简，寻求安宁。\n我首先要明确自己对手机的需求。首先我不玩手机游戏，其次拍照只需要扫码和人脸识别，最后我不刷短视频等信息流。我的目标是只把手机作为一个必备工具使用，娱乐、学习等均不通过它完成。\n目前安装的第三方APP：\n通信：微信； 钱包：微信、支付宝、中国工商银行、中国农业银行、中国银行、杭州银行； 导航：高德地图； 公共服务：浙里办、交管12123、个人所得税、中国电信、铁路12306； 办公：腾讯会议、飞书； 购物：无； 摄影：系统自带相机； 娱乐：无； 信息：无; 其他：v2rayNG、Bitwarden、chatGPT、LocalSend、MXPlayer、Moon+ Reader Pro。 博客 我需要一个记录的地方，我想本博客就是一个不错的选择。它依托于GitHub，基本不需要担心丢失。其次，我主要给自己看，不需要太多观众，若无链接，本博不太容易被看到。（当然了，如果被看到了那便是有缘人，欢迎）。\n那就来整理一下这个博客，我应该建立几个分类。我会在这里写些什么呢？我想无非包括以下几点：\n对人生的思考。我常常思考人生，也经常萌生一些对人生意义的想法，这个分类有必要。 生活随笔。记录生活点滴，以及一些实践过的生活小妙招。 对社会事件的看法？这个需要吗，我还存在疑问； 工作内容相关？比如一些技术类内容 ","date":"2025-06-24T00:42:32-07:00","permalink":"https://bitdove.github.io/posts/minimalism/","title":"【WIP】我的极简生活观"},{"content":" 免责声明： 本文所述内容仅供技术学习和研究使用，不构成任何形式的非法行为指导。请读者严格遵守所在地区的法律法规，自行判断和承担使用相关技术可能带来的风险。作者不对因使用本文内容而产生的任何法律责任承担责任。\nThis is for macOS\nInstall Xray with Homebrew 1 brew install xray I will not use Homebrew anymore due to macOS downgrade.\nWrite Xray Config File Open Config File Using nano 1 nano /opt/homebrew/etc/xray/config.json Write Xray Client Config File replace username with your real username create .xray_log folder under your home folder create access.log and error.log file under .xray_log folder grant 755 to .xray_log, and 666 to access.log and error.log. replace IPaddress, port, id, serverName, publicKey, shortId 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 { \u0026#34;log\u0026#34;: { \u0026#34;loglevel\u0026#34;: \u0026#34;warning\u0026#34;, \u0026#34;access\u0026#34;: \u0026#34;/Users/uesername/.xray_log/access.log\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;/Users/uesername/.xray_log/error.log\u0026#34; }, \u0026#34;dns\u0026#34;: { \u0026#34;servers\u0026#34;: [ { \u0026#34;address\u0026#34;: \u0026#34;1.1.1.1\u0026#34;, \u0026#34;domains\u0026#34;: [\u0026#34;geosite:geolocation-!cn\u0026#34;] }, { \u0026#34;address\u0026#34;: \u0026#34;223.5.5.5\u0026#34;, \u0026#34;domains\u0026#34;: [\u0026#34;geosite:cn\u0026#34;], \u0026#34;expectIPs\u0026#34;: [\u0026#34;geoip:cn\u0026#34;] }, { \u0026#34;address\u0026#34;: \u0026#34;114.114.114.114\u0026#34;, \u0026#34;domains\u0026#34;: [\u0026#34;geosite:cn\u0026#34;] }, \u0026#34;localhost\u0026#34; ] }, \u0026#34;routing\u0026#34;: { \u0026#34;domainStrategy\u0026#34;: \u0026#34;AsIs\u0026#34;, \u0026#34;rules\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;domain\u0026#34;: [\u0026#34;geosite:category-ads-all\u0026#34;], \u0026#34;outboundTag\u0026#34;: \u0026#34;block\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;domain\u0026#34;: [\u0026#34;geosite:cn\u0026#34;], \u0026#34;outboundTag\u0026#34;: \u0026#34;direct\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;ip\u0026#34;: [\u0026#34;geoip:private\u0026#34;, \u0026#34;geoip:cn\u0026#34;, \u0026#34;223.5.5.5\u0026#34;, \u0026#34;114.114.114.114\u0026#34;], \u0026#34;outboundTag\u0026#34;: \u0026#34;direct\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;domain\u0026#34;: [\u0026#34;geosite:geolocation-!cn\u0026#34;], \u0026#34;outboundTag\u0026#34;: \u0026#34;proxy\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;ip\u0026#34;: [\u0026#34;1.1.1.1\u0026#34;], \u0026#34;outboundTag\u0026#34;: \u0026#34;proxy\u0026#34; } ] }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;tag\u0026#34;: \u0026#34;socks-in\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;socks\u0026#34;, \u0026#34;listen\u0026#34;: \u0026#34;0.0.0.0\u0026#34;, \u0026#34;port\u0026#34;: 10800, \u0026#34;settings\u0026#34;: { \u0026#34;udp\u0026#34;: true }, \u0026#34;sniffing\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;destOverride\u0026#34;: [\u0026#34;http\u0026#34;, \u0026#34;tls\u0026#34;, \u0026#34;quic\u0026#34;], \u0026#34;routeOnly\u0026#34;: true } }, { \u0026#34;tag\u0026#34;: \u0026#34;http-in\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;listen\u0026#34;: \u0026#34;0.0.0.0\u0026#34;, \u0026#34;port\u0026#34;: 10801, \u0026#34;sniffing\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;destOverride\u0026#34;: [\u0026#34;http\u0026#34;, \u0026#34;tls\u0026#34;, \u0026#34;quic\u0026#34;], \u0026#34;routeOnly\u0026#34;: true } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;tag\u0026#34;: \u0026#34;proxy\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;vless\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;vnext\u0026#34;: [ { \u0026#34;address\u0026#34;: \u0026#34;xxx.xxx.xxx.xxx\u0026#34;, \u0026#34;port\u0026#34;: 99999, \u0026#34;users\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\u0026#34;, \u0026#34;flow\u0026#34;: \u0026#34;xtls-rprx-vision\u0026#34;, \u0026#34;encryption\u0026#34;: \u0026#34;none\u0026#34; } ] } ] }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;security\u0026#34;: \u0026#34;reality\u0026#34;, \u0026#34;realitySettings\u0026#34;: { \u0026#34;fingerprint\u0026#34;: \u0026#34;chrome\u0026#34;, \u0026#34;serverName\u0026#34;: \u0026#34;xxxxxxx.xxx\u0026#34;, \u0026#34;publicKey\u0026#34;: \u0026#34;xxxxxxxxxxxxxxxxxxxxxx\u0026#34;, \u0026#34;shortId\u0026#34;: \u0026#34;xxxxxxxxx\u0026#34;, \u0026#34;spiderX\u0026#34;: \u0026#34;\u0026#34; } } }, { \u0026#34;tag\u0026#34;: \u0026#34;direct\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34; }, { \u0026#34;tag\u0026#34;: \u0026#34;block\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;blackhole\u0026#34; } ] } Add Proxy Switch to .zshrc 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # uesername add proxy proxyon(){ # Set environment variables export http_proxy=\u0026#34;http://127.0.0.1:10801\u0026#34; export https_proxy=\u0026#34;http://127.0.0.1:10801\u0026#34; export all_proxy=\u0026#34;socks5://127.0.0.1:10800\u0026#34; echo \u0026#34;Environment variables set for HTTP, HTTPS, and SOCKS5 proxies.\u0026#34; # Set system-level proxy for Wi-Fi networksetup -setwebproxy Wi-Fi 127.0.0.1 10801 networksetup -setsecurewebproxy Wi-Fi 127.0.0.1 10801 networksetup -setsocksfirewallproxy Wi-Fi 127.0.0.1 10800 echo \u0026#34;System-level proxy enabled for Wi-Fi.\u0026#34; # Start Xray brew services start xray echo \u0026#34;Xray config file path is /opt/homebrew/etc/xray/config.json\u0026#34; echo \u0026#34;Xray log file path is /Users/uesername/.xray_log\u0026#34; # Return Xray status and IP info brew services info xray echo \u0026#34;Your IP address is $(curl -s ip.sb)\u0026#34; } proxyoff() { # Unset environment variables unset http_proxy unset https_proxy unset all_proxy echo \u0026#34;Environment variables for proxies unset.\u0026#34; # Disable system-level proxy for Wi-Fi networksetup -setwebproxystate Wi-Fi off networksetup -setsecurewebproxystate Wi-Fi off networksetup -setsocksfirewallproxystate Wi-Fi off echo \u0026#34;System-level proxy disabled for Wi-Fi.\u0026#34; # Stop xray brew services stop xray # Return Xray status and IP info brew services info xray echo \u0026#34;Your IP address is $(curl -s ip.sb)\u0026#34; } # uesername add some alias alias ipinfo=\u0026#34;curl -s ipinfo.io\u0026#34; ","date":"2024-12-12T16:06:53-07:00","permalink":"https://bitdove.github.io/posts/xray-core-as-client/","title":"[TODO] You Don't Need a GUI Proxy Client"},{"content":"Source Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 #include \u0026lt;iostream\u0026gt; class Base_Member{ public: Base_Member(){ std::cout \u0026lt;\u0026lt; \u0026#34; Base_Member Constructor\u0026#34; \u0026lt;\u0026lt; std::endl; } ~Base_Member(){ std::cout \u0026lt;\u0026lt; \u0026#34; Base_Member Destructor\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class Derived_Member{ public: Derived_Member(){ std::cout \u0026lt;\u0026lt; \u0026#34; Derived_Member Constructor\u0026#34; \u0026lt;\u0026lt; std::endl; } ~Derived_Member(){ std::cout \u0026lt;\u0026lt; \u0026#34; Derived_Member Destructor\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class Base{ public: Base(){ std::cout \u0026lt;\u0026lt; \u0026#34; Base Constructor\u0026#34; \u0026lt;\u0026lt; std::endl; } virtual ~Base(){ std::cout \u0026lt;\u0026lt; \u0026#34; Base Destructor\u0026#34; \u0026lt;\u0026lt; std::endl; } private: Base_Member bm; }; class Derived : public Base{ public: Derived(){ std::cout \u0026lt;\u0026lt; \u0026#34; Derived Constructor\u0026#34; \u0026lt;\u0026lt; std::endl; } ~Derived(){ std::cout \u0026lt;\u0026lt; \u0026#34; Derived Destructor\u0026#34; \u0026lt;\u0026lt; std::endl; } private: Derived_Member dm; }; int main(){ //派生类指针指向派生类对象 std::cout \u0026lt;\u0026lt; \u0026#34;------派生类指针指向派生类对象------\u0026#34; \u0026lt;\u0026lt; std::endl; Derived* pDerived = new Derived(); delete pDerived; std::cout \u0026lt;\u0026lt; std::endl; //派生类指针不可以指向基类对象 //基类指针指向基类对象 std::cout \u0026lt;\u0026lt; \u0026#34;------基类指针指向基类对象------\u0026#34; \u0026lt;\u0026lt; std::endl; Base* pBase1 = new Base(); delete pBase1; std::cout \u0026lt;\u0026lt; std::endl; //基类指针指向派生类对象 std::cout \u0026lt;\u0026lt; \u0026#34;------基类指针指向派生类对象------\u0026#34; \u0026lt;\u0026lt; std::endl; Base* pBase2 = new Derived(); delete pBase2; std::cout \u0026lt;\u0026lt; std::endl; } Output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ------派生类指针指向派生类对象------ Base_Member Constructor Base Constructor Derived_Member Constructor Derived Constructor Derived Destructor Derived_Member Destructor Base Destructor Base_Member Destructor ------基类指针指向基类对象------ Base_Member Constructor Base Constructor Base Destructor Base_Member Destructor ------基类指针指向派生类对象------ Base_Member Constructor Base Constructor Derived_Member Constructor Derived Constructor Derived Destructor Derived_Member Destructor Base Destructor Base_Member Destructor ","date":"2024-10-30T23:48:55-07:00","permalink":"https://bitdove.github.io/posts/cpp-constructor-destructor-calling-order/","title":"【一文读懂】C++构造函数与析构函数的调用顺序"},{"content":"Info of Test System 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 _,met$$$$$gg. mason@LinuxVM ,g$$$$$$$$$$$$$$$P. ------------- ,g$$P\u0026#34; \u0026#34;\u0026#34;\u0026#34;Y$$.\u0026#34;. OS: Debian GNU/Linux 12 (bookworm) x86_64 ,$$P\u0026#39; `$$$. Host: VMware Virtual Platform None \u0026#39;,$$P ,ggs. `$$b: Kernel: 6.1.0-26-amd64 `d$$\u0026#39; ,$P\u0026#34;\u0026#39; . $$$ Uptime: 5 hours, 31 mins $$P d$\u0026#39; , $$P Packages: 557 (dpkg) $$: $$. - ,d$$\u0026#39; Shell: bash 5.2.15 $$; Y$b._ _,d$P\u0026#39; Resolution: 1280x800 Y$$. `.`\u0026#34;Y$$$$P\u0026#34;\u0026#39; Terminal: /dev/pts/0 `$$b \u0026#34;-.__ CPU: 12th Gen Intel i3-12100 (2) @ 3.302GHz `Y$$ GPU: 00:0f.0 VMware SVGA II Adapter `Y$$. Memory: 696MiB / 1932MiB `$$b. `Y$$b. `\u0026#34;Y$b._ `\u0026#34;\u0026#34;\u0026#34; Size of C++ Types 1 2 3 4 5 6 7 8 9 10 11 sizeof(bool) = 1 sizeof(char) = 1 sizeof(short int) = 2 sizeof(int) = 4 sizeof(unsigned int) = 4 sizeof(unsigned long) = 8 sizeof(long) = 8 sizeof(long long) = 8 sizeof(float) = 4 sizeof(double) = 8 sizeof(long double) = 16 Source Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;iostream\u0026gt; int main(int argc, char* argv[]){ std::cout \u0026lt;\u0026lt; \u0026#34;sizeof(bool) = \u0026#34; \u0026lt;\u0026lt; sizeof(bool) \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sizeof(char) = \u0026#34; \u0026lt;\u0026lt; sizeof(char) \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sizeof(short int) = \u0026#34; \u0026lt;\u0026lt; sizeof(short int) \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sizeof(int) = \u0026#34; \u0026lt;\u0026lt; sizeof(int) \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sizeof(unsigned int) = \u0026#34; \u0026lt;\u0026lt; sizeof(unsigned int) \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sizeof(unsigned long) = \u0026#34; \u0026lt;\u0026lt; sizeof(unsigned long) \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sizeof(long) = \u0026#34; \u0026lt;\u0026lt; sizeof(long) \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sizeof(long long) = \u0026#34; \u0026lt;\u0026lt; sizeof(long long) \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sizeof(float) = \u0026#34; \u0026lt;\u0026lt; sizeof(float) \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sizeof(double) = \u0026#34; \u0026lt;\u0026lt; sizeof(double) \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sizeof(long double) = \u0026#34; \u0026lt;\u0026lt; sizeof(long double) \u0026lt;\u0026lt; std::endl; return 0; } ","date":"2024-10-30T23:40:39-07:00","permalink":"https://bitdove.github.io/posts/cpp-type-size-test/","title":"【测试】C++类型大小测试"},{"content":"关联式容器 关联式容器概述 关联式容器的每个元素都有一个key值一个value值。当元素被插入到关联式容器时，容器内部结构便依照key值大小，按照某种规则将该元素置于适当位置。\n关联式容器没有头尾之分，自然也就没有push_back()、pop_front()等操作。\n关联式容器的内部结构只有两种：\n以红黑树（RB-tree）为底层结构: set map multiset multimap 以哈希表（Hash-table）为底层结构: unordered_set unordered_map unordered_multiset unordered_multimap Tree的导览 节点的大小：该节点及其所有子节点的节点总数； 路径长度：A节点到B节点的唯一路径经过的边数； 节点的高度：该节点到其最深子节点（叶节点）的路径长度； 节点的深度：根节点到该节点的路径长度 二叉搜索树 二叉搜索树的性质：左子树的节点值 \u0026lt; 根节点的值 \u0026lt; 右子树的节点值\n查找：找最小就一直往左走，找最大就一直往右走； 插入：从根节点开始，遇到大的就向左，遇到小的就向右，一直到尾端，即为插入点。 删除：分两种情况： 目标节点只有一个子节点，直接将其子节点连至其父节点。 目标节点有两个子节点，以右子树中的最小值取而代之即可。 平衡二叉搜索树 所谓平衡，即没有任何一个节点过深。\n平衡二叉搜索树是加了“额外平衡条件”的二叉搜索树。\n平衡二叉搜索树比一般的二叉搜索树要复杂，插入节点和删除节点的平均时间也更长，但是它们可以避免极难应付的最坏（高度不平衡）情况，而且由于它们总是保持着某种程度的平衡，所以元素的查找时间平均而言就比较少。\n平衡二叉搜索树相较一般的二叉搜索树：\n查找更快； 插入和删除节点较慢。 常见的平衡二叉搜索树有AVL树、红黑树。\nAVL树 为了确保整棵树的深度为O(logN)，AVL树的“额外平衡条件”是：\n任何节点的左右子树高度相差最多为1。 最佳的平衡条件肯定是每个节点的左右子树有相同高度，但这个条件过于严苛，很难保证插入新元素而又保持这种平衡。所以AVL树退而求其次，允许每个节点的左右子树高度相差1，虽然这个条件会把平衡弱化，但仍能保证“对数深度”平衡状态。\n插入新节点后，可能会有节点违反平衡条件，且只有插入点到根节点这条路径上的各节点可能违反平衡状态。只要调整其中最深的那个节点，便可使整棵树重新获得平衡。\n假设该最深节点为X，由于节点最多有两个子节点，而所谓“平衡被破坏”意味着X的左右子树的高度相差2，因此可以分为四种情况：\n插入点位于X的左子节点的左子树——左左； 插入点位于X的左子节点的右子树——左右； 插入点位于X的右子节点的左子树——右左； 插入点位于X的右子节点的右子树——右右。 左左和右右彼此对称，称为外侧插入，可用单旋转解决； 左右和右左彼此对此，称为内侧插入，可用双旋转解决。\n单旋转 对于外侧插入，以左左为例，情况肯定是这样的，X的左子节点的左子树因新节点插入而成长了一层，导致X的左子树比右子树深度多2.\n调整方法（左左为例）：将X的左子节点提起来，使X自然下滑，并将X的左子节点的右子树挂到下滑后的X的左侧，即可重新获得平衡。\n这么做的原因呢？\n二叉树的规则使我们知道，X值肯定大于X的左子节点值，所以X必须成为调整后的X的左子节点的右子节点； 同时，X的左子节点的右子树的所有节点值肯定介于X和X的左子节点的值之间，所以X的左子节点的右子树应该落在调整后的X的左侧。 可以看出，左左的单旋转是一次顺时针旋转；右右的单旋转对称，是一次逆时针旋转。\n双旋转 对于内侧插入，以左右为例，单旋转无法解决问题。\n调整方法：双旋转利用两次单旋转完成：\n先对X的左子节点和X的左子节点的右子节点做一次单旋转； 再对X和第一次调整后的新的X的左子节点（原来的X的左子节点的右子节点）做一次单旋转。 AVL树的平衡条件仍较为严苛，对于set和map来说，需要频繁的插入和删除，若用AVL树作底层结构，会影响性能。AVL树只适合查找较多而插入删除操作较少的情况。\nRB-tree(红黑树) 红黑树不仅是二叉搜索树，而且满足以下规则：\n每个节点不是红色就是黑色； 根节点是黑色； 如果节点为红，其子节点必须为黑；(即父子节点不得同时为红)； 任一节点至NULL的任何路径，所含黑节点树必须相同。 根据规则4，新增节点必须为红； 根据规则3，新增节点的父节点必须为黑。 当新节点按照二叉搜索树的规则到达插入点，却未能符合上述条件时，就必须调整颜色和旋转树形。\n新插入节点导致破坏红黑树的规则肯定是破坏3，即父子节点同时为红了。 NULL节点可视为黑色。\n设新节点为X，其父节点为P，伯父节点为S，祖父节点为G，曾祖父节点为GG。根据规则4，X必为红，若P亦为红（这就违反了规则3，需要调整），则G必为黑（因为原为RB-tree，得符合规则3）。那么，根据X的插入位置及外围节点（S和GG）的颜色，可分为以下四种情况：\nS为黑且X为外侧插入。对这种情况，只需对P、G做一次单旋转，并更改P、G颜色，即可重新满足红黑树的规则3; S为黑且X为内侧插入。对这种情况，必须先对P、X做一次单旋转，并更改G、X颜色，再将结果对G做一次单旋转，即可重新满足规则3； S为红且X为外侧插入。对这种情况，先对P、G做一次单旋转，并改变X的颜色。此时如果GG为黑，一切搞定。若GG为红，见情况4； S为红且X为外侧插入。对这种情况，先对P、G做一次单旋转，并改变X的颜色。如果此时GG为红，还得持续往上做，直到不再有父子连续为红的情况。 以红黑树为底层结构的关联容器 set set的特性是，所有的元素都会根据key值自动被排序。\nset的key值就是value值，value值就是key值。set不允许两个元素有相同的key值。\n不能通过set的迭代器更改set的元素值。因为set元素值就是其key值，关系到set元素的排列规则。如果任意改变set元素值，会严重破坏set组织。set的迭代器其实被定义成底层红黑树的const迭代器了，杜绝写入操作。\n对set进行插入和删除操作后，之前的迭代器不会失效。（当然，被删除元素的迭代器肯定是失效了）\nmap map的特性是，所有元素会根据各自的key值自动被排序。\nmap的元素是pair类型，同时拥有key值和value值。pair的第一元素被视为key，第二元素被视为value。map不允许两个元素有相同的key值。\n通过map的迭代器可以修改map元素的value值，不可以修改map的key值，因为key值关系到map的排列规则，任意更改map元素的key值会破坏map组织。\n对map进行插入和删除操作后，之前的迭代器不会失效。（当然，被删除元素的迭代器肯定是失效了）\nmultiset multiset的特性及用法与set完全相同，唯一的差别在于它允许key值重复。\nmultimap multimap的特性及用法与set完全相同，唯一的差别在于它允许key值重复。\n哈希表（Hash-table） 二叉搜索树具有对数平均时间的表现建立在“输入的数据有足够的随机性”这样一种假设上。\n哈希表在查找、插入、删除等操作上具有“常数平均时间”的表现，且这种表现是以统计为基础的，不需依赖输入元素的随机性。\n哈希函数：将哈希表中元素的键值映射为元素存储位置的函数。 $$ Address = Hash(key)$$哈希冲突：可能出现不同的元素被映射到相同的位置。\n比如采用求余的哈希函数的话，2和5对3求余都是2，这样2和5就都存到位置2上了，这就是哈希冲突。\n解决哈希冲突的方法：\n线性探测 二次探测 开链法 以哈希表为底层结构的关联容器 红黑树有自动排序功能，哈希表没有。所以以哈希表为底层的关联容器在C++标准里都以unordered_开头。\nunordered_set 与set一样，unordered_set的key值就是value值，value值就是key值。\nunordered_map 与map一样，unordered_map的元素是pair类型，同时拥有key值和value值。pair的第一元素被视为key，第二元素被视为value。\nunordered_multiset unordered_multiset与multiset的特性完全相同，唯一的差别在于其底层是哈希表，所以其元素不会被自动排序。\nunordered_multimap unordered_multimap与multimap的特性完全相同，唯一的差别在于其底层是哈希表，所以其元素不会被自动排序。\n容器概述 C++标准里提供了以下容器或容器配接器：\n序列式容器： array vector list deque forward_list 关联式容器 set map multiset multimap 不定序关联容器 unordered_set unordered_map unordered_multiset unordered_multimap 配接器 stack queue priority_queue 序列式容器 array array是静态连续空间，一经配置，大小不可改变。\n就是数组，除了空间的灵活性不足，其他与vector很像。用的也比较少，一般都用vector了，这里就不多说了。\nvector vector的数据安排与操作方式，与array很相似。二者唯一的差别在于空间的运用的灵活性。\narray是静态空间，一旦配置不能改变； vector是动态空间，随着元素加入，内部机制会自行扩充空间以容纳新元素。 vector维护的是连续线性空间，其迭代器就是普通指针。\n1 vector\u0026lt;int\u0026gt;::iterator iter; 那么iter其实就是int*类型。\n两个迭代器start和finish之间是连续空间中目前已被使用的空间，end_of_storage指向整块连续空间的尾端。\n为了降低频繁空间配置带来的成本开销，vector实际配置的大小会比客户需求的更大一些，以备将来可能的扩充。这便是capacity的概念。\n[start,finish]是size(); [start, end_of_storage]是capacity(); [finish, end_of_storage]是备用空间。 一旦size() == capacity(),便是满载。下次再有新增元素，整个vector就要另觅他所了。“另觅他所”的过程会经历“重新配置大空间，元素移动，释放原空间”这一系列动作，工程浩大。\n所谓动态增加大小，并不是在原空间之后接续新空间（因为无法保证原空间之后有可供配置的空间），而是以原空间大小的两倍另外配置一块较大空间，然后将原内容拷贝过来，然后才开始在原内容后边构造新元素，并释放原空间。\n因此，对vector的任何操作，一旦引起空间重新配置，指向原vector的所有迭代器就都失效了，这是一个经常犯的错误，务必小心。\nlist list是环状双向链表。它的好处在于每次插入或删除一个元素，就配置或释放一个元素空间，与vector相比，list对空间运用更加精准，绝不浪费。且对于任何位置的元素插入或移除，list永远是常数时间。\nvector和list适用场景与以下有关：\n元素多寡 元素的构造复杂度（有无non-trival copy constructor， non-trival copy assignment operator） 元素存取行为的特性 list的节点结构如下：\n1 2 3 4 5 6 7 template \u0026lt;class T\u0026gt; struct __list_node{ typedef void* void_pointer; void_pointer prev; void_pointer next; T data; }; 由于list的内存空间无法保证是连续的，所以它的迭代器不再是普通指针。list的迭代器必须有能力指向list节点，并进行正确的递增、递减、取值、成员存取等操作。\nlist的操作大多不会使迭代器失效，即便是删除操作，也只有指向被删除元素的那个迭代器失效。\n由于list是一个环状双向链表，所以它只需要一个指针，便可以完整遍历整个链表。\n对于insert操作，新节点将位于哨兵迭代器（标示出插入点）所指节点的前方，这是STL对插入操作的标准规范。\ndeque vector是单向开口的连续线性空间，deque则是一种双向开口的线性连续空间。所谓双向开口，即可以在首尾两端分别做元素的插入和删除操作。\ndeque其实是动态地以分段连续空间组合而成。但是这些分段的连续空间，在用户看来确实一整块连续空间，这其实是deque做出的假象。这种假象由deque的中控器map（注意，不是STL中的map容器）负责维持。\n这个map可以理解为映射，它是一个指针，指向一小段连续内存空间，这块空间中的每个元素又都是一个指针，每个指针都指向deque的分段连续空间中的某一段。默认每一段是512字节。\nforward_list forward_list是单向链表。\n前边说了，对于insert操作，新节点将位于哨兵迭代器（标示出插入点）所指节点的前方，这是STL对插入操作的标准规范。\n但是forward_list作为单向链表，它没有什么方便方法回头定出前一个位置，它只能从头找起，所以除了forward_list起点处附近的区域外，在其他位置insert()或erase()就很慢，对此，forward_list特别提供了insert_after()和erase_after()。\n同样出于效率考虑，它不提供push_back()，只提供push_front()。\nAdapter（配接器） stack stack是先进后出（FILO）的数据结构。他只有一个出口，除了最顶端元素外，没有其他方法获得stack的其他元素。即stack是不允许有遍历行为的，自然也就没有迭代器了。\nSTL中的stack其实不算是container，而是adapter，因为其底层默认是deque，把deque的头端封闭，便形成一个stack。\n具有“修改某物接口，形成另一种风貌”之性质者，谓之adapter。\n除了deque，list也是双向开口的，所以list也可以做stack的底层结构。\nqueue queue是先进先出（FIFO）的数据结构。它有两个出入口，但都是被限制的，尾端只进不出，头端只出不进。除了尾端进，头端出之外，没有其他方法存取queue的其他元素，即queue也是不允许遍历的，自然也就没有迭代器了。\nqueue也是一种adapter，它同stack一样，默认以deque作为底层结构，list同样也可以做其底层结构。\n封闭deque的头端入口和尾端出口，就成了一个queue。\npriority_queue priority_queue是拥有权值观念的queue。\n所谓拥有权值观念，可以理解为有序的，其内的元素并非按照加入的次序排列，而是按照元素的权值排列，权值最高者排在最前边。\n默认状态下，priority_queue是用一个大根堆（max-heap）来完成，而大根堆是一个以vector表现得完全二叉树。\n大根堆：max-heap，父节点值大于或等于子节点值的完全二叉树； 小根堆：min-heap，父节点值小于或等于子节点值的完全二叉树。\n所以，priority_queue是以vector为底层结构，辅以heap处理规则来实现的，所以它也是一种adapter。\npriority_queue也不允许遍历，自然也没有迭代器。\n","date":"2024-10-30T23:34:54-07:00","permalink":"https://bitdove.github.io/posts/cpp-stl-container/","title":"【一文读懂】C++ STL中的容器"},{"content":"互斥与同步 在多线程编程中，有两大问题需要解决：互斥和同步。这两个问题经常放在一起说，但它们还是存在一些差别的。\n互斥：由于线程间存在共享数据，当多线程并发地对共享数据进行操作（主要是写操作）时，如不加以管理，可能导致数据不一致问题。互斥就是一个共享数据在同一时刻只能被一个线程使用，这样就保证了共享数据的一致性。\n同步：同步比互斥要更加严格。互斥只是规定多个线程不能同时使用共享数据，但是对谁先使用谁后使用并没有作出限制；而同步是指线程间存在依赖，它们应该有严格地执行顺序，如果A还没执行，那B只能等待A执行完再执行。\n对于互斥问题，一般用互斥锁（mutex）就可以解决；而同步问题，可以采用条件变量。\n当然，无论是互斥还是同步，都有其他解决方法，本文只关注互斥锁和条件变量。\n三线程顺序打印ABC 我们以三个线程按顺序循环打印字符ABC为例，在本例中：\n共享资源：标准输出就是这个问题中的共享资源。\n互斥问题：在同一时刻，三个线程中只能有一个打印字符；\n同步问题：三个线程之间存在明显的依赖关系：A打印完，B才可以打印；B打印完，C才可以打印；C打印完，A才可以打印。\n如果我们仅仅用互斥锁解决互斥问题，即用mutex对标准输出加以保护，确保同一时刻只有一个线程占用标准输出。那如何保证他们按ABC的顺序交替执行打印呢？\n你可能说可以通过轮询，比如让B线程一直轮询，一直问A线程：“你打印完没？”，直到获得肯定答案。这样很显然是非常占用CPU时间的，珍贵的CPU时间片全都拿来做轮询了，这是对资源的巨大浪费。\n或者你还有另一种方案，让B直接sleep一会儿，等sleep结束，再去问A打印完没。这种方案显然会影响线程的性能。\n条件变量解决了这个问题。通过条件变量，我们就可以采用事件模式。B线程发现A没打印完，就告诉操作系统，我要wait，一会儿会有其他线程发信号来唤醒我的。这个其他线程就是A线程，当A打印完，就调用signal/broadcast,告诉操作系统，之前有线程在wait，现在可以唤醒它（们）了。\n值得注意的是，条件变量自身并不包含条件，只是它通常与while或if等条件语句搭配使用，故得名条件变量。\n条件变量、互斥量、用户提供的判定条件，这三者一般组合使用。 线程检查用户提供的判定条件，如果条件不满足就通过wait函数释放锁然后进入阻塞。这个过程的原子性由条件变量提供，这也是条件变量的意义。\n下面贴出三线程按顺序循环打印字符ABC十次的源代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; pthread_cond_t cond = PTHREAD_COND_INITIALIZER; int isMyTurn = 0; void* printA(void* arg){ for(int i = 0; i \u0026lt; 10; ++i){ pthread_mutex_lock(\u0026amp;mutex); while(isMyTurn != 0){ pthread_cond_wait(\u0026amp;cond, \u0026amp;mutex); } printf(\u0026#34;A\\n\u0026#34;); sleep(1); isMyTurn = 1; pthread_cond_broadcast(\u0026amp;cond); pthread_mutex_unlock(\u0026amp;mutex); } } void* printB(void* arg){ for(int i = 0; i \u0026lt; 10; ++i){ pthread_mutex_lock(\u0026amp;mutex); while(isMyTurn != 1){ pthread_cond_wait(\u0026amp;cond, \u0026amp;mutex); } printf(\u0026#34;B\\n\u0026#34;); sleep(1); isMyTurn = 2; pthread_cond_broadcast(\u0026amp;cond); pthread_mutex_unlock(\u0026amp;mutex); } } void* printC(void* arg){ for(int i = 0; i \u0026lt; 10; ++i){ pthread_mutex_lock(\u0026amp;mutex); while(isMyTurn != 2){ pthread_cond_wait(\u0026amp;cond, \u0026amp;mutex); } printf(\u0026#34;C\\n\u0026#34;); sleep(1); isMyTurn = 0; pthread_cond_broadcast(\u0026amp;cond); pthread_mutex_unlock(\u0026amp;mutex); } } int main(){ pthread_t threadA, threadB, threadC; pthread_create(\u0026amp;threadA, NULL, \u0026amp;printA, NULL); pthread_create(\u0026amp;threadB, NULL, \u0026amp;printB, NULL); pthread_create(\u0026amp;threadC, NULL, \u0026amp;printC, NULL); pthread_join(threadA, NULL); pthread_join(threadB, NULL); pthread_join(threadC, NULL); } 在这个程序里，mutex、cond、isMyTurn这三者就是解决该问题中互斥与同步问题的三要素。\n我们通过isMyTurn变量提供判定条件:\n其值为0时，A可以打印； 其值为1时，B可以打印； 其值为2时，C可以打印。 以当前B线程获得时间片为例，锁住互斥量之后，检查判定条件，若isMyTurn的值不为1，则调用wait，并将已经锁住的互斥量传递给wait，wait函数会做三件事：\n对互斥量解锁； B线程进入阻塞状态，即把B线程放到等待cond条件变量的列表里。 wait函数返回时，对互斥量重新加锁。 由于B线程进入阻塞状态，调度程序会选择其他就绪线程执行，我们假设是A线程被调度，则A首先锁住互斥量，然后检查判定条件，发现isMyTurn当前值为0，所以它打印字符\u0026rsquo;A\u0026rsquo;,并将isMyTurn置为1，然后调用signal/broadcast函数通知操作系统，可以唤醒正在等待cond条件变量的线程了，使它（们）脱离阻塞状态。\n被唤醒的线程从wait函数返回，返回的同时会自动给互斥量加锁，然后继续检查判定条件，若不是自己的值，则继续调用wait进入阻塞；若是自己对应的值，则打印对应字符，并改变isMyTurn的值。\n存在的问题 signal和broadcast用哪个好？ signal和broadcast函数区别如下：\nsignal函数只唤醒一个等待该条件的线程；当有多个线程等待cond时，则唤醒优先级最高的一个；若多个等待cond的线程优先级相同，则唤醒谁是不确定的。 broadcast函数则唤醒所有等待该条件的线程。 适合用broadcast的情况：\n读者写者问题。即写者写完后，通知所有读线程可以读共享数据了； 一个生产者多个消费者且生产者一次生产多个产品的情况。生产者生产完，通知所有消费者可以消费了； 多生产者多消费者问题。 适合用signal的情况：\n单一生产者且每次生产一个产品的情况，最好只有一个消费者。 signal/broadcast与unlock的顺序问题 首先强调，man手册中明确指明：\nThe pthread_cond_broadcast() or pthread_cond_signal() functions may be called by a thread whether or not it currently owns the mutex that threads calling pthread_cond_wait() or pthread_cond_timedwait() have associated with the condition variable during their waits; however, if predictable scheduling behavior is required, then that mutex shall be locked by the thread calling pthread_cond_broadcast() or pthread_cond_signal().\n即无论当前线程是否持有锁，它都可以调用signal/broadcast。尽管如此，如果需要可预测的调度行为，还是应该在上锁的情况下调用signal和broadcast。\n但是在网上看到，上锁情况下调用signal和broadcast会降低效率。\nsignal/broadcast之后，unlock之前，可能其他线程已经获得时间片，它想锁住互斥量，但发现互斥量还被锁着，只能继续阻塞，直到持有锁的线程执行unlock后，它再次获得时间片，才能上锁。\n针对上面的三线程顺序打印ABC的程序，我进行了测试，测试环境为单核机器，测试结果如下：\n函数选用 测试结果 先signal再unlock 打印完一次ABC后卡住不动 先unlock再signal 正常 先broadcast再unlock 正常 先unlock再broadcast 正常 为什么先signal再unlock，执行结果不对，这个问题有待解决，还没有想通。欢迎知道的朋友留言，教教我，谢谢。\nReferences ","date":"2024-10-13T02:27:51-07:00","permalink":"https://bitdove.github.io/posts/linux-condition/","title":"【一文读懂】互斥锁与条件变量"},{"content":"程序的内存布局 聊static关键字之前，先要复习一下一个进程的内存布局。\nkernel space stack ↓ unused dynamic libraries unused heap ↑ read/write sections(.data .bss) readonly sections(.init .rodata .text) reserved 其中，stack向低地址增长，heap向高地址增长。\n对于32位的Linux系统，kernel space占1GB（0xc0000000～0xffffffff），剩下的用户空间占3GB。\n.text段：编译后产生的机器代码\n.data段：已初始化的全局变量和局部静态变量。\n.bss段：未初始化的全局变量和局部静态变量。\n未初始化 的全局变量和局部静态变量默认值都为0，本来也可以放在.data段，但是为它们在.data段分配空间并存放0是没有必要的。但可执行文件又必须记录未初始化的全局变量和局部静态变量的大小总和，所以.bss段只是为它们预留位置而已，并没有内容，在文件中也不占据空间。\nstatic关键字 面向过程程序设计的static 静态局部变量\n分配在静态存储区, 在程序整个运行期间都不释放。\n静态全局变量\n该变量在全局数据区分配内存。\n静态全局变量在声明它的整个文件都是可见的，而在文件之外是不可见的。\n静态函数\n静态函数与普通函数不同，它只能在声明它的文件当中可见，不能被其它文件使用。\n面向对象程序设计的static 静态数据成员\n对于非静态数据成员，每个类对象都有自己的拷贝。而静态数据成员被当作是类的成员。无论这个类的对象被定义了多少个，静态数据成员在程序中也只有一份拷贝，由该类型的所有对象共享访问。也就是说，静态数据成员是该类的所有对象所共有的。对该类的多个对象来说，静态数据成员只分配一次内存，供所有对象共用。所以，静态数据成员的值对每个对象都是一样的，它的值可以更新。\n静态成员函数\n与静态数据成员一样，我们也可以创建一个静态成员函数，它为类的全部服务而不是为某一个类的具体对象服务。静态成员函数与静态数据成员一样，都是类的内部实现，属于类定义的一部分。普通的成员函数一般都隐含了一个this指针，this指针指向类的对象本身，因为普通成员函数总是具体的属于某个类的具体对象的。通常情况下，this是缺省的。如函数fn()实际上是this-\u0026gt;fn()。但是与普通函数相比，静态成员函数由于不是与任何的对象相联系，因此它不具有this指针。从这个意义上讲，它无法访问属于类对象的非静态数据成员，也无法访问非静态成员函数，它只能调用其余的静态成员函数。\n","date":"2024-10-13T02:27:03-07:00","permalink":"https://bitdove.github.io/posts/cpp-static/","title":"【一文读懂】C++中的static关键字"},{"content":"Linux下CMake构建echo服务器项目 昨天测试CSAPP第十一章网络编程中的echo服务器时，想到顺便学着用CMake构建一下项目。\n关于CMake 这里来讲一下CMake是什么？以及我们为什么需要CMake？\nCMake是什么？ 在Windows下编程的时候，大概率会用到像Windows Visual Studio这样的集成开发环境（IDE），在这种IDE工作环境中，程序员只负责写程序，而像编译、链接这些工作是由IDE来自动完成的。\n实际上，编译和链接是相当复杂的一些工作，各种依赖关系想想都令人头大，只是Windows下IDE帮我们承担了这项任务。\n而Linux下是缺少这种IDE的。因为Linux下编程常常是服务端的编程，可能是在云主机上，只有命令行而没有GUI。\n那Linux下编译、链接这些工作谁来做呢？\n如果项目很小，源文件很少时，我们直接用编译命令就好了。比如\n1 gcc -o hello helloworld.c 但是，一旦遇到大工程，可能有成百上千个源文件，这时候各个源文件之间、源文件与库之间的依赖关系会非常复杂，还是用编译命令来编译、链接的话，将会非常低效且易错。\n这时候，make应运而生。没错，是make，还不是CMake。\n使用make需要有一个Makefile文件，Makefile文件定义了工程的依赖关系、编译参数等，Makefile文件告诉make命令需要怎样的去编译和链接程序，并且make会智能地根据当前的文件修改的情况来确定哪些文件需要重编译，从而自己编译所需要的文件和链接目标程序。\n但是对于一个大工程，编写Makefile也是件复杂的事，于是人们又想，为什么不设计一个工具，读入所有源文件之后，自动生成Makefile呢，于是就出现了CMake工具，它能够输出各种各样的makefile或者project文件,从而帮助程序员减轻负担。\nCMakeLists是需要程序员自己写的。\n我们的项目 项目组织结构如下图，这是一个比较正规的工程组织结构。src文件夹存放项目源文件，如.c .cpp等；include文件夹存放头文件；bin文件夹用来存放最终生成的可执行文件；build文件夹用来存放构建项目时生产的中间文件。\n示例项目是一个echo服务器。客户端发送字符串给服务端，服务端像回声一样再把同样的字符串发回客户端，并在服务端显示服务端接收了多少字节。\ncaspp.h是CSAPP提供的一个头文件，csapp.c是其实现文件。\nechoclient.c是客户端的实现文件。\nechoserveri.c是服务端的实现文件。\necho.c是用来显示接收字节数的函数实现文件。\n所以该项目最终会生成两个可执行文件，一个客户端，一个服务端。\nCMake工作原理 一个刚才会有多个CMakeLists，项目最外层一个CMakeLists，然后每个存放源文件的文件夹里要有一个CMakeLists。\n针对我们的echo项目，则一共要写两个CMakeLists文件：最外层需要写一个，称之为外层CMakeLists；src文件夹内需要写一个，称之为内层CMakeLists。\n外层CMakeLists 1 2 3 4 5 cmake_minimum_required (VERSION 2.8) project (MyEchoServer) option (CLIENT \u0026#34;For building echoClient\u0026#34; ON) set (EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/bin) add_subdirectory (./src) 一共五条语句：\n第一条语句指明要求的CMake最低版本。\n第二条语句提供项目名称等信息。\n第三条是控制选项，这条比较重要。\n因为我们编译客户端的时候不需要echo.c和echoserveri.c这两个文件的参与。这里定义一个名为CLIENT的选项，用来给内层CMakeLists一个标识，如果这个选项是ON，就编译客户端。是OFF则编译服务端。\n第四条语句设置了可执行文件的输出目录。\nEXECUTABLE_OUTPUT_PATH是cmake内置的变量，意为可执行文件输出路径。\nPROJECT_SOURCE_DIR也是cmake内置的变量，意为工程的根目录。\n这条语句含义就是把可执行文件输出路径设置为工程根目录下的bin文件夹。\n第五条语句也很重要。\nadd_subdirectory命令向当前工程添加存放源文件的子目录。src文件夹存放着项目源文件，所以这里传递src。\n外层CMakeLists是总的CMakeLists，它控制着整个构建流程。它通过add_subdirectory来进入各个装有源文件的子目录，并执行该目录里的内层CMakeLists，直到处理完再出来继续处理下一个add_subdirectory。\n我们这里只有一个源文件夹src，所以就只有一条add_subdirectory命令。\n内层CMakeLists 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 set (CLIENT_SRC_LIST ./csapp.c ./echoclient.c) set (SERVER_SRC_LIST ./csapp.c ./echo.c ./echoserveri.c) include_directories (../include) find_package (Threads) if (CLIENT) add_executable (echoclient ${CLIENT_SRC_LIST}) target_link_libraries (echoclient ${CMAKE_THREAD_LIBS_INIT}) else() add_executable (echoserver ${SERVER_SRC_LIST}) target_link_libraries (echoserver ${CMAKE_THREAD_LIBS_INIT}) endif() set (EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/bin) 当外层CMakeLists通过add_subdirectory(./src)进入内层CMakeLists时，就开始执行内层CMakeLists，直到处理完才回到外层CMakeLists。\n在内层CMakeLists，我们首先定义了CLIENT_SRC_LIST和SERVER_SRC_LIST两个变量，前者指明了编译客户端所需的源文件，后者则指定了编译服务端需要的源文件。\n接下来的include_directories (../include)指明该项目所需头文件的路径。\n在接下来就比较重要了，因为echo项目用到了多线程，所以编译时需要加上-lpthread这个选项，当我们用gcc直接编译时，应该这样：\n1 gcc -o echoclient csapp.c echoclient.c -lpthread 但是，用CMake时，发生一些变化。我们需要用find_package(Threads)来寻找线程库。\n接下来是if-else语句，如果CLIENT是ON的，则生成名为echoclient的客户端可执行文件，其依赖文件为CLIENT_SRC_LIST变量包含的源文件列表。否则，生成名为echoserver的服务端可执行文件，其依赖文件为SERVER_SRC_LIST变量包含的源文件列表。target_link_libraries命令负责将目标文件与库文件进行链接，这里的库文件就是Threads库。\n最后一条语句就是设置可执行文件输出路径，前边已解释过。\n测试 加上这两个CMakelists之后，我们的项目组织结构图如下。\n我们进入build文件夹进行构建测试。在build文件夹内输入以下命令\n1 2 3 4 cmake .. make cmake .. -DCLIENT=OFF make ","date":"2024-10-13T02:26:15-07:00","permalink":"https://bitdove.github.io/posts/build-echo-project-with-cmake/","title":"如何使用CMake构建项目？"},{"content":"命令格式 1 include_directories ([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...]) 将指定目录添加到编译器的头文件搜索路径之下，指定的目录被解释成当前源码路径的相对路径。\n命令解析 默认情况下，include_directories命令会将目录添加到列表最后，可以通过命令设置CMAKE_INCLUDE_DIRECTORIES_BEFORE变量为ON来改变它默认行为，将目录添加到列表前面。也可以在每次调用include_directories命令时使用AFTER或BEFORE选项来指定是添加到列表的前面或者后面。如果使用SYSTEM选项，会把指定目录当成系统的搜索目录。该命令作用范围只在当前的CMakeLists.txt。\ninclude_directories命令的基本行为 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #CMakeLists.txt cmake_minimum_required(VERSION 3.18.2) project(include_directories_test) include_directories(sub) include_directories(sub2) #默认将sub2添加到列表最后 include_directories(BEFORE sub3) #可以临时改变行为，添加到列表最前面 get_property(dirs DIRECTORY ${CMAKE_SOURCE_DIR} PROPERTY INCLUDE_DIRECTORIES) message(\u0026#34;\u0026gt;\u0026gt;\u0026gt; include_dirs=${dirs}\u0026#34;) #打印一下目录情况 set(CMAKE_INCLUDE_DIRECTORIES_BEFORE ON) #改变默认行为，默认添加到列表前面 include_directories(sub4) include_directories(AFTER sub5) #可以临时改变行为，添加到列表的最后 get_property(dirs DIRECTORY ${CMAKE_SOURCE_DIR} PROPERTY INCLUDE_DIRECTORIES) message(\u0026#34;\u0026gt;\u0026gt;\u0026gt; SET DEFAULT TO BEFORE, include_dirs=${dirs}\u0026#34;) 1 2 3 #输出 \u0026gt;\u0026gt;\u0026gt; include_dirs=/XXX/XXX/sub3;/XXX/XXX/sub;/XXX/XXX/sub2 \u0026gt;\u0026gt;\u0026gt; SET DEFAULT TO BEFORE, include_dirs=/XXX/XXX/sub4;/XXX/XXX/sub3;/XXX/XXX/sub;/XXX/XXX/sub2;/XXX/XXX/sub5 结合实际说明用法 创建的文件和目录结构及说明如下：\n1 2 3 4 ├── CMakeLists.txt #最外层的CMakeList.txt ├── main.cpp #源文件，包含被测试的头文件 ├── sub #子目录 └── test.h #测试头文件，是个空文件，被外层的main,cpp包含 场景1：不使用include_directories包含子目录sub,直接在main.cpp里面包含\u0026quot;test.h\u0026quot;。 1 2 3 4 # CMakeList.txt cmake_minimum_required(VERSION 3.18.2) project(include_directories_test) add_executable(test main.cpp) 1 2 3 4 5 6 7 8 //main.cpp #include \u0026#34;test.h\u0026#34; #include \u0026lt;stdio.h\u0026gt; int main(int argc, char **argv) { printf(\u0026#34;hello, world!\\n\u0026#34;); return 0; } 执行cmake --build .，会提示找不到头文件的错误:\n1 2 fatal error: \u0026#39;test.h\u0026#39; file not found #include \u0026#34;test.h\u0026#34; 场景2：使用include_directories包含子目录sub,并在main.cpp里面包含\u0026quot;test.h\u0026quot;。 1 2 3 4 5 # CMakeList.txt cmake_minimum_required(VERSION 3.18.2) project(include_directories_test) include_directories(sub) #与上个场景不同的地方在于此处 add_executable(test main.cpp) 1 2 3 4 5 6 7 8 //main.cpp #include \u0026#34;test.h\u0026#34; #include \u0026lt;stdio.h\u0026gt; int main(int argc, char **argv) { printf(\u0026#34;hello, world!\\n\u0026#34;); return 0; } 执行cmake --build .，会生成可执行文件test，使用./test执行后会输出打印hello, world!。\n当然，不使用include_directories(sub)，在main.cpp中直接使用#include \u0026quot;sub/test.h\u0026quot;也是可以的。\n","date":"2024-10-13T02:23:23-07:00","permalink":"https://bitdove.github.io/posts/cmake-include-directories/","title":"【CMake命令】include_directories"},{"content":"const关键字 const即constan的缩写，即不变的，被const修饰之后，相当于程序员告诉编译器：这个值是不变的，你处理的时候注意着点儿。const关键字的核心是ReadOnly，即“只读”。\nconst可以修饰内置类型变量、自定义的类对象、类的成员函数、函数的返回值、函数的参数。\nconst修饰普通变量 1 2 3 const int a = 8; int b = a; //Correct a = 9; //Fault 编译器会把a认定为常量，其值不可被改变，所以对它赋值是错误的。\nconst修饰指针变量 const修饰指针变量有三种情况：\nconst修饰指针指向的内容，即指针所指地址中的内容不可变。 const修饰指针本身，即指针所指向的地址不可变。 const同时修饰指针和指针指向的内容，即二者皆不可变。 1 const int *p = 8; 由内向外看，*表示p是一个指针；const int表示p指针指向一个int型常量，综合起来就是p是一个常量指针。即p指针指向的这个地址存的是个8，这个值不能变，但是p可以指向其他的地址。\n1 2 int a = 8; int* const p = \u0026amp;a; 由内而外看，const表示p是一个常量，这已经说明它自身的值是不变的；int*表示p是一个指向int型变量的指针；所以，综合起来，p是一个指向int型变量的指针常量。即p指向的地址是不可变的，但这段地址存放的内容是可以变的。\n1 2 int a = 8; const int* const p = \u0026amp;a; 依旧由内而外看，const表示p是一个常量；const int*表示p是一个指向int型常量的指针；综合起来，p是一个指向int型常量的指针常量。即p指向的地址以及它指向的地址中存放的内容均为不可变的。\n总结：*左边的const表示内容不变；*右边的const表示地址不变。\u000b常量指针：指向常量的指针，即其指向的地址中的内容不变。\n指针常量：指针本身是常量，即其指向地址不变。\nconst修饰函数参数 const修饰函数参数也分三种情况：\n对于值传递的函数，一般这种情况不需要 const 修饰，因为函数会自动产生临时变量复制实参值。\n1 2 3 4 5 6 7 8 9 include \u0026lt;iostream\u0026gt; void ValueTransfer(const int a){ ++a; std::cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; std::endl; } int main(){ ValueTransfer(8); return 0; } 上边这段程序用g++编译时报错：\n1 2 3 const_test.cpp: In function ‘void ValueTransfer(int)’: const_test.cpp:3:4: error: increment of read-only parameter ‘a’ ++a; 对只读的参数a进行自增操作是非法的，编译直接不通过。\n当 const 参数为指针时，可以防止指针被意外篡改。\n1 2 3 4 5 6 7 8 9 10 11 #include\u0026lt;iostream\u0026gt; void Test(int *const a){ std::cout \u0026lt;\u0026lt; *a \u0026lt;\u0026lt; std::endl; //a为8 *a = 9; } int main(void){ int a = 8; Test(\u0026amp;a); std::cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; std::endl; // a为9 return 0; } 自定义类型的参数传递，需要临时对象复制参数，对于临时对象的构造，需要调用构造函数，比较浪费时间，因此我们采取 const 外加引用传递的方法。\n按值传递对象需要复制所有对象成员的副本，这可能会减慢程序的执行时间，如果对象有很多成员，则更是如此。另一方面，当按引用传递对象时，由于该函数可以访问原始对象，而不必进行任何复制，所以它比通过值传递更快，正因为如此，一般更愿意按引用传递对象。\n但是，按引用传递对象有一个缺点，因为该函数可以访问原始对象，所以它可以调用其成员函数更改对象成员数据。这就是为什么当程序员想要保护对象的内容时，通常不会按引用传递变量。\n幸运的是这个问题有解决办法。为了保护对象让它作为实参传递，而又不必复制副本，可以将它作为常量引用进行传递，这意味着原始对象作为引用被传递给了函数，但是它不能调用没有const修饰的成员函数或更改对象的成员数据，它只能调用自己被指定为const函数的成员函数。\nconst修饰函数返回值 const修饰函数返回值也分三种情况：\nconst 修饰内置类型的返回值，修饰与不修饰返回值没什么区别。 const 修饰自定义类型的作为返回值，此时返回的值不能作为左值使用，既不能被赋值，也不能被修改。 const 修饰返回的指针或者引用，是否返回一个指向 const 的指针，取决于我们想让用户干什么。 const修饰类的成员函数 const 修饰类成员函数，其目的是防止成员函数修改被调用对象的值，如果我们不想修改一个调用对象的值，所有的成员函数都应当声明为 const 成员函数。\nconst 关键字不能与 static 关键字同时使用，因为 static 关键字修饰静态成员函数，静态成员函数不含有 this 指针，即不能实例化，const 成员函数必须具体到某一实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include\u0026lt;iostream\u0026gt; class Test{ public: Test(){} Test(int _m):_cm(_m){} int get_cm() const{ return _cm; } private: int _cm; }; void Cmf(const Test\u0026amp; _tt){ std::cout \u0026lt;\u0026lt; _tt.get_cm(); //输出8 } int main(void){ Test t(8); Cmf(t); return 0; } 如果 get_cm() 去掉 const 修饰，g++编译时提示以下错误:\n1 2 3 const_test.cpp: In function ‘void Cmf(const Test\u0026amp;)’: const_test.cpp:13:29: error: passing ‘const Test’ as ‘this’ argument of ‘int Test::get_cm()’ discards qualifiers [-fpermissive] std::cout \u0026lt;\u0026lt; _tt.get_cm(); Cmf 传递的 const _tt 即使没有改变对象的值，编译器也认为函数会改变对象的值，进而编译不通过。所以我们尽量按照要求将所有的不需要改变对象内容的函数都作为 const 成员函数。\n如果有个成员函数想修改对象中的某一个成员怎么办？这时我们可以使用 mutable 关键字修饰这个成员，mutable 的意思也是易变的，容易改变的意思，被 mutable 关键字修饰的成员可以处于不断变化中。\nconst修饰函数形参 值传递pass by value 值传递时，被调函数只是获得了来自主调函数的实参的一个副本，相当于把实参值赋给形参，这个形参就变成了被调函数里的一个局部变量，与主调函数之后再无联系，不管你被调函数里怎么折腾这个局部变量，都不会影响到主调函数内的实参。\n这种情况，函数形参用不用const修饰其实区别不大，因为值传递本来就不会改变实参本身。\n如果函数内部不会有改变形参值的操作，也可以加const，但这只是强调这个函数内部不会改变形参的值，同时也确保形参值不会被意外改变。\n如果函数是需要改变形参值的，那自然是不能加const了，加了无法通过编译。\n指针传递pass by pointer 1 2 3 4 5 6 7 void fun(int* p){ *p = 20; } void main(){ int a = 10; fun(\u0026amp;a); } 指针传递本质仍旧是值传递，无非传递的值是地址而已。\n就像上边这个例子，取a的地址作为实参传递给fun函数，其形参p也就指向了a的地址。无论你在fun内部对p进行什么操作，你都无法改变实参a的地址。但是fun函数可以通过获得的a的地址来改变a的内容，如上，a的值会变成20。\n这种情况，如果在*右边加一个const，那p就是指针常量，在fun函数内就不能有改变p指向的操作，同时也可以防止指针被意外改变；如果在*左边加一个const，那p就是指向常量的指针，也就无法在fun内通过解引用p来改变a的值了。\n引用传递pass by reference 1 2 3 4 5 void fun(int \u0026amp;a){...} void main(){ int b = 10; fun(b); } 引用传递其实是给实参起了一个别名，在被调函数内部可以通过操作这个别名来改变实参。\n引用本身不是一个对象，引用在定义之后也没办法改变它绑定的对象，而const是修饰对象的，所以对于引用而言，const只能出现在\u0026amp;左边，而不能出现在右边。\nconst int \u0026amp;a;表示a是一个整型常量的别名。\n这种内置类型的形参，加不加const区别不大，如果函数内不会有改变形参值的操作，可以加const，但加了也只是强调函数内部不会改变实参的值，同时也保证实参值不被意外改变。\n但对于类类型的形参而言，按值传递对象需要复制所有对象成员的副本，这可能会减慢程序的执行时间，如果对象有很多成员，则更是如此。另一方面，当按引用传递对象时，由于该函数可以访问原始对象，而不必进行任何复制，所以它比通过值传递更快，正因为如此，一般更愿意按引用传递对象。\n但是，按引用传递对象有一个缺点，因为该函数可以访问原始对象，所以它可以调用其成员函数更改对象成员数据。这就是为什么当程序员想要保护对象的内容时，通常不会按引用传递变量。\n幸运的是这个问题有解决办法。为了保护对象让它作为实参传递，而又不必复制副本，可以将它作为常量引用进行传递，这意味着原始对象作为引用被传递给了函数，但是它不能调用没有const修饰的成员函数或更改对象的成员数据，它只能调用自己被指定为const函数的成员函数。\n","date":"2024-10-13T02:22:13-07:00","permalink":"https://bitdove.github.io/posts/cpp-const/","title":"【一文读懂】C++中的const关键字"},{"content":"new expression 分配内存-调用构造函数-返回指针\nThe new operator is an operator which denotes a request for memory allocation on the Heap. If sufficient memory is available, new operator initializes the memory and returns the address of the newly allocated and initialized memory to the pointer variable. When you create an object of class using new keyword(normal new).\nThe memory for the object is allocated using operator new from heap. The constructor of the class is invoked to properly initialize this memory. operator new 只分配内存-返回指针/抛出异常\nOperator new is a function that allocates raw memory and conceptually a bit similar to malloc().\nIt is the mechanism of overriding the default heap allocation logic. It doesn’t initializes the memory i.e constructor is not called. However, after our overloaded new returns, the compiler then automatically calls the constructor also as applicable. It’s also possible to overload operator new either globally, or for a specific class New operator vs operator new Operator vs function: new is an operator as well as a keyword whereas operator new is only a function. New calls “Operator new”: “new operator” calls “operator new()” , like the way + operator calls operator +() “Operator new” can be Overloaded: Operator new can be overloaded just like functions allowing us to do customized tasks. Memory allocation: ‘new expression’ call ‘operator new’ to allocate raw memory, then call constructor. References ","date":"2024-09-30T09:52:09+08:00","permalink":"https://bitdove.github.io/posts/things-about-new/","title":"【一文读懂】C++ new那些事儿"},{"content":"前言 本文待完善。\n整体思路 使用Hugo作为博客框架，在本地编写Markdown文件，构成博客站点源码库。将源码库上传至GitHub仓库Hugoblog，并设置GitHub Action，由GitHub Action运行hugo命令生成博客HTML文件并上传至bitdove.github.io，最终由GitHub Pages完成部署。\n所以需要两个GitHub仓库。\nHugoblog：用于存储站点源码。 bitdove.github.io：用于存储生成的HTML文件。 Hugo安装与配置 参考Hugo官方文档，根据操作系统选择安装方式。本文以macOS为例。\n前提 Hugo依赖Git和Go，所以要先安装这两个。\n不展开讲了。\n安装hugo 本文采用Homebrew的安装方式\n1 brew install hugo 安装结束，执行以下命令，看到版本号说明安装成功。\n1 hugo version 新建站点 在你希望的位置执行下面的命令，新建一个Hugo站点。\n1 hugo new site HugoBlog 这样会出现一个名为HugoBlog的文件夹，这就是博客源码。\n选择主题 在官方主题库选择一个主题，当然也可以去GitHub找官方主题库里没有的主题。本文选择Stack主题。\n本文选择Git Submodule的方式安装。\n1 2 3 cd Hugoblog git init git submodule add https://github.com/CaiJimmy/hugo-theme-stack/ themes/hugo-theme-stack 这样theme文件夹下就会出现该主题。我想让我的博客跟Stack主题提供的Demo站点一样，所以做了一下事情。\n把Hugoblog/themes/Hugo-theme-stack/exampleSite/content/下的内容复制到Hugoblog/content/。 删除Hugoblog/hugo.toml，把Hugoblog/themes/Hugo-theme-stack/Hugo.yaml复制到Hugoblog/。 这样执行以下命令，在本地预览，发现已经跟Demo一致。\n1 hugo server -D 配置博客 各种个性化配置，包括该博客名称、换头像、改链接、去除自己不需要的多语言支持等等，在hugo.yaml中配置。\n删除默认博文、删除默认分类和标签、修改博文默认模版等等。\n不展开说了。\nGitHub Actions Push to GitHub 接下来就是把整个文件夹推到GitHub，在GitHub新建一个仓库Hugoblog。把本地的Hugoblog文件夹推到这个仓库。不细说了。\n之后，因为我们以后写文章、更新博客，都是要推这个文件夹，所以写一个脚本更方便，在Hugoblog下新建一个名为deploy.sh的脚本文件，把以下内容复制粘贴过去。这样以后写完md文件，直接执行./deploy.sh就完成部署了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #!/bin/bash # Check if the directory /public exists if [ -d \u0026#34;./public\u0026#34; ]; then # If it exists, delete the directory rm -rf ./public echo \u0026#34;./public directory has been deleted.\u0026#34; else # If it doesn\u0026#39;t exist, print a message echo \u0026#34;./public directory does not exist.\u0026#34; fi # Check if a commit message was provided as an argument if [ -z \u0026#34;$1\u0026#34; ]; then # If no commit message is provided, use the current date and time COMMIT_MSG=\u0026#34;Update at $(date)\u0026#34; else # Use the provided commit message COMMIT_MSG=\u0026#34;$1\u0026#34; fi # Add all changes git add . # Commit changes with the provided message git commit -m \u0026#34;$COMMIT_MSG\u0026#34; # Push changes to the \u0026#39;main\u0026#39; branch git push origin main # Print a success message echo \u0026#34;Changes have been pushed to GitHub successfully!\u0026#34; 因为我们想这个库只保存源码，所以生成的静态HTML文件我们不要，所以在上传之前先检测有无/public文件夹，有的话删掉再上传。\nDeploy Key 在本地用sshkeygen生成一对key\n公钥给bitdove.github.io的Deploy key\n私钥给Hugoblog的Actions的secrets。\nHugoblog的Workflow permissions改为Read and write permissions\nGitHub Actions 给Hugoblog添加Actions\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 name: Deploy Hugo to GitHub Pages on: push: branches: - main # Trigger deployment when changes are pushed to the main branch jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout the repository uses: actions/checkout@v2 with: submodules: true - name: Set up Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.134.2\u0026#39; extended: true - name: Build the website run: hugo - name: Deploy to GitHub Pages uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.DEPLOY_KEY }} publish_dir: ./public # This is the directory where Hugo generates static files external_repository: bitdove/bitdove.github.io publish_branch: main GitHub图床 每个repo有1G的大小限制，如果把图片也传到博客仓库，很快就会满。\n在GitHub新建一个图床库PicsBed_1\n生成一个Token，选public_repo\n安装PicGo，设置Token。\n为PicsBed_1添加Actions如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 name: Update README with Directory Structure on: push: branches: - main jobs: update-readme: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 - name: Generate directory structure run: | echo \u0026#34;# Directory Structure\u0026#34; \u0026gt; structure.txt echo \u0026#34;\\`\\`\\`\u0026#34; \u0026gt;\u0026gt; structure.txt tree -I \u0026#34;.git|node_modules|structure.txt\u0026#34; \u0026gt;\u0026gt; structure.txt echo \u0026#34;\\`\\`\\`\u0026#34; \u0026gt;\u0026gt; structure.txt - name: Update README run: | cat structure.txt \u0026gt; README.md - name: Commit changes run: | git config --local user.name \u0026#34;GitHub Action\u0026#34; git config --local user.email \u0026#34;action@github.com\u0026#34; git add README.md git commit -m \u0026#34;Update directory structure in README\u0026#34; git push env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} References Hugo官方文档 Stack主题官方网站 Stack主题官方GitHub仓库 图片上传工具PicGo官网 图片上传工具PicGo官方GitHub仓库 ","date":"2024-09-20T15:18:02+08:00","permalink":"https://bitdove.github.io/posts/build-your-blog/","title":"Hugo + GitHub Pages搭建个人博客"},{"content":" 免责声明： 本文所述内容仅供技术学习和研究使用，不构成任何形式的非法行为指导。请读者严格遵守所在地区的法律法规，自行判断和承担使用相关技术可能带来的风险。作者不对因使用本文内容而产生的任何法律责任承担责任。\nPreface As we all know, overseas websites like Google and Twitter cannot be directly accessed in mainland China. We also know that you can access these websites by connecting to a VPN. As for the details, most people don\u0026rsquo;t know, and there is really no need to know. But one thing we must understand is that an important reason why VPN can work is that GFW does not block all overseas websites. It is for this reason that we can find loopholes to exploit.\nTechnically speaking, VPN ≠ circumventing the Great Firewall. However, in mainland China, VPN has become synonymous with circumventing the Great Firewall, so I won’t go into details here.\nOn the Internet, IP addresses are our \u0026ldquo;identity cards\u0026rdquo;. These banned overseas websites also have their own IP addresses, but unfortunately they are blocked by GFW, so we cannot access them directly. There are still some IP addresses that are not blocked and we can access them. A series of wall-climbing technologies are built on this basis.\nAssume there is an IP address A, which is not blocked by GFW, and as a member of the Internet, A can access those blocked websites. We can send the request to access Google to A, and A will help us access it and then send the result to us. This is the principle of Proxy, and it is also the basis for a series of wall-circumvention technologies to be realized.\nBuy a VPS First of all, we need an IP address that is not blocked. Purchasing an overseas VPS can meet this requirement. A VPS is actually a cloud server located overseas.\nThere are many VPS providers, such as BandWagon, Vultr, CloudCone, etc. This article takes Vultr as an example, and other manufacturers are similar.\nRegister and log in to Vultr, click the Deploy button in the upper right corner and follow the steps below to deploy a VPS.\nChoose VPS Type and Location Select Shared CPU as the type.\nThe location depends on your needs. Here we take Los Angeles, USA as an example.\nSelect System Image Choose an operating system. For a server, you should naturally choose Linux. Debian is recommended as it is more stable.\nChoose a Plan Choose a configuration based on your needs. The higher the configuration, the more expensive it is. Here we choose the cheapest plan of 5$/month.\nOther Configs Remove Auto Backups, it costs money.\nRemove IPv6, it is not needed.\nHere you can upload the SSH key and transfer the public key of your local computer ~/.ssh/ to Vultr. In this way, you can log in directly with the key after the deployment is completed without entering a password, which is much more convenient.\nSet the host name in Server Hostname. You can give it a name of your own. This article takes Test as an example.\nPlace an order Now it’s ready. Confirm the quantity and price, and click Deploy Now to start deployment.\nThe deployment process may take several minutes, so be patient.\nDeployment Completed When the Status changes to Running, the deployment is complete. The coded part is the public IP address of this VPS, which is represented by 100.200.300.400 below.\nCheck if the IP is blocked Enter your IP address in Webmaster Tools - Ping Detection and click Ping Detection. If most of the information is green, it means that your IP address is not blocked and you can use it with confidence.。\nIf it is all red, it means that this IP address has been blocked and cannot be used. According to the policy of your VPS manufacturer, find a way to change the IP until it is available.\nConfiguring the VPS SSH login to VPS To configure your VPS, first log in to your VPS via SSH. Open your terminal tool and enter the following command to log in to your VPS.\n1 ssh root@100.200.300.400 SSH logging into a Linux server is a basic operation and will not be explained in detail.\nUpdate Update your package index and then upgrade all installed packages to their latest versions, ensuring your system is up to date with the latest features and security patches.\n1 2 apt update apt upgrade Enable ufw firewall The first thing to do after logging in is to enable the ufw firewall. First, confirm whether ufw has been installed. Execute the following command. If the ufw version number is returned, it means it has been installed.\n1 ufw --version If ufw is not installed, install it yourself.\nRun the following command to configure ufw.\n1 2 3 4 5 6 7 8 9 10 11 # Setting ufw defaults sudo ufw default deny incoming sudo ufw default allow outgoing # Allow SSH connections sudo ufw allow ssh # Allow HTTP connections sudo ufw allow http # Allow HTTPS connections sudo ufw allow https # Startup sudo ufw enable Other common ufw commands：\n1 2 3 4 5 6 7 # Check ufw status sudo ufw status # ufw status output with line number, and delete a line sudo ufw status numbered sudo ufw delete 5 # Reload ufw configuration sudo ufw reload Change SSH default port Open an editor such as nano or vim and open the file /etc/ssh/sshd_config 1 nano /etc/ssh/sshd_config Find the item Port in the opened file, remove the comment symbol #, and change 22 to the new port number (1025-65535). This article takes 9753 as an example. Restart the ssh service for the changes to take effect. 1 service sshd restart Open new port number on firewall 1 ufw allow 9753/tcp comment \u0026#34;SSH\u0026#34; Delete the original port 22 in the firewall. The figure below deletes 22/tcp. Use the same method to delete 22/tcp(v6). Test the new port number login\nNote: To ensure that you do not lose connection, please do not close the current ssh login window! Instead, open another window to test!\nIn a new terminal window, log in to the VPS using the new port number.\n1 ssh root@100.200.300.400 -p 9753 Set up key-only login Upload the public key to the VPS. 1 2 3 4 5 6 7 8 # Create a new .ssh folder in your home directory mkdir ~/.ssh # Modify the .ssh folder permissions chmod 700 ~/.ssh # Upload the public key. Replace the content in quotation marks with the public key value echo \u0026#34;Your public key content\u0026#34; \u0026gt;\u0026gt; ~/.ssh/authorized_keys # Modify the permissions of the authorized_keys file chmod 600 ~/.ssh/authorized_keys Disable password login 1 nano /etc/ssh/sshd_config Find the item PasswordAuthentication, uncomment it and change it to no, then save and exit.\nFor some systems, it is useless to change only this one, and you also need to change the following one. If the system does not have this file, ignore this step.\n1 nano /etc/ssh/sshd_config.d/50-cloud-init.conf Similarly, uncomment the PasswordAuthentication option and change it to no, then save and exit.\nRestart the ssh service for the changes to take effect. 1 service sshd restart Test key login. Open a new terminal and log into the VPS using the following command.\n1 ssh -i path/to/yourprivatekeyname -p 9753 root@100.200.300.400 Change path/to/yourprivatekeyname to the path of the private key corresponding to the public key used by the VPS. Usually it is under ~/.ssh/.\nCreate a new common user Execute the following command to create a new user. Follow the prompts to complete the process. 1 adduser leo Give the new user a name. This article uses leo as an example.\nAdd new user leo to sudo. 1 visudo Give the public key to the new user. 1 2 3 4 5 6 7 8 9 10 # Switch to new user leo su leo # Create a .ssh folder in the home directory of the new user leo mkdir ~/.ssh # Modify the .ssh folder permissions chmod 700 ~/.ssh # Upload the public key. Replace the content in quotation marks with the public key value echo \u0026#34;公钥内容\u0026#34; \u0026gt;\u0026gt; ~/.ssh/authorized_keys # Modify the permissions of the authorized_keys file chmod 600 ~/.ssh/authorized_keys This way new users can log in using the key.\nDisable root login Open /etc/ssh/sshd_config, find the item PermitRootLogin, uncomment it and change yes to no.\n1 sudo nano /etc/ssh/sshd_config Restart the sshd service for the changes to take effect.\n1 sudo service sshd restart In this way, the root user will not be able to log in, and the leo user will be used to manage the VPS in the future.\nInstall Fail2Ban 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Install Fail2Ban sudo apt update \u0026amp;\u0026amp; sudo apt install fail2ban # Create a configuration file sudo nano /etc/fail2ban/jail.local # Paste the following into the open file ******Begin of pasting content****** [sshd] enabled = true port = 9753 filter = sshd logpath = /var/log/auth.log maxretry = 5 bantime = 7200 findtime = 600 ******End of pasting content****** # Start Fail2Ban sudo systemctl start fail2ban The above configuration means that an IP address that attempts to log in to ssh five times within 600 seconds will be sentenced to 7200 seconds in prison.\nFail2Ban common commands:\n1 2 3 4 5 6 7 8 9 10 11 12 # Restart Fail2Ban sudo systemctl restart fail2ban # Check fail2ban status sudo systemctl status fail2ban # Set Fail2Ban to start at boot sudo systemctl enable fail2ban # Check fail2ban-client status sudo fail2ban-client status # Check sshd jail status sudo fail2ban-client status sshd # Unban the specified IP sudo fail2ban-client set sshd unbanip 192.0.0.1 At this point, the VPS security configuration has been completed. The next step is to actually build a proxy.\nXray installation and configuration It is not recommended to use any third-party one-click scripts. Who knows if there is anything hidden in them? The official documentation is detailed enough and the installation and configuration are simple enough. For details of this part, please refer to Official Documentation。\nInstall Xray The GitHub repository Xray-install is the installation method provided by Xray official. The official installation script can be found on the repository\u0026rsquo;s README page:\n1 bash -c \u0026#34;$(curl -L https://github.com/XTLS/Xray-install/raw/main/install-release.sh)\u0026#34; @ install This command is also used to update the new version later.\nOne-click installation, simple enough.\nConfig Xray Generate a valid UUID and save it for future use (UUID can be roughly understood as an ID that is almost never repeated, like a fingerprint).\n1 xray uuid This uuid should be retained and will be used in the subsequent configuration.\nModify the Xray configuration file.\n1 sudo nano /usr/local/etc/xray/config.json Paste the following content. You only need to modify port and id. In this article, port takes 12345 as an example, and id takes the one generated in the previous step as an example.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # The original version, VMess+Kcp, cannot access the ChatGPT client { \u0026#34;log\u0026#34;: { \u0026#34;loglevel\u0026#34;: \u0026#34;warning\u0026#34;, \u0026#34;access\u0026#34;: \u0026#34;/var/log/xray/access.log\u0026#34;, // This is the path for Linux \u0026#34;error\u0026#34;: \u0026#34;/var/log/xray/error.log\u0026#34; }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;port\u0026#34;: 12345, // Server listening port \u0026#34;protocol\u0026#34;: \u0026#34;vmess\u0026#34;, // Main Incoming Protocol \u0026#34;settings\u0026#34;: { \u0026#34;clients\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;0061c282-49f7-41d7-b223-0a9b6d8675dd\u0026#34;, // uuid，The client and server must be the same \u0026#34;alterId\u0026#34;: 0 } ] }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;kcp\u0026#34;, //Here, kcp can also be written as mkcp. Both writing methods have the same effect. \u0026#34;kcpSettings\u0026#34;: { \u0026#34;uplinkCapacity\u0026#34;: 15, \u0026#34;downlinkCapacity\u0026#34;: 100, \u0026#34;congestion\u0026#34;: true, \u0026#34;readBufferSize\u0026#34;: 1, \u0026#34;writeBufferSize\u0026#34;: 1, \u0026#34;header\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;wireguard\u0026#34; } } } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34;, // Main Outgoing Protocol \u0026#34;settings\u0026#34;: {} } ] } Open the port number specified in the configuration file.\n1 2 sudo ufw allow 12345/tcp comment \u0026#34;Xray\u0026#34; sudo ufw allow 12345/udp comment \u0026#34;Xray\u0026#34; Start Xray\n1 2 3 4 5 6 # Start Xray sudo systemctl start xray # Set Xray to start at boot sudo systemctl enable xray # Check Xray status sudo systemctl status xray When you see the green active(running) as shown in the figure below, it means that Xray has been successfully started and the server is configured.\nEnable BBR acceleration.\nAdd the official backports repository for Debian 10 to get updated software repositories.\n1 sudo nano /etc/apt/sources.list Then add the following line at the end, save and exit.\n1 deb http://archive.debian.org/debian buster-backports main Refresh the software repository and query the latest version of the official Debian kernel and install it. Please be sure to install the version corresponding to your VPS (this article takes the more common [amd64] as an example).\n1 sudo apt update \u0026amp;\u0026amp; sudo apt -t buster-backports install linux-image-amd64 Modify the kernel parameter configuration file sysctl.conf and enable BBR.\n1 sudo nano /etc/sysctl.conf Add the following content\n1 2 net.core.default_qdisc=fq net.ipv4.tcp_congestion_control=bbr Reboot the VPS to take effect of the kernel update and the BBR configuration.\n1 sudo reboot Make sure BBR is enabled.\n1 lsmod | grep bbr At this point, a result like tcp_bbr should be returned.\nIf you want to confirm that the fq algorithm is enabled correctly, you can use the following command:\n1 lsmod | grep fq At this point, a result like sch_fq should be returned.\nConfigure the client.\nAfter the server configuration is finished, the next step is to configure your client. The configuration method varies depending on the proxy tool used by the client. But they are all based on the server configuration. The main thing is to configure IP:Port and uuid to be consistent with the server.\nI won’t go into detail about the client configuration.\nIn this way, you can access the Internet scientifically. You just cannot use the ChatGPT client because ChatGPT blocks the IPs of these VPS manufacturers.\nWarp Unlock ChatGPT Client ChatGPT blocks the IP addresses of VPS vendors, but Cloudflare\u0026rsquo;s Warp can provide us with IP addresses, so we use the IP addresses provided by Warp to access ChatGPT. However, the IPv4 addresses provided by Warp have been abused and cannot access the ChatGPT client, so we use Warp IPv6. The goal is to use the public IPv4 address of the VPS when accessing ordinary websites, and use the IPv6 address of Warp when accessing ChatGPT.\nExecute the following script to install WGCF.\n1 wget -N https://gitlab.com/fscarmen/warp/-/raw/main/menu.sh \u0026amp;\u0026amp; bash menu.sh Select the language as needed. This article selects Chinese.\nBecause our VPS is an IPv4 only machine and does not have an IPv6 address, we only need Warp to provide an IPv6 address, so choose 2. Add a Warp IPv6 network interface for IPv4 only.\nSelect 1. Global (default) as the working mode.\nSelect the account type. Choose according to your needs. I have the team version of WARP, which is Zero Trust, so I choose 3. Teams.\nThe next step is to log in to the selected account. Teams account selection 2. It is more convenient to log in by organization name and email verification code.\nSelect 3 for priority level. Use the VPS initial settings (default).\nWGCF will start installing. Wait for the installation to complete and run the following command. You can see that there is a network card called warp.\n1 sudo ifconfig This way the VPS has an IPv6 address.\nModify the Xray configuration file\n1 sudo nano /usr/local/etc/xray/config.json Overwrite with the following content. Replace the IPv4 address with your VPS public IPv4 address, and replace the IPv6 address with the address of the warp network card. Also replace uuid and port with your own. Leave the rest unchanged.\n2025/07/18添加色情屏蔽规则。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 # Warp takes over IPv6 traffic version, VMess+Kcp, unlocks ChatGPT client { \u0026#34;log\u0026#34;: { \u0026#34;loglevel\u0026#34;: \u0026#34;warning\u0026#34;, \u0026#34;access\u0026#34;: \u0026#34;/var/log/xray/access.log\u0026#34;, // This is the path for Linux \u0026#34;error\u0026#34;: \u0026#34;/var/log/xray/error.log\u0026#34; }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;port\u0026#34;: 12345, // Server listening port \u0026#34;protocol\u0026#34;: \u0026#34;vmess\u0026#34;, // Main Incoming Protocol \u0026#34;settings\u0026#34;: { \u0026#34;clients\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;0061c282-49f7-41d7-b223-0a9b6d8675dd\u0026#34;, // uuID，The client and server must be the same \u0026#34;alterId\u0026#34;: 0 } ] }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;kcp\u0026#34;, //Here, kcp can also be written as mkcp. Both writing methods have the same effect. \u0026#34;kcpSettings\u0026#34;: { \u0026#34;uplinkCapacity\u0026#34;: 15, \u0026#34;downlinkCapacity\u0026#34;: 100, \u0026#34;congestion\u0026#34;: true, \u0026#34;readBufferSize\u0026#34;: 1, \u0026#34;writeBufferSize\u0026#34;: 1, \u0026#34;header\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;wireguard\u0026#34; } } } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34;, // Main Outgoing Protocol \u0026#34;settings\u0026#34;: { \u0026#34;domainStrategy\u0026#34;: \u0026#34;UseIPv4\u0026#34; }, \u0026#34;sendThrough\u0026#34;: \u0026#34;100.200.300.400\u0026#34; // VPS public IPv4 address }, { \u0026#34;tag\u0026#34;: \u0026#34;warp\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;domainStrategy\u0026#34;: \u0026#34;UseIPv6\u0026#34; }, \u0026#34;sendThrough\u0026#34;: \u0026#34;2606:4700:110:88b8:5141:4387:4a3:20d1\u0026#34; // warp network card IPv6 address }, { \u0026#34;tag\u0026#34;: \u0026#34;block\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;blackhole\u0026#34; } ], \u0026#34;routing\u0026#34;: { \u0026#34;rules\u0026#34;: [ { \u0026#34;domain\u0026#34;: [ \u0026#34;geosite:openai\u0026#34;, \u0026#34;geosite:bing\u0026#34;, \u0026#34;geosite:netflix\u0026#34; ], \u0026#34;outboundTag\u0026#34;: \u0026#34;warp\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34; }, { \u0026#34;domain\u0026#34;: [ \u0026#34;geosite:category-porn\u0026#34; // block porn ], \u0026#34;outboundTag\u0026#34;: \u0026#34;block\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34; } ] } } Restart Xray and confirm that Xray has run successfully.\n1 2 sudo systemctl start xray sudo systemctl status xray Connect to the node on the client and you will find that the ChatGPT client can be used normally.\nReferences Project X official documentation 保护好你的小鸡！保姆级服务器安全教程！ vps 解锁 chatgpt 注册Cloudflare并加入ZeroTrust教程 ","date":"2024-09-18T16:26:03+08:00","permalink":"https://bitdove.github.io/posts/how-to-build-proxy-with-xray/","title":"【Proxy】How to Build Proxy with Xray"},{"content":"什么是ARP？ ARP是Address Resolution Protocol的首字母缩写，即地址解析协议。\n如果一台主机要将一个帧发送到另一台主机，只知道这台主机的IP地址是不够的，还需要知道主机的硬件地址。\n对于以太网而言，硬件地址即48位的MAC地址。\n对于采用以太网的TCP/IP网络，ARP协议提供从IPv4地址到MAC地址的动态映射。\n动态是指它会自动执行和随时间变化，而不需要系统管理员重新配置。比如一台主机因更换网卡改变了MAC地址，ARP在一定延时之后继续正常运作。\nARP不能跨网络使用！\nARP仅用于IPv4，IPv6使用ICMPv6中的邻居发现协议实现类似功能。\nARP帧的格式 注：这里所说的ARP帧实际上是指ARP消息封装成的以太网帧。\n以太网帧的格式 上图描述了链路层以太网帧的基本格式及各个字段的大小：\nDST：填写目的MAC地址，占6字节。 SRC：填写源MAC地址，占6字节； 长度或类型：用于确定数据部分（上层协议PDU）来自哪种协议； 上层协议PDU：以太网帧的有效载荷部分，存放上层协议发来的PDU； FCS：帧校验序列，提供了对帧完整性的检查。 DST：可以填写广播地址或组播地址，广播功能用于ARP协议，组播功能用于ICMPv6，分别实现IPv4地址和IPv6地址到MAC地址的映射； 长度或类型：TCP/IP网络常见值包括IPv4（0x0800）、IPv6（0x86DD）、ARP（0x0806）。 以太网帧有最小和最大尺寸的规定，除有效载荷（上层协议PDU）部分，其他四部分固定占有18字节：\n最小帧为64字节：这要求上层协议PDU最小为46字节，如果不够就在有效载荷尾部填充0，以保证达到最小帧要求； 最大帧为1518字节：这要求上层协议PDU最大为1500字节，对于IP分组，如果超过1500字节，则需要进行IP分片。 有效载荷部分的最大长度，即1500字节，也被称为以太网的MTU（最大传输单元）。\nARP消息的格式 上图描述了ARP消息的格式及各个字段的大小：\n硬件类型：指出硬件地址类型，占2字节。对于以太网，该值为1； 协议类型：指出要映射的协议地址类型，占2字节。对于IPv4地址，该值为0x0800； 硬件大小：指出硬件地址的字节数，占1字节。对于以太网MAC地址，该值为6； 协议大小：指出要映射的协议地址的字节数，占1字节。对于IPv4地址，该值为4； Op：指出该ARP消息是ARP请求（该值为1）还是ARP应答（该值为2），占2字节； 源硬件地址：对于以太网，就是填发送方的MAC地址，占6字节； 源协议地址：对于IPv4网络，就是填发送方的IPv4地址，占4字节； 目的硬件地址：对于ARP请求，设为0；对于ARP应答，填接收方的MAC地址；占6字节； 目的协议地址：对于IPv4网络，就是填接收方的IPv4地址，占4字节。 对于一个ARP请求，它的任务是寻找目的协议地址（已知）对应的目的硬件地址（未知），所以除了目的硬件地址设为0，其他字段均需填写；\n当所请求的系统接收到ARP请求，它填充自己的硬件地址，将两个源地址和两个目的地址互换，将Op字段设置为2，然后发送生成的应答。\nARP帧的格式 ARP帧中存在重复信息：以太网头部和ARP消息中均包含发送方的MAC地址。\nARP缓存 ARP高效运行的关键是每个主机和路由器上的ARP缓存。\n在Linux下，我们可以使用arp命令查看本机的ARP缓存。\nFlags字段的C表示该条目是由ARP协议动态学习而来；若为M表示是手工输入的；若为P表示“发布”。\n从上图看，我的云服务器上只有其默认网关的ARP缓存。\n当系统接收到发送给它的ARP请求时，除了发送ARP应答，它还会在其ARP缓存中保存请求者的IP地址和MAC地址。\nARP缓存是有超时时间的，通常，完整条目的超时为20分钟，不完整条目的超时为3分钟。并且通常在每次使用一个条目后为它重新启动20分钟的超时。\n对一个不存在的主机进行ARP请求，就会在ARP缓存中生成一个不完整条目。\nARP如何工作？ 下面通过一个实际场景描述ARP的工作流程。\n场景：主机A要给同一子网内的主机B发送消息，我们假设主机A和主机B的ARP缓存中中均没有对方的IP地址和MAC地址映射信息。主机A和主机B的IP地址和MAC地址如下。\n主机A的IP地址：10.0.0.56；\n主机A的MAC地址：00:00:c0:6f:2d:40；\n主机B的IP地址：10.0.0.3；\n主机B的MAC地址：00:00:c0:c2:9b:26。\nARP请求 主机A发现自己不知道主机B的MAC地址，无法封装以太网帧，所以发出如下ARP请求帧：\n这个ARP请求帧相当于主机A在子网内广播了这样一条消息：IP地址为10.0.0.3的主机，请把你的MAC地址告诉我！\n由于是广播，所以子网内的所有主机的以太网接口都可以接收到该ARP请求帧，IP地址不是10.0.0.3的主机将主动丢弃该帧。\nARP应答 而主机B接收到ARP请求后，发现自己的IP地址与请求中的IP地址一致，所以它做出反应：发送ARP应答帧：\n同时，主机B还会把主机A的IP地址及对应的MAC地址添加到自己的ARP缓存中。\n主机A收到ARP应答帧后，就有了主机B的MAC地址，加上之前已知的主机B的IP地址，也一同添加到自己的ARP缓存中。\n这就是一个完整的ARP请求/应答流程。有了主机B的MAC，主机A就可以给主机B发送消息了。\n代理ARP 代理ARP的原理就是当出现跨网段的ARP请求时，路由器将自己的MAC地址返回给发送ARP请求的发送者，实现MAC地址代理（善意的欺骗），最终使得主机能够通信。\n免费ARP 免费ARP的特殊之处在于，ARP请求中的源IP地址和目的IP地址均为请求发送者的IP地址，即：主机发送ARP请求寻找自己的MAC地址。\n免费ARP有两个用处：\n检测IP冲突。如果这个ARP请求收到了应答，说明请求者的IP地址已经被其他主机用了。 更新自己的MAC地址。如果主机的MAC地址变了（如更换了网卡），而IP地址没变。则可以发送一个免费ARP，告诉其他主机：我换MAC地址了，你们注意下。收到免费ARP的其他主机，就可以在自己的ARP缓存里找IP地址与免费ARP里的IP地址一致的条目，然后把这个IP地址对应的MAC地址更新为免费ARP里指明的新MAC地址。 如上述主机A检测自己的IP地址是否冲突，可发送免费ARP如下：\nACD ACD是IPv4地址冲突检测的简称，用途顾名思义，就是检测IP地址是否冲突的，一般在通过DHCP获取IP地址后，DHCP客户机通过ACD技术检测分配的IP地址是否冲突。\nACD技术是通过ARP协议来完成的。\nACD定义了ARP探测消息和ARP通告消息。\nARP探测消息 ARP探测消息是一个特殊的ARP请求，特殊在其源IP地址字段被设置为0。ARP探测分组用于查看IP地址是否被其他主机占用。\n还是以上述的主机A为例，ARP探测消息如下：\nARP探测消息的源IP地址设置为0，是为了避免候选IP地址（10.0.0.56）被另一台主机使用时的缓存污染。\n当主机A发送自己的ARP探测时，它可能接收到ARP请求或应答：\n若收到针对它自己ARP探测的应答，说明IP地址10.0.0.56被其他主机占用了； 若收到ARP请求（免费ARP或ARP探测），请求中的目的IP地址字段也是候选IP地址10.0.0.56，说明有其他主机也正在尝试获得该IP地址。 以上两种情况，主机A都会生成一个地址冲突消息，如果是DHCP分配的该IP地址，则发送DHCPDECLINE消息拒绝该IP地址。\nARP通告消息 如果通过ARP探测消息发现，10.0.0.56没有被其他主机占用，即没有出现IP地址冲突，则主机A会间隔2秒向子网广播发送2个ARP通告消息，以表明它现在占用这个IP地址（10.0.0.56）。\n可以看到ARP通告消息其实跟免费ARP没有区别。\nACD是一个持续的过程，这是它与免费ARP的区别。当主机A通告了它正在使用IP地址10.0.0.56后，它会继续接收ARP请求/应答消息，查看自己的IP地址（10.0.0.56）是否出现在这些ARP请求/应答消息的源IP地址字段中。如果是的话，说明其他主机正在与自己使用相同的IP地址。对于这种情况，有三种解决方案：\n停止使用该地址； 保留该地址，但发送一个防御性的ARP通告，如果冲突继续，则停止使用该地址； 不理会冲突，继续使用。 ","date":"2024-05-09T00:28:32-07:00","permalink":"https://bitdove.github.io/posts/arp-protocol/","title":"【一文读懂】ARP协议"},{"content":"引言 进程间通信即InterProcess Communication，简称IPC。其目的是实现不同进程之间的通信问题。\n进程间通信方式可以归纳为以下几类：\n管道：PIPE、FIFO； 系统IPC：消息队列、共享存储； 信号（Signal） 套接字：socket。 管道 PIPE PIPE是UNIX系统最古老的IPC方式，也叫未命名管道，PIPE有以下两种局限性：\nPIPE是半双工的，即数据只能在一个方向上流动。 PIPE只能在具有公共祖先的两个进程之间使用。通常，一个进程创建一个管道，然后进程调用fork之后，这个管道就可以在父进程和子进程之间使用了。 PIPE通过调用pipe函数来创建：\n1 2 3 #include \u0026lt;unistd.h\u0026gt; int pipe(int fd[2]); //返回值：成功则返回0；出错则返回-1。 参数fd[2]为一个长度为2的文件描述符数组，fd[0]是读出端，fd[1]是写入端。当函数成功返回，则自动维护了一个从fd[1]到fd[0]的数据通道。 通常，进程会先调用pipe，接着调用fork，从而创建从父进程到子进程的IPC通道。如下图所示：\nfork之后做什么取决于我们想要的数据流的方向：\n如果想要从父进程到子进程流动的PIPE，则关闭父进程的读端（fd[0]）和子进程的写端（fd[1]）,下图展示了这种情况； 如果想要从子进程到父进程流动的PIPE，则关闭父进程的写端（fd[1]）和子进程的读端（fd[0]）。 PIPE的一端被关闭后，下列两条规则起作用：\n对写端关闭的PIPE，在所有数据都被读取（read）后，read返回0，表示文件结束； 对读端关闭的PIPE，write时将产生SIGPIPE信号，如果忽略该信号或者捕捉该信号并从其处理程序返回，则write返回-1，errno设置为EPIPE。 以上图从父进程到子进程的管道为例：\n如果父进程已经关闭了fd[1]，那么在子进程读取完PIPE内所有数据后，read会返回0，表示文件结束； 如果子进程已经关闭了fd[0]，父进程还在write时，会产生SIGPIPE信号。 因为上述创建数据通道的流程（首先要调用pipe创建PIPE，然后调用fork创建子进程，最后还要根据通道方向关闭父/子进程的读/写端）过于繁杂，所以标准I/O库提供了两个函数：popen和pclose，这两个函数实现的操作是：\npopen：创建一个PIPE，fork一个子进程，关闭未使用的管道端，执行一个shell命令； pclose：关闭由popen所建立的管道及文件指针； 1 2 3 4 5 #include \u0026lt;stdio.h\u0026gt; FILE *popen(const char *cmdstring, const char *type); //返回值：若成功，返回文件指针；若出错，返回NULL int pclose(FILE *fp); //返回值：若成功，返回cmdstring的终止状态；若出错，返回-1 函数popen先执行fork，然后调用exec执行cmdstring，并且返回一个标准I/O文件指针。\ncmdstring由Bourne shell以下列方式执行：\n1 sh -c cmdstring 如果type是“r”，则文件指针连接到cmdstring的标准输出； 如果type是“w”，则文件指针连接到cmdstring的标准输入。 FIFO FIFO也叫命名管道。相比于PIPE，FIFO的最大优势在于：它在两个不相关的进程间也能交换数据。\nFIFO是一种文件类型。FIFO的路径名存在于文件系统中。创建FIFO类似于创建文件：\n1 2 3 4 #include \u0026lt;sys/stat.h\u0026gt; int mkfifo(const char *path, mode_t mode); int mkfifoat(int fd, const char *path, mode_t mode); //两个函数返回值：成功返回0；出错返回-1 若path为绝对路径，则fd参数被忽略，mkfifoat和mkfifo类似； 若path为相对路径，则fd参数是一个打开目录的有效文件描述符，路径名和目录有关； 若path为相对路径，且fd参数有一个特殊值AF_FDCWD，则路径名以当前目录开始，mkfifoat和mkfifo类似。 mode参数用于指定新建的FIFO文件的访问权限；\n与PIPE类似：\n若write一个尚无进程为读而打开的FIFO，则产生SIGPIPE信号； 若FIFO的最后一个写进程关闭了该FIFO，则将为该FIFO的读进程产生一个文件结束标志。 XSI IPC 《APUE》中提到了三种XSI IPC：消息队列、信号量、共享存储。\n这里首先要说明一些东西：信号（Signal）和信号量（Semaphore）是两个不同的东西：\n信号（Signal）是软件中断，由用户、系统或者进程发送给目标进程的信息，以通知目标进程某个状态的改变或系统异常； 信号量（Semaphore）是一种特殊变量，用于协调进程对共享资源的访问。 也就是说信号（Signal）是用来传递信息的，尽管它传递的信息量非常小，小到只有一个数字，但它确实在传递消息，所以信号（Signal）可以算是一种进程间通信方式；而信号量（Semaphore）是用来解决多进程或多线程对共享资源的互斥访问问题的，它应该属于进/线程同步机制。所以我会把信号量（Semaphore）放在下一篇讲进/线程同步问题的时候介绍，本篇只介绍XSI IPC里的消息队列和共享内存。\n不过，《APUE》既然提到了三种XSI IPC：消息队列、信号量、共享存储。也就是说信号量同消息队列还有共享存储出自同一家标准，所以它们还是有些联系的。下面简单说一下。\n每个IPC对象（消息队列、信号量、共享存储）都有两个名字：标识符和键。其中标识符是内部名，键是外部名。\n标识符不同于文件描述符，它不是小整数，而是连续加1，直到达到最大值之后又回转到0； 创建IPC对象时需要指定键，其类型为key_t，通常在头文件\u0026lt;sys/types.h\u0026gt;中被定义为长整型，内核负责把键变换成标识符。 键的指定有三种方式：\nIPC_PRIVATE； 自己定义； 用ftok函数。 XSI IPC为每一个IPC结构关联了一个权限结构体ipc_perm，该结构规定了权限和所有者，创建IPC对象后，可以通过***ctl函数来修改这个结构体里某些字段的值。\nXSI IPC的缺点：\nIPC结构没有引用计数，终止之后也不会删除，需要通过调用msgctl或者执行命令ipcrm来删除； IPC结构不在文件系统中，也没有文件描述符，所以不能用ls来查看，也不能对它们用select/poll等IO多路复用函数。 消息队列 消息队列是消息的链表，存储在内核中，由消息队列标识符标识。\n1 2 3 4 5 #include \u0026lt;sys/msg.h\u0026gt; int msgget(key_t key, int flag);//成功返回消息队列ID；出错返回-1 int msgctl(int msqid, int cmd, struct msqid_ds *buf);//成功返回0；出错返回-1 int msgsnd(int msqid, const void *ptr, size_t nbytes, int flag);//成功返回0；出错返回-1 ssize_t msgrcv(int msqid, void *ptr, size_t nbytes, long type, int flag);//成功返回消息数据部分的长度；出错返回-1 msgget函数用于创建一个新队列或打开一个现有队列，其中flag参数用于设置权限（ipc_perm中的mode成员）； msgctl函数用于修改ipc_perm结构的成员值，也用于删除消息队列以及仍在该队列中的所有数据； msgsnd函数用于讲新消息添加到队列尾端； msgrcv函数用于从队列中取消息。 并不一定要以先进先出顺序取消息，也可以按照消息的类型（type）字段取消息。\n共享存储 共享存储允许两个或多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种IPC。\n共享存储有两种：\n内存文件映射：即通过mmap函数，将同一个文件映射到多个进程的虚拟地址空间； XSI共享存储：与内存文件映射相比，它没有相关文件，它的共享存储段是内存的匿名段。 XSI 共享存储 1 2 3 4 5 #include \u0026lt;sys/shm.h\u0026gt; int shmget(key_t key, size_t size, int flag);//成功返回共享存储ID；出错返回-1 int shmctl(int shmid, int cmd, struct shmid_ds *buf);//成功返回0；出错返回-1 void *shmat(int shmid, const void *addr, int flag);//成功返回指向共享存储段的指针；出错返回-1 int shmdt(const void *addr);//成功返回0；出错返回-1 shmget函数用于获得一个共享存储标识符，size为共享存储段的长度（以字节为单位），flag参数设置权限； shmctl函数用于修改ipc_perm结构的成员值，也用于删除共享存储以及仍在该共享存储中的所有数据； shmat函数用于将共享存储段与进程地址空间连接起来，addr参数用于指定连接地址，一般为0，指连接地址由系统决定； shmdt函数用于在对共享存储段的操作结束之后，将进程地址空间与该共享存储段分离，注意，仅分离，并不删除。 内存文件映射 1 2 3 #include \u0026lt;sys/mman.h\u0026gt; void *mmap(void *addr, size_t len, int prot, int flag, int fd, off_t off); //成功返回映射区起始地址；出错返回MAP_FAILED addr参数用于指定映射区的起始地址，一般为0，指起始地址由系统决定； len参数为映射的字节数； fd参数为要映射的文件的文件描述符； off参数为要映射字节在文件中的起始偏移量； prot参数指定映射区的保护要求； flag参数影响映射区的多种属性，不详细展开。 信号 信号是软件中断。它只能用于通知进程某事件的发生，并不能传输数据。\n通过kill -l命令可以看到目前Linux支持的全部信号，已经达到了62种（32号和33号没有）。\n每个信号的名字都是以SIG开头，这些信号名在头文件\u0026lt;signal.h\u0026gt;中被定义为正整数常量（信号编号）。\n在某个信号出现时，可以告诉内核按下列三种方式之一处理：\n忽略该信号； 捕捉信号。为了做到这一点，要通知内核在某种信号发生时，调用一个用户函数。在用户函数中，可执行用户希望对这种事件进行的处理； 执行系统默认动作。大多数信号的系统默认动作是终止该进程； UNIX系统信号机制最简单的接口是signal函数：\n1 2 3 #include \u0026lt;signal.h\u0026gt; void (*signal(int signo, void (*func) (int))) (int); //成功返回以前的信号处理配置；出错返回SIG_ERR signo是我们要处理的信号的信号名；func是我们对信号signo要进行的处理方式，有以下三种：\n若为SIG_IGN则向内核表示忽略该信号（SIGKILL和SIGSTOP不能忽略）； 若为SIG_DFL则向内核表示接到此信号后的动作是系统默认动作； 若为函数地址，则在信号发生时，调用该函数。该函数则叫做信号处理程序。 signal函数现在已基本被sigaction函数替代：\n1 2 3 4 5 #include \u0026lt;signal.h\u0026gt; int sigaction(int signo, const struct sigaction *restrict act, struct sigaction *restrict oact); //成功返回0；出错返回-1 sigaction函数的功能是检查或修改与指定信号相关联的处理动作：\nsigno参数是要检测或修改其具体动作的信号编号； act用于指定新的信号处理方式； oact若不为NULL，则通过它返回之前的信号处理方式。 sigaction结构体里的sa_handler成员指定信号处理方式。详见《APUE》。\n套接字 套接字描述符 套接字实现通过网络相连的不同计算机之间的进程间通信。在UNIX系统中，套接字也是一种文件类型，故它也有自己的文件描述符，叫做套接字描述符。\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; int socket(int domain, int type, int protocol); //成功返回套接字（文件）描述符；出错返回-1 domain参数确定通信的特性，其常见取值为:\nAF_INET：代表IPv4； AF_INET6：代表IPv6。 type参数确定套接字类型，进一步确定通信特征，常见取值为：\nSOCK_DGRAM：固定长度、无连接、不可靠报文传递； SOCK_STREAM：有序、可靠、双向、面向连接的字节流。 protocol参数通常为0，表示为给定的domain和type选择默认协议：\ndomain=AF_INET，type=SOCK_STREAM时，默认协议为TCP； domain=AF_INET，type=SOCK_DGRAM时，默认协议为UDP。 尽管套接字描述符本质上是文件描述符，但并非所有参数为文件描述符的函数都可以接受套接字描述符。如lseek就不能，因为套接字没有文件偏移量的概念。\n寻址及关联 我们想跟另一台主机上的进程通信，首先要能够标识我们的目标通信进程，需要两个信息：\nIP地址：锁定要通信的计算机； 端口号：锁定要通信的进程。 可以称（IP，Port）为套接字地址。\n但是有这样一个CPU架构特性——字节序，字节序分两种：\n大端字节序：高位存在低地址，低位存在高地址； 小端字节序：低位存在低地址，高位存在高地址。 不同的计算机使用的CPU不同，那主机字节序就有可能不同，这个问题必须解决，要不然我这边是0x01020304，传到那边成0x04030201了，这是绝对不可以的。解决方案：\n由网络协议指定一种字节序，称为网络字节序。通信双方收到数据后再转成自己的字节序。 TCP/IP协议栈采用大端字节序。\nUNIX提供了四个函数，用于完成主机字节序和网络字节序的相互转换：\n1 2 3 4 5 #include \u0026lt;arpa/inet.h\u0026gt; uint32_t htonl(uint32_t hostint32);//32位整数的主机字节序到网络字节序的转换 uint16_t htons(uint16_t hostint16);//16位整数的主机字节序到网络字节序的转换 uint32_t ntohl(uint32_t netint32);//32位整数的网络字节序到主机字节序的转换 uint16_t ntohs(uint16_t netint16);//16位整数的网络字节序到主机字节序的转换 在IPv4因特网中，套接字地址用结构体sockaddr_in表示：\n1 2 3 4 5 6 7 8 9 struct in_addr{ in_addr_t s_addr; //IPv4地址 }; struct sockaddr_in{ sa_family_t sin_family; //协议族 in_port_t sin_port; //端口号 struct in_addr sin_addr; //IPv4地址 } IP地址我们经常用点分十进制表示，但是计算机只能理解二进制格式，所以还有两个用来转换点分十进制和二进制地址的函数：\n1 2 3 4 5 6 7 8 9 10 #include \u0026lt;arpa/inet.h\u0026gt; const char *inet_ntop(int domain, const void *restrict addr, char *restrict str, socklen_t size); //返回值：成功则返回点分十进制地址字符串的指针；出错返回NULL int inet_pton(int domain, const char *restrict str, void *restrict addr); //返回值：成功则返回1；若格式无效则返回0；出错返回-1 inet_ntop函数将网络字节序二进制地址转换为点分十进制； inet_pton函数将点分十进制转换为网络字节序的二进制地址。 客户端程序的套接字由系统选择默认端口即可；而对于服务端程序，我们需要把其套接字关联到一个固定的套接字地址上，这个过程由bind函数完成：\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; int bind(int sockfd, const struct sockaddr *addr, socklen_t len); //返回值：成功返回0；出错返回-1 sockfd参数为要关联地址的套接字描述符（socket函数的返回值）； addr参数为套接字地址结构体，对sockaddr_in结构体进行类型转换即可； len参数为addr变量的大小，可由sizeof()得出。 建立连接 对于面向连接的套接字类型（如SOCK_STREAM），在开始交换数据之前，需要在客户端和服务端之间建立连接，发起连接的一般为客户端，这由connect函数完成：\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; int connect(int sockfd, const struct sockaddr *addr, socklen_t len); //成功返回0；出错返回-1 sock参数是要发起连接的套接字描述符（即客户端的套接字描述符）； addr参数是服务端的套接字（即对方的套接字地址结构）； len参数addr变量的大小，可由sizeof()得出。 因为我们通常不会用bind函数给客户端的套接字绑定一个地址（端口号），所以connect函数会给客户端套接字绑定一个默认地址，即客户端进程的端口号在这时产生。\n服务器调用listen函数来宣告它愿意接受连接请求：\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; int listen(int sockfd, int backlog); //返回值：成功返回0；出错返回-1 sockfd参数为服务端套接字描述符； backlog参数规定了内核应该为该套接字排队的最大连接个数。 backlog参数牵扯到TCP连接的内容，以后细讲。\n调用listen之后，服务端套接字就能接收连接请求，使用accept函数获得连接请求并建立连接：\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; int accept(int sockfd, struct sockaddr *restrict addr, socklen *restrict len); //成功返回新的套接字描述符；出错返回-1 sockfd参数为服务端套接字描述符； 如果不关心客户端的身份，addr和len可以均设为NULL。 accept函数返回一个新的套接字描述符，这个新的套接字与客户端套接字连接在一起，并用来交换数据；\n这个新的套接字与原始套接字（sockfd）具有相同的套接字类型和地址族；\n原始套接字继续保持可用状态并接收其他连接请求。\n时序图 一图胜千言，下面是面向连接的TCP socket通信时序图：\n总结 《APUE》中明确指明，要尽量避免使用消息队列及信号量（Semaphore）。\n为什么共享存储是最快的IPC方式？\n使用PIPE、FIFO、消息队列如下图所示：\n使用PIPE、FIFO、消息队列从一个文件传输信息到另外一个文件需要复制4次：\n服务端将信息从相应的文件复制到服务端临时缓冲区中； 从服务端临时缓冲区中复制到PIPE（FIFO/消息队列）； 客户端将信息从PIPE（FIFO/消息队列）复制到客户端临时缓冲区中； 从客户端临时缓冲区将信息复制到输出文件中。 共享内存的消息复制只有两次：\n从输入文件到共享内存； 从共享内存到输出文件。 PIPE、FIFO、消息队列都属于间接通信，它们要经过内核；而共享存储属于直接通信，共享存储段分配在虚拟地址空间中的用户那一部分，客户端和服务端共享，不经过内核而直接读写，所以快。\n共享存储的缺点就是需要进行同步操作。\n","date":"2022-06-07T01:18:12-07:00","permalink":"https://bitdove.github.io/posts/interprocess-communication/","title":"【一文读懂】进程间通信"},{"content":"调度的概念 首先，在《进程与线程基础》一文中，我们已经了解到：\n进程是资源分配的基本单位； 线程是CPU调度的基本单位。 一个单核CPU在某一时刻只能允许一个线程执行，但是现在的计算机总是有一大堆进/线程等待执行。这就需要某种规则来决定处理这些进/线程的顺序，这就是调度要研究的问题。\n回忆之前提到的进程状态：\n运行态：当前正在占有CPU的进/线程；\n就绪态：具备运行条件，等待系统分配CPU的进/线程；\n阻塞态：不具备运行条件，正在等待某外部事件发生的进/线程。\n所谓进程调度，就是指在处于就绪态的一堆进/线程里，按照一定的调度算法，选出一个进/线程并给它分配CPU时间让它运行，从而实现多进程/多线程的并发执行。\n进程调度与线程调度尽管有些不同，但大部分是相同的，本文仅关注二者共同的部分。\n进程切换的基本流程：\n首先用户态必须切换到内核态； 保存当前进程的状态，包括在其PCB中保存CPU各寄存器值，以便日后重新执行； 调度算法选定一个新进程； 新进程的内存地址空间重新装入MMU（内存管理单元）； 新进程开始执行。 调度目标 所有系统 对于所有系统，都应该有以下调度目标：\n公平——给每个进程公平的CPU份额； 策略强制执行——保证规定的调度策略被执行； 平衡——保证系统的所有部分都在忙碌。 批处理系统 批处理系统更适合非抢占式调度算法（见下文），应有以下调度目标：\n吞吐量——每小时最大作业数； 周转时间——从提交到终止的最短时间； CPU利用率——保持CPU始终忙碌。 交互式系统 交互式系统更适合抢占式调度算法（见下文），应有以下调度目标：\n响应时间——快速响应请求； 均衡性——满足用户的期望。 实时系统 对于实时系统，应有以下调度目标：\n满足截止时间——避免丢失数据； 可预测性——如多媒体系统中避免品质降低。 调度算法 进程调度的核心自然是调度规则，即各种调度算法。\n计算机都有一个硬件时钟，也叫RTC或CMOS，它独立于操作系统，由主板上一块电池供电的芯片，所以即使计算机断电，RTC也可以维持时间。这个硬件时钟会周期性的发出时钟中断。\n根据如何处理时钟中断，可以把调度算法分为两类：\n非抢占式调度算法：发生时钟中断时不调度； 抢占式调度算法：通过时钟中断使CPU控制权返回给调度程序，进而调度其它进程。 非抢占式调度算法：正在运行的进程只有在该进程执行完成或发生阻塞（如I/O请求）的情况下才会释放CPU；\n抢占式调度算法：分给进程的时间片耗尽之后，无论当前进程有没有执行完成，调度程序均选择其他进程执行。\n非抢占式调度算法 先来先服务 先来先服务算法（FCFS）：按照进程请求CPU的顺序调度它们。\n意思就是，所有的就绪状态的进程在一个队列中，申请使用CPU的进程按照先来后到的顺序排在队列尾部，每执行完一个进程，系统就从该队列的头部取出第一个进程来执行。\n优点：\n易于理解且算法实现简单； 缺点：\n对短进程不利。排在长进程后面的短进程需要等待很长时间，短进程的响应时间可能会很长。 最短作业优先 最短作业优先算法（SJF）：每次调度时选择当前已到达的、且运行时间最短的作业。\n优点：\n对比FCFS，平均等待时间、平均周转时间、平均带权周转时间均有提高； 缺点：\n需提前掌握各作业的运行时间；\n对长作业不利。因为如果一直有短作业到来，那么长作业永远得不到调度，长作业有可能会饿死，处于一直等待短作业执行完毕的状态。\n周转时间：从进程请求CPU到进程执行完毕为止的统计平均时间。\n非抢占式优先级调度 优先级调度：每个进程被赋予一个优先级，允许优先级最高的可运行进程先运行。\n对于非抢占式优先级调度，当一个进程到达就绪队列时，比较它的优先级与当前运行进程的优先级。如果新到达进程的优先级高于当前运行进程的优先级，非抢占优先级调度算法只是将新的进程加到就绪队列的头部，而不会进行进程切换。\n缺点：\n若有源源不断的高优先级进程到来，低优先级进程会导致饥饿。 抢占式调度算法 最短剩余时间优先 最短剩余时间优先（SRTN）：当一个新的进程到达时，把它所需要的整个运行时间与当前进程的剩余运行时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程，否则新的进程等待。\n优点：\n可以使新的短进程得到良好的服务。 缺点：\n需提前掌握各进程的运行时间； 对长进程不利。 最短剩余时间优先（SRTN）是最短作业优先的抢占式版本。\n轮转调度 轮转调度（RR）:每个进程被分配一个时间段，称为时间片，即允许该进程在该时间段内运行。如果在时间片结束时该进程还在运行，则剥夺其CPU并分配给另一个进程；如果该进程在时间片结束前阻塞或结束，则立即进行进程切换。\n轮转调度算法对每个进程都一视同仁，就好比大家都排好队，一个一个来，每个人都运行一会儿再接着重新排队等待运行。\n优点：\n易理解且算法易实现； 可以兼顾长进程和短进程。 缺点：\n平均等待时间较长，频繁上下文切换比较费时；\n时间片的长度选取困难。\n时间片设置的太短会导致过多的进程切换，降低CPU效率；\n时间片设置的太长又可能会引起对短的交互请求的响应时间变长。\n通常时间片设为20-50ms是一个较合理的折中。\n抢占式优先级调度 优先级调度：每个进程被赋予一个优先级，允许优先级最高的可运行进程先运行。\n优先级调度的问题在于高优先级进程可能无休止地运行下去，对此有两种解决方案：\n调度程序可能在每个时钟中断降低当前进程的优先级。如果调整后该进程的优先级低于次高优先级的进程，则进行进程切换。 给每个进程赋予一个允许运行的最大时间片，时间片耗尽，次高优先级的进程就获得运行机会。 优先级有静态赋予和动态赋予两种方式。\n静态赋予即在创建进程时人为确定进程的优先级，并且规定它在进程的整个运行期间保持不变；\n动态赋予即在创建进程时赋予该进程一个初始优先级，然后系统根据进程的执行情况的变化而不断改变其优先级，以便获得更好的调度性能。\n对于抢占式优先级调度，当一个进程到达就绪队列时，比较它的优先级与当前运行进程的优先级。如果新到达进程的优先级高于当前运行进程的优先级，那么抢占式优先级调度算法就会进行进程切换，让新到的高优先级进程运行。\n多级反馈队列 多级反馈队列：在系统中设置多个就绪队列，并为每个队列赋予不同的优先级，从第一个开始逐个降低。不同队列中的进程所赋予的执行时间也不同，优先级越高，时间片越小。\n首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次优先级队列中的进程；\n对于同一个队列中的各个进程，按照时间片轮转调度；\n当一个进程用完分配的时间片后，它被移到低一级优先级队列。\n彩票调度 彩票调度：为进程提供各种系统资源（如CPU时间）的彩票。一旦要做出调度决策时，就随机抽取一张彩票，拥有该彩票的进程则获得该资源。\n为了增加重要进程“中彩票”的机率，可以给它们额外的彩票。\n公平分享调度 公平分享调度：考虑进程的拥有者是谁，保证每个用户公平的分享CPU。\n之前的调度算法都不关注进程所有者是谁。这样做的结果是，如果用户1启动9个进程而用户2启动1个进程，使用轮转或相同优先级调度算法，那么用户1将得到90%的CPU时间，而用户2只得到10%的CPU时间。\n","date":"2022-06-06T01:14:52-07:00","permalink":"https://bitdove.github.io/posts/process-scheduling/","title":"【一文读懂】进程调度"},{"content":"引言 在C++中，有三种成员函数,按照加入C++的先后顺序排列如下：\nnonstatic member functions virtual member functions static member functions 经过编译器的处理之后，这三种成员函数的调用方式是不相同的，下边我们一个一个看。 我们提供这样一个类Point3d，作例子：\n1 2 3 4 5 6 7 8 9 10 11 12 class Point3d { public: float magnitude() const; private: float _x; float _y; float _z; } float Point3d::magnitude() const{ return sqrt(_x * _x + _y * _y + _z * _z); } Nonstatic Member Functions C++有这样一个设计准则：非静态成员函数至少要和一般的非成员函数有相同的效率。也就是说，如下两个函数：\n1 2 float magnitude3d(const Point3d* _this){...} //非成员函数 float Point3d::magnitude3d() const {...} //成员函数 选择第二个函数不应该给程序带来性能上的损失，否则我还不如直接选第一个函数（不让它做类的成员函数）。\n那编译器是怎么保证这个原则的呢？答案是编译器内部会把成员函数转换为对等的非成员函数。 举个例子，下面是magnitude()的非成员函数版定义：\n1 2 3 4 5 float magnitude(const Point3d* _this){ return sqrt(_this-\u0026gt;_x * _this-\u0026gt;_x + _this-\u0026gt;_y * _this-\u0026gt;_y + _this-\u0026gt;_z * _this-\u0026gt;_z); } 乍一看，成员函数版应该效率更高，因为它直接取用_x,_y,_z这三个成员，而非成员函数版要通过指针间接取用。其实不然，因为成员函数版会被编译器内化为非成员函数版，转化步骤如下;\n改写函数原型，安插一个额外的参数（this指针）到成员函数。 非const的非静态成员函数改写如下： 1 Point3d::magnitude(Point3d *const this) 即添加了一个指针常量this。\nconst的非静态成员函数改写如下： 1 Point3d::magnitude(const Point3d* const this) 即添加一个指向常量的指针常量this。\n把每一个对非静态数据成员的存取操作改成通过this指针来存取： 1 2 3 4 5 6 7 { return sqrt( this-\u0026gt;_x * this-\u0026gt;_x + this-\u0026gt;_y * this-\u0026gt;_y + this-\u0026gt;_z * this-\u0026gt;_z ); } 将成员函数重新写成一个外部函数。将函数名称通过“mangling”，使它称为程序中独一无二的词汇： 1 extern magnitude__7Point3dFv(register Point3d* const this); 经此三步，这个函数的转换就完成了。之后，每个调用操作也会被转换。比如： 1 2 3 4 Point3d obj; Point3d* ptr = \u0026amp;obj; obj.magnitude(); ptr-\u0026gt;magnitude(); 以上两个调用操作，就会被分别转换为：\n1 2 magnitude__7Point3dFv(\u0026amp;obj); magnitude__7Point3dFv(ptr); Virtual Functions 如果magnitude()是一个虚函数，那么以下调用：\n1 ptr-\u0026gt;magnitude() 就会被内部转化为：\n1 (* ptr-\u0026gt;vptr[1])(ptr); 整体其实是通过函数指针调用magnitude()函数； vptr是编译器产生的指针，指向虚表； 1是虚表slot的索引值，关联到magnitude()函数； 第二个ptr表示this指针。 Static Member Functions 静态成员函数的主要特性是它没有this指针。因为它没有this指针，所以静态成员函数有以下特点：\n它不能直接操作类中的非静态成员； 它不能是const、volatile或virtual的； 它不需要经过类的对象来调用（尽管很多时候我们仍是这样调用它）。 如果magnitude()是一个静态成员函数，那么以下调用：\n1 2 obj.magnitude(); ptr-\u0026gt;magnitude(); 会被转换为一般的非成员函数调用，像这样：\n1 magnitude__7Point3dSFv(); 由于缺乏this指针，所以静态成员函数差不多等同于非成员函数。\n","date":"2021-06-28T20:24:15-07:00","permalink":"https://bitdove.github.io/posts/cpp-member-function-calling/","title":"【一文读懂】C++成员函数的调用方式"},{"content":"引言 继承是C++作为面向对象语言的一大特性。继承提高了代码的复用和可扩展性。子类可以把父类的数据成员“完整”地继承下来，而对于父类的成员函数，子类继承的是它们的调用权。 根据子类继承父类的个数，继承分为单继承、多继承：\n单继承，子类继承一个父类 多继承：子类继承多个父类 另外还有一种虚继承，虚继承其实是为了解决多继承带了的问题而引入的。后边再详述。 单继承没什么好说的，所以不单独列一节。并且下边的美人鱼例子，虽是为讲多继承而设计，但它也包含了单继承的内容。\n多继承 我们以美人鱼为例，美人鱼既有美人的某些属性，又有鱼的某些属性，可以把美人和鱼看作美人鱼的父类；而美人和鱼都是动物，可以把动物看作美人和鱼的共同父类。这样我们就可以定义如下几个类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Animal{ public: int data_Animal; }; class Beauty : public Animal{ public: int data_Beauty; }; class Fish : public Animal{ public: int data_Fish; }; class BeautyFish : public Beauty, public Fish{ public: int data_BeautyFish; }; 如果把这四个类的继承关系画成图，你就会发现，四个类组成一个菱形，这就是菱形继承。\n那么这四个类的对象会占用多大的内存呢？我在64位Linux平台下，用g++编译器的-fdump-class-hierarchy选项做了测试，为忽略内存对齐影响，使用#pragma pack(1)设为1字节对齐。测试结果如下：\n1 2 3 4 sizeof(Animal) == 4 sizeof(Beauty) == 8 sizeof(Fish) == 8 sizeof(BeautyFish) == 20 -fdump-class-hierarchy生成的文件内容如下（只保留以上四个类）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Class Animal size=4 align=1 base size=4 base align=1 Animal (0x0x7f11187c4d80) 0 Class Beauty size=8 align=1 base size=8 base align=1 Beauty (0x0x7f111860e5b0) 0 Animal (0x0x7f11187c4de0) 0 Class Fish size=8 align=1 base size=8 base align=1 Fish (0x0x7f111860e618) 0 Animal (0x0x7f11187c4e40) 0 Class BeautyFish size=20 align=1 base size=20 base align=1 BeautyFish (0x0x7f111861e540) 0 Beauty (0x0x7f111860e680) 0 Animal (0x0x7f11187c4ea0) 0 Fish (0x0x7f111860e6e8) 8 Animal (0x0x7f11187c4f00) 8 这是一个简单的模型，各个类都没有虚函数，所以不难想象为什么结果是这样。用图来表示，各个类的对象的内存布局大致如下：\n可以看到，在BeautyFish的对象内，保存了两份data_Animal，一份来自父类Beauty，另一份来自父类Fish。从功能上讲，BeautyFish的对象没有必要保存两份data_Animal，这样是非常浪费内存空间的，这就是多继承带来的数据冗余问题。\n除了数据冗余，多继承还会带来二义性问题。假设有下面这样的程序：\n1 2 3 4 5 6 int main(){ BeautyFish bf; bf.data_Animal = 2021; //语句1 bf.Beauty::data_Animal = 2021; //语句2 bf.Fish::data_Animal = 2021; //语句3 } 语句1将会产生二义性调用，bf内有两份data_Animal，程序不知道该去给哪一个进行赋值操作； 语句2和语句3可以正常通过，因为通过作用域限定符指明了具体给哪个data_Animal进行赋值操作。 虚继承 为了解决多继承带来的数据冗余与二义性问题，C++引入了虚继承机制。虚继承使子类只保留一份间接基类的成员，既节省内存空间，又避免了二义性的麻烦。\n于BeautyFish类而言，Beauty和Fish是它的直接基类，Animal则是它的间接基类。\n具体做起来也非常简单，只需要在Beauty和Fish继承Animal时，加一个virtual关键字。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Animal{ public: int data_Animal; }; class Beauty : public virtual Animal{ public: int data_Beauty; }; class Fish : public virtual Animal{ public: int data_Fish; }; class BeautyFish : public Beauty, public Fish{ public: int data_BeautyFish; }; 同样的方法，我们再来测一下四个类的对象的大小，测试结果如下：\n1 2 3 4 sizeof(Animal) == 4 sizeof(Beauty) == 16 sizeof(Fish) == 16 sizeof(BeautyFish) == 32 -fdump-class-hierarchy生成的文件内容如下（只保留以上四个类）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 Class Animal size=4 align=1 base size=4 base align=1 Animal (0x0x7f758e638d80) 0 Vtable for Beauty Beauty::_ZTV6Beauty: 3u entries 0 12u 8 (int (*)(...))0 16 (int (*)(...))(\u0026amp; _ZTI6Beauty) VTT for Beauty Beauty::_ZTT6Beauty: 1u entries 0 ((\u0026amp; Beauty::_ZTV6Beauty) + 24u) Class Beauty size=16 align=1 base size=12 base align=1 Beauty (0x0x7f758e4825b0) 0 vptridx=0u vptr=((\u0026amp; Beauty::_ZTV6Beauty) + 24u) Animal (0x0x7f758e638de0) 12 virtual vbaseoffset=-24 Vtable for Fish Fish::_ZTV4Fish: 3u entries 0 12u 8 (int (*)(...))0 16 (int (*)(...))(\u0026amp; _ZTI4Fish) VTT for Fish Fish::_ZTT4Fish: 1u entries 0 ((\u0026amp; Fish::_ZTV4Fish) + 24u) Class Fish size=16 align=1 base size=12 base align=1 Fish (0x0x7f758e482618) 0 vptridx=0u vptr=((\u0026amp; Fish::_ZTV4Fish) + 24u) Animal (0x0x7f758e638e40) 12 virtual vbaseoffset=-24 Vtable for BeautyFish BeautyFish::_ZTV10BeautyFish: 6u entries 0 28u 8 (int (*)(...))0 16 (int (*)(...))(\u0026amp; _ZTI10BeautyFish) 24 16u 32 (int (*)(...))-12 40 (int (*)(...))(\u0026amp; _ZTI10BeautyFish) Construction vtable for Beauty (0x0x7f758e482680 instance) in BeautyFish BeautyFish::_ZTC10BeautyFish0_6Beauty: 3u entries 0 28u 8 (int (*)(...))0 16 (int (*)(...))(\u0026amp; _ZTI6Beauty) Construction vtable for Fish (0x0x7f758e4826e8 instance) in BeautyFish BeautyFish::_ZTC10BeautyFish12_4Fish: 3u entries 0 16u 8 (int (*)(...))0 16 (int (*)(...))(\u0026amp; _ZTI4Fish) VTT for BeautyFish BeautyFish::_ZTT10BeautyFish: 4u entries 0 ((\u0026amp; BeautyFish::_ZTV10BeautyFish) + 24u) 8 ((\u0026amp; BeautyFish::_ZTC10BeautyFish0_6Beauty) + 24u) 16 ((\u0026amp; BeautyFish::_ZTC10BeautyFish12_4Fish) + 24u) 24 ((\u0026amp; BeautyFish::_ZTV10BeautyFish) + 48u) Class BeautyFish size=32 align=1 base size=28 base align=1 BeautyFish (0x0x7f758e492540) 0 vptridx=0u vptr=((\u0026amp; BeautyFish::_ZTV10BeautyFish) + 24u) Beauty (0x0x7f758e482680) 0 primary-for BeautyFish (0x0x7f758e492540) subvttidx=8u Animal (0x0x7f758e638ea0) 28 virtual vbaseoffset=-24 Fish (0x0x7f758e4826e8) 12 subvttidx=16u vptridx=24u vptr=((\u0026amp; BeautyFish::_ZTV10BeautyFish) + 48u) Animal (0x0x7f758e638ea0) alternative-path 虽然只是加了个virtual，但我们可以看到上边的文件已经比之前的复杂很多了。经过分析上边的文件，结合gdb的打印类布局的内容以及网上相关博客，我还是分析出了四个类的内存布局。\nAnimal、Beauty和Fish的内存模型如下图：\nAnimal类对象的内存布局与之前一模一样，不再赘述。\nBeauty和Fish内存模型是一样的，我们以Beauty为例讲解。\n虚继承的话，子类的对象里首先存的是自己的东西，最后才是虚基类的东西； 非虚继承的话，子类的对象里首先存的是基类的东西，最后才是自己的东西。如果有多个基类，则按照继承的顺序，第一个基类被设为主基类。 由于是Beauty虚继承Animal，所以在Beauty对象的内存里，首先是虚指针vptr和Beauty自己的数据data_Beauty，最后才是从虚基类Animal继承来的data_Animal。\nBeauty的虚表有三个内容：\n第一个slot是vbase_offset，其值是12。这个值的意思是，Beauty中虚基类的部分（即Animal的部分）在Beauty对象内存中的偏移量是12。我们可以看到从Beauty对象的内存首地址偏移12个字节正好是data_Animal的地址。 第二个slot是offset_to_top。将对象从当前这个类型（this指针）转换为该对象的实际类型的地址偏移量； 第三个slot是type_info_for_Beauty,用于RTTI。 第二和第三个slot里的内容还没有弄明白，这里就先不多说了。\nBeautyFish就比较复杂了，其内存布局大致如下：\nBeautyFish非虚继承Beauty和Fish，所以BeautyFish对象的内存里，首先是基类的东西，即Beauty的虚指针和数据、Fish的虚指针和数据，然后是BeautyFish自己的数据，最后是虚基类Animal的数据。\nBeautyFish的虚表这里不再展开。\n总结 关于C++对象的内存布局，C++标准并没有作出严格的约束，只是做了一个框架性的约束，而具体的实现交由编译器自己来完成。所以就导致C++对象模型相关内容是编译器相关的，不同的编译器可能会有不同的结果。\n以我所知道的，GCC和VC++对于C++对象内存模型的实现差别就很大。比如对于虚基类，GCC的做法是扩展了虚表（virtual table）；而VC++则是模仿虚表，建了一个虚基类表（virtual base class table），正如虚指针vptr指向虚表一样，VC++会在C++对象里加一个虚基类指针vbptr，该指针指向虚基类表。\n这些东西有些繁杂，我也不能保证写的一定正确，很多东西都是自己分析得出，只为建立自己的C++对象模型观。如有朋友发现有误，欢迎指出。\n","date":"2021-06-22T06:19:43-07:00","permalink":"https://bitdove.github.io/posts/cpp-multiple-inheritance/","title":"美人+鱼=美人鱼——谈C++多继承"},{"content":"引言 如《Effective C++》中所言，C++是一个语言联邦，它由以下四部分组成：\nC：可以理解为兼容C的那部分，即面向过程的； Object-Oriendted C++：即C++面向对象的部分，封装、继承、多态； Template C++：即泛型编程； STL：标准模版库，主要包含容器、迭代器、算法等。 面向过程：如C语言，数据和**处理数据的操作(即函数)**是分开的，也就是说语言本身并没有支持数据和函数之间的关联性。\n本文我们要谈的就是C++面向对象的部分内容。\n封装：于C++而言，封装实际上指的就是class，通过class把数据和函数封装在一起，对外只提供类的接口，而把实现细节隐藏起来，同时还可以通过访问权限制定数据和函数的安全等级，从而提高了安全性和隐私性。 继承：继承可以理解为代码复用，是为了提高代码的复用性和可扩展性。子类继承父类，在保留“家族传统”的同时，还允许子类有自己的“小个性”。对于父类中的数据成员，子类完整的继承下来，所谓“完整”是指这种继承是要占用内存的；而对于父类的成员函数，子类继承的只是函数的调用权。 多态：多态可以理解为接口复用，也就是通过不同的方式调用“相同的接口”将产生不同的操作。多态分为静态多态和动态多态，静态多态通过重载实现，动态多态通过虚函数实现。 多态中，关于“相同的接口”中的“相同”，不同形式的多态有一些程度上的区分。一个函数由返回类型、函数名、函数形参、函数体四部分组成。\n静态多态：通过重载实现，“相同”指的是函数名相同，函数形参必须不同，返回类型相同不相同都可以，既然要实现不同功能，函数体当然也是不同的； 动态多态：通过子类重写父类的虚函数实现，“相同”指的是除了函数体外其他完全相同，返回类型、函数名、函数形参都相同，只有函数体不同（为实现不同功能）。 静态多态是在编译期就确定下来的，编译器编译的时候会把这些函数加上各自的形参信息，这样实际上还是不同的函数，从而实现静态多态。重载的函数都在同一个类里面。\n动态多态是在运行期才能确定下来。\nC++对象基本模型 所谓C++对象模型，可以理解为对于各种支持的底层实现机制，这里我们简单关注C++对象在内存中的布局。 C++类的成员可以归纳为以下两大类五小类：\n成员函数 静态成员函数(static member functions) 非静态成员函数(non-static member functions) 虚成员函数(virtual member functions) 数据成员 静态数据成员(static data members) 非静态数据成员(non-static data members) 那么，我们可以定义这样一个类Base，在不考虑继承的情况下，它囊括了类的所有可能的成员。\n1 2 3 4 5 6 7 8 9 class Base{ public: static int fun_1(); //static member function int fun_2(); //non-static member function virtual int fun_3(){} //virtual member function private: static int data_1; //static data member int data_2; //non-static data member }; 对于这样一个类Base，实例化后，它的对象占多少字节呢？先给出答案：\n在32位机器上，sizeof(Base)得到的值为8； 在64位机器上，sizeof(Base)得到的值为16。 为什么是这样的值呢？这是由C++对象模型所决定的。在C++对象模型中：\n非静态数据成员（如data_2）由类的每个对象各自保存,根据对象的内存分配方式，存储在Heap或Stack； 静态数据成员（如data_1）只分配一次内存，由类的所有对象共用，存储在数据段(.data)； 静态成员函数（如fun_1）和非静态成员函数（如fun_2）均存储在代码段（.text）； 虚函数（如fun_3）也存储在代码段（.text），并以以下2个步骤支持之： 类产生一堆指向虚成员函数的指针，这些指针放在一个表中，称为虚表(virtual table)； 类的每个对象都存储一个指针vptr，它指向虚表。 vptr指针存放在对象内存的前四个字节，虚表存放在只读数据段(.rodata)。\n也就是说，类实例化后，对象内只有非静态数据成员和虚指针vptr。这就能解释为什么sizeof(Base)的结果是8（32位机器）和16（32位机器）了：\nint型的data_1占4个字节； vptr是指针，与机器相关，32位下占4字节，64位下占8字节； 内存对齐填补的空间。 以上三部分加起来，就是每个Base类所占的内存大小。\nC++对象内存布局 对于上述Base类，以32位平台为例，用以下分配方式分配内存后，其内存布局如下图所示。\n1 2 3 int main(){ Base* ptr = new Base; } 注：上图的内存布局旨在描述一种通用模型，而具体的要视平台、编译器而定。\nReferences ","date":"2021-06-21T20:27:56-07:00","permalink":"https://bitdove.github.io/posts/cpp-object-model-via-memory-sight/","title":"内存角度看C++对象模型"},{"content":"引言 在《TCP的三次握手与四次挥手》中，我们已经了解了一个TCP连接的建立与终止的规则及这个过程中发送的各个类型的报文段。这些决定TCP应该做什么的规则其实是由当前TCP连接所属的状态决定的。当前的状态会在各种触发条件下发生改变。常见的触发条件如：\n传输或接收到某报文段； 计时器超时； 客户端/服务端应用程序的读写操作； 来自其他层的信息。 这些规则可以概括为TCP的状态转换图。\n本文就以TCP状态转换为出发点，再探TCP的连接管理相关内容。\nTCP状态转换图 TCP定义了11种状态，状态名字基于netstat命令所输出的名称。\nCLOSED状态作为开始状态点和终止状态点，但它并不能算一个“官方”状态。\n典型TCP过程 所谓典型TCP过程，这个词是我定的，即上图中黑线表示的过程的有序集合。这些黑线组成的典型TCP过程不考虑同时打开与关闭、重置等特殊情况。本节描述这个过程。\n可以看到除了CLOSING，其他10种状态均在典型TCP过程中。\n开始时，客户端/服务端均处于CLOSED状态； 服务端进程启动，调用listen函数后，服务端由CLOSED转换为LISTEN； 客户端进程启动，调用connect函数后，TCP三路握手建立连接过程被激起，客户端发送第一路握手请求的SYN报文段，然后由CLOSED转换为SYN_SENT； 服务端接收到客户端发来的SYN报文段，发起第二路握手请求，向客户端发送SYNACK报文段，然后由LISTEN转换为SYN_RCVD； 客户端接收到服务端发来的SYNACK报文段，发起第三路握手请求，向服务端发送ACK报文段，然后由SYN_SENT转换为ESTABLISHED，至此，客户端已完成连接； 服务端收到客户端发来的ACK报文段，也由SYN_RCVD转换为ESTABLISHED，至此双方连接建立完成； ESTABLISHED是通信双方双向传输数据的状态； 尽管双方均可发起主动关闭操作，但我们以客户端负责执行主动关闭为例。\n数据传输结束，客户端调用close函数关闭套接字描述符，激起TCP四路握手关闭连接的过程，客户端发送第一路握手的FIN报文段，然后由ESTABLISHED转换为FIN_WAIT_1； 服务端收到客户端发来的FIN报文段，发起第二路握手，向客户端发送ACK报文段，然后由ESTABLISHED转换为CLOSE_WAIT； 客户端收到服务端发来的ACK报文段，什么都不发送，由FIN_WAIT_1转换为FIN_WAIT_2； 服务端调用close函数，发起第三路握手，向客户端发送FIN报文段，由CLOSE_WAIT转换为LAST_ACK； 客户端收到服务端发来的FIN报文段，发起第四路握手，向服务端发送ACK报文段，由FIN_WAIT_2转换为TIME_WAIT； 服务端收到客户端发来的ACK报文段，什么都不发送，由LAST_ACK转换为CLOSED，至此服务端关闭； 客户端等待2MSL，计时器超时后，客户端由TIME_WAIT转换为CLOSED，至此双方连接彻底关闭。 非典型TCP过程 TCP状态转换图中还有一些非典型过程，在图中用蓝色表示。下边我们描述一下这些部分。这些非典型过程包括以下内容：\n连接建立超时 同时打开 同时关闭 重置报文段（RST） 连接建立超时 有时会存在连接不能建立的情况，比如服务器关闭的情况。\n当客户端发送SYN报文段，但迟迟得不到回应的时候，客户端就会频繁地发送SYN报文段，直到达到限定的次数，客户端放弃与服务端进行连接，由SYN_SENT转换为CLOSED。\nLinux系统默认重试次数为5次。\n指数回退：首个SYN报文段发送后3秒发送第二个SYN报文段，第二个报文段发送后6秒后发送第三个SYN报文段，第三个报文段发送后12秒后发送第四个SYN报文段，以此类推，即每一次回退数值都是前一次的两倍。\n同时打开过程 TCP支持双方同时打开的情况，要实现同时打开，有两个要求：\n通信双方均有彼此的套接字地址结构sockaddr_in；（正常情况下，只有客户端知道服务端的套接字地址，而服务端不知道客户端的。）；\n通信双方在收到来自对方的SYN报文段之前必须先发送一个SYN报文段。\n由于双方均同时扮演了客户端与服务端的角色，所以不能将任何一方称为客户端或服务端。\n如上图所示，同时打开的过程如下：\n双方在CLOSED状态时，通过调用connect函数，均在接收到对方的SYN报文段之前，自己就先发送了一个SYN报文段，双方均进入SYN_SENT状态； 在接收到对方发来的SYN报文段后，双方均向彼此发送SYNACK报文段，并进入SYN_RCVD状态； 双方在接收到彼此的SYNACK报文段后，均进入ESTABLISHED状态，连接建立完成。 可以看到，同时打开过程需要交换四个报文段，比普通的三路握手增加了一个。\n同时关闭过程 在接收到对方发来的FIN报文段之前，双方均向对方发送FIN报文段，这会触发同时关闭过程。\n如上图，同时关闭过程如下：\n双方在ESTABLISHED状态时，通过调用close函数，均在收到对方的FIN报文段之前，向对方发送了FIN报文段，双方均进入FIN_WAIT_1状态； 双方并没有如预期收到对方的ACK报文段，而是收到了FIN报文段，双方均向对方回应ACK报文段，均进入CLOSING状态； 双方收到对方发来的ACK报文段后，均进入TIME_WAIT状态，待2MSL超时后，进入CLOSED状态，至此连接彻底关闭。 FIN报文段还包含一个ACK段用于确认对方最近一次发来的数据。\n可以看到同时关闭过程与正常关闭过程交换相同数量的报文段，二者的区别在于：\n正常关闭过程中报文段序列是不交叉的，一个发，另一个收到之后再发； 同时关闭过程中报文段序列是交叉的，一个发的同时另一个也再发。 同时关闭过程用到了一个正常过程中没有的状态：CLOSING。\n重置报文段（RST） 一个将TCP头部中的RST字段置1的报文段称为重置报文段，它用于关闭那些已经没有必要继续存在的连接。\n以下是常见的产生重置报文段的场景：\n客户端发起一个连接请求，服务端却没有相应的进程在目的端口监听时，服务端就会给该客户端发送一个重置报文段；\n终止一条连接。在任何时刻均可以发送一个重置报文段替代FIN来终止一条连接，通过这种方式终止连接时，任何排队的数据都将被抛弃，重置报文段立即发送出去；\n在不告知另一方的情况下，通信的一端关闭或终止了连接，将导致这条TCP连接处于半开状态。这通常发生在通信一方的主机崩溃的情况下。这种情况下只要不尝试通过这条半开连接传输数据，正常工作的一端将不会检测到另一端已经崩溃（因为崩溃的一端连重置报文段或者FIN报文段都没办法发出去）。这时如果崩溃的一端重新连接，它对这条连接上另一端发送过来的数据一无所知，TCP规定此时崩溃一方将回复一个重置报文段以关闭这个连接。\nTCP的TIME_WAIT状态的目的是让任何一个受制于与数据相关的关闭连接的数据被丢弃。在这段时期，等待的一方通常不需要任何操作，它只需要维持当前状态直到2MSL的计时结束。然而，如果它在这段时期内接收到来自于这条连接的一个重置报文段时，它的TIME_WAIT状态就会被破坏而提前进入CLOSED状态。\n为什么连接的被动关闭方会发送重置报文段呢？在连接的主动关闭方进入TIME_WAIT状态前，它回复一个ACK以告知被动关闭方自己已经接收到FIN报文段，被动关闭方收到这个ACK后随即进入CLOSED状态，此时主动关闭方还在TIME_WAIT状态等待2MSL计时结束。在这个时期，网络中可能存在延时，被动关闭方之前发送的对某数据的ACK在这个时候才姗姗来迟，此时这个ACK对处于TIME_WAIT状态的主动关闭方来说是旧的消息，因此它会发送一个ACK作为响应，其中包含了最新的序列号与ACK值。已经处于CLOSED状态的被动关闭方收到这个ACK后就会发送一个重置报文段作为响应。这会导致另一端的TIME_WAIT状态过早结束而进入CLOSED状态。解决这个错误的最简单方法就是让处于TIME_WAIT状态的TCP连接不对重置报文段做出响应。\nTCP其他问题 TIME_WAIT状态 在TIME_WAIT状态中，TCP将会等待两倍于最大段生存期（MSL）的时间，MSL代表任何报文段在被丢弃前在网络中被允许存在的最长时间。\nTIME_WAIT状态有两个存在的理由：\n可靠地实现TCP全双工连接的终止； 第一个理由可以通过断开连接时客户端最终发送给服务端的，以响应服务端的FIN报文段的ACK报文段丢失来解释。服务端迟迟收不到ACK，服务端就重发它的FIN报文段，如果没有TIME_WAIT状态，客户端就直接处于CLOSED状态了，那客户端就没有该连接的信息了，客户端就会回复给服务端一个重置报文段，这就不是正常断开连接的过程了；所以客户端需要有一个TIME_WAIT状态，来维护这个连接，从而可以发送ACK来响应服务端重传过来的FIN报文段。\n允许老的重复分组在网络中消逝。 第二个理由解释：如果一条TCP连接关闭之后，双方再以相同的四元组建立新连接，如果旧连接中有一些分组还在网络中，由于IP地址和端口号相同，这些分组就可能到达新连接，这样就会产生混乱。为了避免这个情况，设置TIME_WAIT状态，等待2MSL时间，在这段时间内，旧连接的四元组仍被占用，无法用相同的四元组建立新连接，这样就避免了新旧连接的数据混乱；同时，2MSL的时间足够让旧连接的分组在网络中消逝，这样再用相同的四元组建立连接时，就可以保证新连接不会接受到旧连接的分组。\nlisten函数的第二个参数 1 2 3 #include \u0026lt;sys/socket.h\u0026gt; int listen(int sockfd, int backlog); //成功返回0，出错返回-1 backlog参数规定了内核应为sockfd排队的最大连接个数，为了理解backlog参数，我们必须认识到内核为每一个监听套接字维护两个队列：\n未完成连接队列：那些处于SYN_RCVD状态的套接字组成的队列。即客户端发来的SYN报文段已到达服务端，服务端正在等待完成三路握手过程； 已完成连接队列：那些处于ESTABLISHED状态的套接字组成的队列，即每个已完成三路握手过程的客户端对应该队列中的一项。 上述两队列之和不能超过backlog。\nTCP半关闭 TCP支持半关闭操作。\n伯克利套接字的API提供了半关闭操作，应用程序只需要调用shutdown函数来代替基本的close函数，就能实现上述操作。\n初始序列号的选取 由于客户端和服务端之间的TCP连接是由客户端的IP地址及端口号和服务端的IP地址及端口号构成的四元组所确定的，因此当客户端出现了故障把这个TCP连接断开了，之后再以相同的四元组建立新的TCP连接（也就是说客户端和服务端两次建立TCP连接都是使用了相同的IP地址和端口号），就会出现数据乱序的问题。\n换句话说，只要客户端发送了一个TCP报文段，且这个TCP报文段的四元组和序列号，和之前的TCP连接（四元组和序列号）相同的话，就会被服务端确认。这其实反映了TCP的脆弱性，如果TCP的这种缺点被一些恶意攻击者加以利用：选择合适的序列号、IP地址和端口号的话，就能伪造出一个TCP报文段，从而打断正常的TCP连接。那么通过谨慎选取初始化序列号的方式（通过算法来随机生成序列号）就会使序列号难以猜出，也就不容易利用这种缺点来进行一些恶意攻击行为。\nLinux系统采用基于时钟的方案来选取初始化序列号。\nTCP MTU的发现 MTU，即最大路径传输单元，指经过两台主机之间路径的所有网络报文段中最大传输单元的最小值。\n当中间路由器的最大传输单元小于任何一个通信端的最大段大小（MSS）时，TCP就会执行路径最大传输单元发现过程：\nIPv4头部中有一个3位的标志字段，目前只有低两位有意义，其中中间一位叫做DF位（Don\u0026rsquo;t Fragment），当该位置1时代表不能分片。\nTCP发送端发送数据时将IP数据报中的DF位置1，这样中间路由器如果收到分片才能处理的过大的数据报时，中间路由器不会分片，而是将该数据报丢弃； 路由器通过ICMP把链路上的MTU值通知TCP发送端； TCP发送端获得ICMP所通知的MTU值以后，将它设置为当前的MTU。TCP发送端发送根据这个MTU对数据报进行分片处理。如此反复，直到数据报被发送到目标主机为止没有再收到任何ICMP，就认为最后一次ICMP所通知的MTU即是一个合适的MTU值。 TCP选项 TCP头部中包含了多个选项，常见的选项如下：\nEOL：指出了选项列表的结尾，表示选项列表结束，说明无需对选项列表再进行处理。 NOP：允许发送者在必要的时候用多个4字节组填充某个字段。 MSS：最大段大小，即TCP协议所允许的从对方接收到的最大报文段。 一方把MSS发送给对方时，不是在商量，而是在通知对方，它表示在整个连接过程中都不愿意接收比MSS值大的报文段。\nMSS的值是TCP数据载荷部分的字节数，而不包括TCP与IP头部。\n建立一条TCP连接时，通信双方应该在SYN报文段的MSS选项中向对方说明自己允许的最大段大小。\nMSS的默认值是536字节，加上TCP头部20字节和IPv4头部20字节，一共组成576字节的IPv4数据报，这是标准中规定的任何主机都应该能处理的IPv4数据报的最小大小；\nIPv4中常见的MSS值为1460字节，加上TCP头部20字节和IPv4头部20字节，共组成1500字节的IPv4数据报，这正好是链路层中以太网的最大传输单元（MTU）。\n由于IPv6头部比IPv4头部大20字节，所以MSS值相应减20字节，为1440字节。\nSACK：选择确认选项。接收方通过这个选项来描述乱序的数据（空洞），帮助发送方重传； 窗口缩放选项：用于将TCP窗口大小字段的范围从16位增加至30位。该选项作为16位窗口大小的比例因子，最大比例数值为14，可将窗口大小的最大值由65535字节扩展至1GB； 窗口缩放选项只能出现在SYN报文段中，连接建立后比例因子与方向绑定，每个方向的比例因子可以各不相同。\n时间戳选项：发送方根据该选项通过每一个接收到的ACK来估算TCP连接的往返时间，并根据结果设置重传超时； 用户超时选项：指明了TCP发送者在确认对方未能成功接收数据之前愿意等待该数据ACK确认的时间； 认证选项：用于增强连接的安全性。 ","date":"2021-05-17T00:14:35-07:00","permalink":"https://bitdove.github.io/posts/tcp-introduction-deeper/","title":"【一文读懂】TCP协议（下）"},{"content":"引言 Echo客户端/服务端程序应该是网络编程领域的入门首选，可以视为网络编程领域的HelloWorld程序。\n为了深入学习网络编程，我写了这样一个程序，姑且叫它Simplest_Socket。这确实是最简单的socket通信程序。与一般的Echo服务器不同，Simplest_Socket会把客户端传来的英文字符串转换为大写再返回给客户端；而不像Echo服务器那样原样返回。\n这样设计的目的在于体现服务器的“服务”功能，尽管只是把小写转为大写，但这确实是一项服务。\n思路 TCP套接字通信由一个四元组确定一个端到端通信，即：\n（客户端IP地址，客户端端口号，服务端IP地址，服务端端口号）\n整体的时序图如下：\n上图中数据传输采用了read/write函数，套接字是一种文件类型，所以用这两个文件IO来读写套接字描述符也可以；但是套接字与普通文件又有些不同，在\u0026lt;sys/socket.h\u0026gt;中声明了专门用于socket的IO函数：send函数和recv函数。Simplest_Socket采用这两个函数来读写套接字。\n客户端 指定服务端套接字地址结构 客户端作为连接的主动发起方，它需要知道它要连到哪个服务器的哪个端口，所以在客户端程序中，首先要定义服务端的套接字地址结构，在IPv4因特网中，套接字地址结构由结构体sockaddr_in定义，它声明在头文件\u0026lt;arpa/inet.h\u0026gt;中。在这个结构体中：\nsin_family用于指定使用的网络层协议IPv4，取值为AF_INET； in_port_t被定义为uint16_t，sin_port指定端口号，由于是无符号16位整型，所以其取值范围为0~65535； sin_addr用于指定IPv4地址，它也是一个结构体in_addr，in_addr_t被定义为uint32_t，即无符号32位整型，正好与IPv4地址的大小对应。 1 2 3 4 5 6 7 8 9 #include \u0026lt;arpa/inet.h\u0026gt; struct in_addr{ in_addr_t s_addr; //IPv4地址 }; struct sockaddr_in{ sa_family_t sin_family; //协议族 in_port_t sin_port; //端口号 struct in_addr sin_addr; //IPv4地址 } 我们所定义的存放IP地址和端口号的变量均已主机字节序存放在我们的本地主机上，当进行网络通信时，需要将它们转化为网络字节序，这些工作由头文件\u0026lt;arpa/inet.h\u0026gt;中声明的htons函数和inet_pton函数来完成：\nhtons函数用于把将无符号16位整型数据由主机字节序转为网络字节序，端口号正好适用； inet_pton函数用于将主机字节序的点分十进制IP地址转换为网络字节序的二进制IP地址，IPv4地址和IPv6地址均可用该函数。 1 2 3 4 5 #include \u0026lt;arpa/inet.h\u0026gt; uint16_t htons(uint16_t hostint16); int inet_pton(int domain, const char *restrict str, void *restrict addr); 所以对于我们的客户端，我们可以定义如下套接字地址结构：\n1 2 3 4 5 6 7 8 9 10 #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;string.h\u0026gt; const char* server_ip = \u0026#34;127.0.0.1\u0026#34;; //服务端IP地址 const uint16_t SERVER_PORT = 2021; //服务端监听端口号 struct sockaddr_in server_sockaddr; memset(\u0026amp;server_sockaddr, 0, sizeof(server_sockaddr)); server_sockaddr.sin_family = AF_INET; //指定IPv4 server_sockaddr.sin_port = htons(SERVER_PORT); inet_pton(AF_INET, server_ip, \u0026amp;server_sockaddr.sin_addr); 声明在\u0026lt;string.h\u0026gt;中的memset函数可以用于初始化新申请的空间，将其置为指定值。\n创建套接字 既然要使用套接字，当然第一件事就是调用socket函数创建套接字。\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; int socket(int family, int type, int protocol); //成功返回非负套接字描述符，出错返回-1 对于我们的客户端：\nfamily：设置协议域为AF_INET，即IPv4； type：设置套接字类型为SOCK_STREAM，即字节流套接字； protocol：设置该参数为0，表示选择根据family和type组合系统提供的默认传输层协议。对于AF_INET和SOCK_STREAM组合，默认协议为TCP。 使用perror函数将错误原因输出到标准错误（stderr）：\n1 2 3 #include \u0026lt;stdio.h\u0026gt; void perror(const char *str); //输出格式为\u0026#34;str:错误原因\u0026#34;,错误原因依照全局变量errno的值来决定要输出的字符串 所以在客户端中这样创建客户端的套接字：\n1 2 3 4 5 6 7 8 #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int client_fd = socket(AF_INET, SOCK_STREAM, 0); //指定TCP协议 if(client_fd \u0026lt; 0){ perror(\u0026#34;socket\u0026#34;); exit(1); } 发起连接 创建完套接字之后，作为主动方的客户端要做的就是发起连接，这由connect函数完成：\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; int connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen); //成功返回0；出错返回-1 sockfd参数即客户端socket函数返回的套接字描述符； servaddr参数指向一个指明了服务端IP地址和端口号的套接字地址结构，即我们之前创建的server_sockaddr； addrlen参数是servaddr参数指向的地址结构的大小，可由sizeof()运算得到。 所以，在客户端中这样发起连接：\n1 2 3 4 5 6 7 #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; if(connect(client_fd, (struct sockaddr*) \u0026amp;server_sockaddr, sizeof(server_sockaddr)) \u0026lt; 0){ perror(\u0026#34;connect\u0026#34;); exit(1); } 调用connect函数将激发TCP的三路握手过程，详情以后分析TCP状态机的时候再讲。\n数据传输 客户端发起连接之后，服务端接收连接，双方完成TCP的三路握手之后，通信链路就建立起来了，客户端可以传输数据了。\n在传输数据之前，我们定义了一个发送缓冲区sendbuf和一个接收缓冲区recvbuf。\n对于Simplest_Socket来说，客户端传输的数据就是用户输入的英文字符串，所以while函数的条件我们设置为fgets函数，fgets函数是一个声明在\u0026lt;stdio.h\u0026gt;的标准IO库函数：\n1 2 3 #include \u0026lt;stdio.h\u0026gt; char *fgets(char *restrict buf, int n, FILE *restrict fp); //成功返回buf；若已到达文件尾或出错返回NULL fgets函数从指定的流fp读取字符送到长度为n的缓冲区buf，一直读到下一个换行符为止，但不会超过n-1个字符。 fgets函数：缓冲区buf以null字节结尾。如果该行（包括换行符）的字符数超过n-1，则fgets只返回一个不完整的行，但是buf总是以null结尾。对fgets的下一次调用会继续读该行。\n我们从标准输入（stdin）读取用户输入的数据到sendbuf。然后就可以使用send函数把sendbuf中的数据通过客户端的套接字传输给服务端，\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; ssize_t send(int sockfd, const void *buf, size_t nbytes, int flags); //成功返回发送的字节数；出错返回-1 send函数将buf中的nbytes个字节的数据通过套接字描述符sockfd发送给服务端，flags参数一般置0。 我们可以用strlen函数获取sendbuf中实际数据的长度：\n1 size_t strlen(const char* str); strlen函数从字符串的开头位置依次向后计数，直到遇见\\0，然后返回计时器的值。最终统计的字符串长度不包括\\0。 我们定义如果用户输入的是Q\\n，表示退出。这个用strcmp函数来完成：\n1 2 #include \u0026lt;string.h\u0026gt; int strcmp(const char *str1, const char *str2) strcmp函数返回值为0则表示参与比较的两个字符串相等。 发送完数据之后要做的就是要接收服务端返回的数据，这由recv函数来完成：\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; ssize_t recv(int sockfd, void *buf, size_t nbytes, int flags); //返回值：返回数据的字节长度；若无可用数据或对等方已经按序结束，返回0；出错返回-1 recv函数通过套接字描述符sockfd接收数据至buf，nbytes参数指定buf的大小，flags参数一般置0。 接收完数据后，通过fputs函数把recvbuf的内容输出到标准输出（stdout）。\n1 2 #include \u0026lt;stdio.h\u0026gt; int fputs(const char *restrict str, FILE *restrict fp); fputs函数将一个以null字节终止的字符串str写到指定的流fp，尾端的终止符null不写出。 在准备发送和接收下一次的新数据之前，我们用memset函数将sendbuf和recvbuf的空间全部置0：\n1 2 #include \u0026lt;string.h\u0026gt; void *memset(void *str, int c, size_t n) memset函数将参数 str 所指向的字符串的前 n 个字符置为值c。 所以在客户端这样写数据传输部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;string.h\u0026gt; const int BUFFER_SIZE = 1024; //定义缓冲区大小 char sendbuf[BUFFER_SIZE]; char recvbuf[BUFFER_SIZE]; while(fgets(sendbuf, sizeof(sendbuf), stdin)){ //从stdin读入待传输数据至sendbuf send(client_fd, sendbuf, strlen(sendbuf), 0); //将sendbuf中的数据通过client_fd套接字传输 if(strcmp(sendbuf, \u0026#34;Q\\n\u0026#34;) == 0) //输入Q表示退出 break; recv(client_fd, recvbuf, sizeof(recvbuf), 0); //从client_fd套接字接收数据，保存至recvbuf fputs(recvbuf, stdout);//将recvbuf中的数据输出至stdout memset(sendbuf, 0, sizeof(sendbuf));//将sendbuf的内存值置0 memset(recvbuf, 0, sizeof(recvbuf));//将recvbuf的内存值置0 } 关闭连接 当用户输入Q\\n，表示要退出连接。\n因为套接字也是一种文件类型，所以我们可以像关闭普通的文件描述符一样，用close函数来关闭它。\n1 2 3 #include \u0026lt;unistd.h\u0026gt; int close(int fd); //成功返回0；出错返回-1 所以在客户端这样写关闭连接部分：\n1 2 3 #include \u0026lt;unistd.h\u0026gt; close(client_fd); 服务端 服务端部分内容与客户端一致，重复部分不再赘述。\n定义服务端套接字地址结构 这一部分与客户端相同，也是定义服务端的套接字地址结构。\n创建监听套接字 服务端作为被动接收连接的一方，需要创建一个监听套接字，这个也跟客户端创建套接字一样。\n绑定 对于服务端，我们一般还会指定一个固定的端口号，并且这个端口号还应该让想用这个服务器的客户端知道，也就是服务端的监听套接字要绑定一个固定的套接字地址结构，这样客户端在想要连接到这个服务端时，才可以知道我应该连接到哪个套接字地址结构，如果你的端口号一直变，那客户端就比较难受了。\n这个绑定工作由bind函数完成。\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; int bind(int sockfd, const struct sockaddr *myaddr, socklen_t addrlen); //成功返回0；出错返回-1 bind函数将套接字sockfd绑定到套接字地址结构myaddr，addrlen为myaddr的长度，可由sizeof()得到。 转化为被动套接字 由socket函数创建的套接字是一个主动套接字，即它是一个会调用connect函数发起连接的客户端套接字。\n那问题就出来了，我服务端的套接字可不是要主动发起连接的，而是要被动接受连接的。那么就需要把socket函数创建的主动套接字转化为被动套接字，这个工作由listen函数来完成：\n1 2 3 #include \u0026lt;sys/socket.h\u0026gt; int listen(int sockfd, int backlog); //成功返回0；出错返回-1 listen函数把主动套接字sockfd转化为被动套接字，指示内核应该接受指向该套接字的连接请求。 backlog参数规定了内核应该为sockfd套接字排队的最大连接个数。 调用listen函数会使TCP服务器状态由ClOSED转为LISTEN。\n接收请求 接下来就是接收客户端的连接请求，该工作由accept函数完成。\n1 2 #include \u0026lt;sys/socket.h\u0026gt; int accept(int sockfd, struct sockaddr *cliaddr, socklen_t *addrlen); accept函数接收监听套接字描述符，并返回一个已连接套接字描述符。 cliaddr参数和addrlen用于返回客户的套接字地址结构及其大小，若不关心客户端的身份，将二者设为NULL即可。 数据传输 数据传输过程也与客户端没有太大不同。\n关闭连接 关闭连接也与客户端相同，只是服务端要关闭两个套接字：\n监听套接字 已连接套接字 源程序 客户端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #include \u0026lt;sys/socket.h\u0026gt; //socket系列函数头文件 #include \u0026lt;arpa/inet.h\u0026gt; //sockaddr_in结构体、inet_pton函数和htons函数头文件 #include \u0026lt;string.h\u0026gt; //strlen函数、strcmp函数和memset函数头文件 #include \u0026lt;unistd.h\u0026gt; //close函数头文件 #include \u0026lt;stdlib.h\u0026gt; //exit函数头文件 #include \u0026lt;stdio.h\u0026gt; //fgets函数、fputs函数、perror函数头文件 const int BUFFER_SIZE = 1024; //定义缓冲区大小 const char* server_ip = \u0026#34;127.0.0.1\u0026#34;; //服务端IP地址 const uint16_t SERVER_PORT = 2021; //服务端监听端口号 int main(){ //定义服务端套接字地址结构 struct sockaddr_in server_sockaddr; memset(\u0026amp;server_sockaddr, 0, sizeof(server_sockaddr)); server_sockaddr.sin_family = AF_INET; //指定IPv4 server_sockaddr.sin_port = htons(SERVER_PORT); inet_pton(AF_INET, server_ip, \u0026amp;server_sockaddr.sin_addr); //创建客户端套接字描述符 int client_fd = socket(AF_INET, SOCK_STREAM, 0); //指定TCP协议 if(client_fd \u0026lt; 0){ perror(\u0026#34;socket\u0026#34;); exit(1); } //发起连接 if(connect(client_fd, (struct sockaddr*) \u0026amp;server_sockaddr, sizeof(server_sockaddr)) \u0026lt; 0){ perror(\u0026#34;connect\u0026#34;); exit(1); } //开始数据传输 char sendbuf[BUFFER_SIZE]; char recvbuf[BUFFER_SIZE]; while(fgets(sendbuf, sizeof(sendbuf), stdin)){ //从stdin读入待传输数据至sendbuf send(client_fd, sendbuf, strlen(sendbuf), 0); //将sendbuf中的数据通过client_fd套接字传输 if(strcmp(sendbuf, \u0026#34;Q\\n\u0026#34;) == 0) //输入Q表示退出 break; recv(client_fd, recvbuf, sizeof(recvbuf), 0); //从client_fd套接字接收数据，保存至recvbuf fputs(recvbuf, stdout);//将recvbuf中的数据输出至stdout memset(sendbuf, 0, sizeof(sendbuf));//将sendbuf的内存值置0 memset(recvbuf, 0, sizeof(recvbuf));//将recvbuf的内存值置0 } //关闭连接 close(client_fd); return 0; } 服务端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 #include \u0026lt;sys/socket.h\u0026gt; //socket系列函数头文件 #include \u0026lt;arpa/inet.h\u0026gt; //sockaddr_in结构体、inet_pton函数、htons函数头文件 #include \u0026lt;string.h\u0026gt; //strlen函数、strcmp函数和memset函数头文件 #include \u0026lt;unistd.h\u0026gt; //close函数头文件 #include \u0026lt;stdlib.h\u0026gt; //exit函数头文件 #include \u0026lt;stdio.h\u0026gt; //perror函数头文件 #include \u0026lt;ctype.h\u0026gt; //toupper函数头文件 const char* server_ip = \u0026#34;127.0.0.1\u0026#34;; //指定服务端IP地址 const uint16_t SERVER_PORT = 2021;//指定监听端口号 const int QUEUE = 1024; //用于listen函数第二个参数，指定内核应为相应套接字排队的最大连接数 const int BUFFER_SIZE = 1024;//指定缓冲区大小 int main(){ //定义服务端套接字地址结构并赋值 struct sockaddr_in server_sockaddr; memset(\u0026amp;server_sockaddr, 0, sizeof(server_sockaddr)); server_sockaddr.sin_family = AF_INET; //指定IPv4 server_sockaddr.sin_port = htons(SERVER_PORT); inet_pton(AF_INET, server_ip, \u0026amp;server_sockaddr.sin_addr); //创建一个监听套接字描述符 int listen_fd = socket(AF_INET, SOCK_STREAM, 0); //指定TCP协议 if(listen_fd \u0026lt; 0){ perror(\u0026#34;socket\u0026#34;); exit(1); } //将监听套接字描述符绑定到套接字地址结构 if(bind(listen_fd, (struct sockaddr*) \u0026amp;server_sockaddr, sizeof(server_sockaddr)) \u0026lt; 0){ perror(\u0026#34;bind\u0026#34;); exit(1); } //开始监听 if(listen(listen_fd, QUEUE) \u0026lt; 0){ perror(\u0026#34;listen\u0026#34;); exit(1); } //接受连接请求，创建 已连接套接字描述符 int conn_fd = accept(listen_fd, NULL, NULL); if(conn_fd \u0026lt; 0){ perror(\u0026#34;accept\u0026#34;); exit(1); } //开始数据传输 char sendbuf[BUFFER_SIZE]; char recvbuf[BUFFER_SIZE]; while(1){ memset(recvbuf, 0, sizeof(recvbuf)); memset(sendbuf, 0, sizeof(sendbuf)); recv(conn_fd, recvbuf, sizeof(recvbuf), 0); //从conn_fd套接字接收数据，保存至recvbuf if(strcmp(recvbuf, \u0026#34;Q\\n\u0026#34;) == 0) //如果收到的数据是Q，表示退出 break; fputs(recvbuf, stdout); //将收到的数据原样输出至stdout //将recvbuf中的小写字母转为大写，新数据保存至sendbuf for(int i = 0; i \u0026lt; strlen(recvbuf); ++i){ if(islower(recvbuf[i])) sendbuf[i] = toupper(recvbuf[i]); else sendbuf[i] = recvbuf[i]; } send(conn_fd, sendbuf, strlen(sendbuf), 0); //将sendbuf中的数据通过conn_fd套接字传输 } //关闭连接及监听描述符 close(conn_fd); close(listen_fd); return 0; } 数据流通图 ","date":"2021-05-14T06:44:38-07:00","permalink":"https://bitdove.github.io/posts/helloworld-on-network-programming/","title":"网络编程领域的HelloWorld程序"},{"content":"引言 由于每个进程有自己独立的虚拟地址空间，为了打破进程与进程之间的“柏林墙”而实现通信，多进程更多的是考虑进程之间如何通信的问题；\n而同一进程内的多个线程共享同一地址空间，为了避免多个线程同时访问数据造成的混乱，多线程之间更多的是考虑线程之间的同步问题。\n所谓同步，即协同步调，按预定的先后次序访问共享资源，以免造成混乱。\n线程同步：即当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作， 其他线程才能对该内存地址进行操作，而其他线程又处于等待状态。\n线程同步的实现方式有6种：互斥量、读写锁、条件变量、自旋锁、屏障、信号量。\n由于笔者主要学习UNIX环境的编程，所以这里只介绍UNIX环境常用的线程同步方式，即POSIX线程库（Pthreads）提供的线程同步接口。本文不会涉及Windows端的线程同步方式，如临界区（CriticalSection）等。\n生产者-消费者模型 为了更好地讲清楚以下的线程同步方式，我决定介绍每种线程同步方式时，都搭配一个实际的应用案例。这个应用案例我决定选择生产者-消费者模型这一经典问题。\n问题描述：有一群生产者进程在生产产品，并将这些产品提供给消费者进程进行消费，生产者进程和消费者进程可以并发执行，在两者之间设置了一个具有n个缓冲区的缓冲池，生产者进程需要将所生产的产品放到一个缓冲区中，消费者进程可以从缓冲区中取走产品消费。\n当生产者生产了一个产品之后，缓冲区里的产品就会+1；同样，如果消费者从缓冲区里边消费一个产品，缓冲区里的产品就会-1。这看起来没有任何问题。\n但是在计算机中，这个缓冲区是位于高速缓存或主存上的，如果说生产者或消费者要操作里边的数据时，就分为三个步骤：\n取出数据放到寄存器中 register = count；\n在CPU的寄存器中将register = register±1；register = register + 1表示生产者生产了一个产品；register = register - 1表示消费者消费了一个产品。\n将register放回缓冲区 count = register。\n当生产者和消费者并发执行的时候，这就会出现问题，因为上述三个操作不具备原子性，即生产者和消费者的这三个操作可能会交叉执行，而不是一方执行完，另一方再执行。见下图，红色部分为生产者生产的过程，蓝色的为消费者消费的过程：\n图右描述了一种可能出现的执行流程（假设count初始值为10）：\n生产者线程获得时间片，执行其第一步：把count值放到寄存器，即register = count；执行之后生产者线程私有的register和共享的count值均为10； 生产者线程时间片未耗尽，执行其第二步：在寄存器中加1，即register = register + 1；执行之后生产者线程私有的register值为11，共享的count值为10； 此时，生产者线程时间片耗尽，CPU调度消费者进程执行，消费者执行其第一步：把count值放到寄存器，即register = count；执行之后消费者线程私有的register和共享的count值均为10； 消费者时间片未耗尽，消费者执行其第二步：在寄存器中减1，即register = register - 1；执行之后消费者线程私有的register值为9，共享的count值为10； 消费者时间片未耗尽，消费者执行其第三步：把register值放回缓冲区，即count = register；执行之后消费者私有的register和共享的count值均为9； 此时，消费者线程时间片耗尽，CPU调度生产者进程执行，生产者继续执行它的第三步：count = register；执行之后生产者私有的register和共享的count值均为11。 问题就出现了：整个过程中生产者生产了一个产品，消费者消费了一个产品，那count值前后应该不变，仍为10才对，现在却是11，说明这个数据是错误的。错误的原因就在于这两个进程并发的执行，他们轮流在操作缓冲区，导致缓冲区中的数据不一致，这个就是生产者-消费者的问题。\n以下程序模拟了生产者消费者问题：生产者生产1亿个产品，消费者消费1亿个产品，最终num应该为0。但事实并非如此。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;pthread.h\u0026gt; int num = 0;//临界资源 void *producer(void* arg){ int times = 100000000;//循环一亿次 while(times--) num += 1;//每次生产一个产品 } void *consumer(void* arg){ int times = 100000000; while(times--) num -= 1;//每次消费一个产品 } int main(){ pthread_t thread_prod,thread_cons; pthread_create(\u0026amp;thread_prod, NULL, \u0026amp;producer, NULL); pthread_create(\u0026amp;thread_cons, NULL, \u0026amp;consumer, NULL); pthread_join(thread_prod, NULL); pthread_join(thread_cons, NULL); printf(\u0026#34;num = %d\\n\u0026#34;, num); } 该程序每次执行的结果并不相同，num值不为0：\n关于这个程序有一点要注意，循环次数要设的大一点。我一开始设的100万次，由于100万次太少了，每个线程的时间片足够一次执行完所有循环而不被其他线程打断，所以最终会输出num等于0。\n设置成1亿次之后就好了，线程的时间片无法一次执行完所有循环，执行完一部分就被CPU喊停，调度另一线程执行了，所以会出现num值不为0；且由于每次执行，线程之间的调度无法原样重现，所以num值每次都不一样。\n互斥量 互斥量（mutex）本质上说是一把锁，在访问共享资源前对互斥量进行设置（加锁），在访问完成后释放（解锁）互斥量。\n对互斥量加锁以后，任何其他试图再次对互斥量加锁的线程都会被阻塞，直至当前线程释放该互斥量。\nPOSIX互斥量API POSIX线程库（Pthreads）提供了互斥量接口，互斥量用pthread_mutex_t数据类型来表示。\n使用互斥量前必须首先进行初始化，有两种初始化方式：\n把它设置为常量PTHREAD_MUTEX_INITIALIZER（仅适用于静态分配的互斥量）； 调用pthread_mutex_init函数进行初始化。 对于动态分配的互斥量（如new和malloc），在释放内存前需要调用pthread_mutex_destroy函数。\n其常见API如下：\n1 2 3 4 5 #include \u0026lt;pthread.h\u0026gt; int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr); int pthread_mutex_destroy(pthread_mutex_t *mutex); //返回值：成功返回0；出错返回错误编号 要用默认属性初始化互斥量，只需把attr参数设为NULL。\n1 2 3 4 5 #include \u0026lt;pthread.h\u0026gt; int pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); //返回值：成功返回0；出错返回错误编号 pthread_mutex_lock函数用于给互斥量加锁，如果互斥量已上锁，则调用该函数的线程将阻塞直到互斥量被解锁； 如果线程不希望被阻塞，它可以使用pthread_mutex_trylock函数尝试对互斥量进行加锁，如果未加锁，则锁住互斥量并返回0；如果已加锁，则返回EBUSY； pthread_mutex_unlock函数用于对互斥量解锁。 1 2 3 4 5 #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;time.h\u0026gt; int pthread_mutex_timedlock(pthread_mutex_t *restrict mutex, const struct timespec *restrict tsptr); //成功返回0；出错返回错误编号 当线程试图获取一个已加锁的互斥量时，pthread_mutex_timedlock函数允许绑定线程阻塞时间。在达到超时时间值时，该函数不会对互斥量加锁，而是返回错误码ETIMEDOUT。 超时指定愿意等待的绝对时间，用timespec结构表示，以秒和纳秒描述时间。\n互斥量解决生产者消费者问题 程序如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int num = 0; pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; void *producer(void* arg){ int times = 100000000; while(times--){ pthread_mutex_lock(\u0026amp;mutex); num += 1; pthread_mutex_unlock(\u0026amp;mutex); } } void *consumer(void* arg){ int times = 100000000; while(times--){ pthread_mutex_lock(\u0026amp;mutex); num -= 1; pthread_mutex_unlock(\u0026amp;mutex); } } int main(){ pthread_t thread_prod, thread_cons; pthread_create(\u0026amp;thread_prod, NULL, \u0026amp;producer, NULL); pthread_create(\u0026amp;thread_cons, NULL, \u0026amp;consumer, NULL); pthread_join(thread_prod, NULL); pthread_join(thread_cons, NULL); printf(\u0026#34;num = %d\\n\u0026#34;, num); } 直接结果如下：\n可见，使用互斥量同步多线程共享资源的访问后，输出就如预期了，每次输出都是0。\n执行的时候会明显感觉到很慢，特意用time命令测试了下，上述程序需要近4秒钟才可以执行完。所以加锁会带来性能的损耗。\n读写锁 互斥量只有两种状态：加锁和不加锁；且一次只有一个线程可以对其加锁；\n读写锁有三种状态：读模式加锁、写模式加锁和不加锁；一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。\n读写锁非常适合对数据结构读的次数远大于写的情况。\nPOSIX读写锁API 读写锁在使用之前必须初始化，在释放它们的底层内存之前必须销毁。\n1 2 3 4 5 #include \u0026lt;pthread.h\u0026gt; int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr); int pthread_rwlock_destroy(pthread_rwlock_t *rwlock); //两个函数返回值：成功返回0；出错返回错误编号 要用默认属性初始化读写锁，只需把attr参数设为NULL。\n对于静态分配的读写锁，也可以使用常量PTHREAD_RWLOCK_INITIALIZER来初始化。\n1 2 3 4 5 #include \u0026lt;pthread.h\u0026gt; int pthread_mutex_rdlock(pthread_rwlock_t *rwlock); int pthread_mutex_wrlock(pthread_rwlock_t *rwlock); int pthread_mutex_unlock(pthread_rwlock_t *rwlock); //成功返回0；出错返回错误编号 pthread_mutex_rdlock函数以读模式获取读写锁； pthread_mutex_wrlock函数以写模式获取读写锁； pthread_mutex_unlock函数用于解锁。 1 2 3 4 5 6 7 #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;time.h\u0026gt; int pthread_rwlock_timedrdlock(pthread_rwlock_t *restrict rwlock, const struct timespec *restrict tsptr); int pthread_rwlock_timedwrlock(pthread_rwlock_t *restrict rwlock, const struct timespec *restrict tsptr); //成功返回0；出错返回错误编号 上边两个函数用于指定线程应该停止阻塞的时间。\n读写锁解决读者写者问题 读者写者问题与之前的生产者消费者问题不同：读者线程只去读取共享资源但不会修改它，而写者线程会修改共享资源。用读写锁可以很好的解决读者写者问题。读者线程以读模式获取锁，这样不影响其他线程以读模式获取锁；写者线程以写模式获取锁，这样在修改共享资源期间，其他线程无法访问该共享资源。\n生产者消费者问题中的生产者线程和消费者线程实际上都是“写者”线程，因为它们都会修改共享资源。\n以下程序使用读写锁（互斥量）解决了读者写者问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int num = 0; pthread_rwlock_t rwlock = PTHREAD_RWLOCK_INITIALIZER; //pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; void *reader(void* arg){ int times = 100000000; while(times--){ pthread_rwlock_rdlock(\u0026amp;rwlock); //pthread_mutex_lock(\u0026amp;mutex); if(times%1000 == 0) usleep(10); pthread_rwlock_unlock(\u0026amp;rwlock); //pthread_mutex_unlock(\u0026amp;mutex); } } void *writer(void* arg){ int times = 100000000; while(times--){ pthread_rwlock_wrlock(\u0026amp;rwlock); //pthread_mutex_lock(\u0026amp;mutex); num += 1; pthread_rwlock_unlock(\u0026amp;rwlock); //pthread_mutex_unlock(\u0026amp;mutex); } } int main(){ pthread_t writer_1, reader_1, reader_2; pthread_create(\u0026amp;writer_1, NULL, \u0026amp;writer, NULL); pthread_create(\u0026amp;reader_1, NULL, \u0026amp;reader, NULL); pthread_create(\u0026amp;reader_2, NULL, \u0026amp;reader, NULL); pthread_join(writer_1, NULL); pthread_join(reader_1, NULL); pthread_join(reader_2, NULL); printf(\u0026#34;num = %d\\n\u0026#34;, num); } 使用读写锁程序执行时间如下：\n换成互斥量程序执行时间如下：\n可以明显地看出，对于多读者少写者的情况，读写锁要比互斥量效率高一些。\n其实读写锁也可以解决上边的生产者消费者问题，就是生产者线程和消费者线程都是使用写模式对共享资源加锁。我测试了下，执行时间大概是8秒钟，是互斥量的两倍。所以用读写锁解决生产者消费者问题不仅没必要而且开销大。\n问题的本质在于，生产者消费者问题没有把共享资源的访问作出读和写的细分，无论是生产者还是消费者对共享资源都是写，所以在这个问题里，读写锁发挥不出它的优势，读写锁还是更适合多读少写的情况。\n条件变量 条件变量允许线程睡眠，直到满足某种条件，当满足条件时，可以向该线程发送信号，通知并唤醒该线程。\n条件变量通常与互斥量配合一起使用。条件变量由互斥量保护，线程在改变条件状态之前必须首先锁住互斥量，其他线程在获得互斥量之前不会察觉到条件的改变，因为必须在锁住互斥量之后它才可以计算条件是否发生变化。\nPOSIX条件变量API 使用条件变量前必须初始化；在释放条件变量的底层内存之前，可以使用pthread_cond_destroy函数进行销毁。\n1 2 3 4 5 #include \u0026lt;pthread.h\u0026gt; int pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr); int pthread_cond_destroy(pthread_cond_t *cond); //两函数返回值：成功返回0；出错返回错误编号 要用默认属性初始化条件变量，只需把attr参数设为NULL。\n对于静态分配的条件变量，也可以使用常量PTHREAD_COND_INITIALIZER来初始化。\n1 2 3 4 5 6 7 #include \u0026lt;pthread.h\u0026gt; int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex); int pthread_cond_timedwait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex, const struct timespec *restrict tsptr); //两函数返回值：成功返回0；出错返回错误编号 pthread_cond_wait函数用于等待条件变量为真； pthread_cond_timedwait函数可以指定一个等待时间，如果在给定时间内条件不能满足，则生成一个返回错误码的变量。 1 2 3 4 #include \u0026lt;pthread.h\u0026gt; int pthread_cond_signal(pthread_cond_t *cond); int pthread_cond_broadcast(pthread_cond_t *cond); //两函数返回值：成功返回0；出错返回错误编号 以上两个函数用于通知线程条件已满足； pthread_cond_signal函数至少能唤醒一个等待该条件的线程； pthread_cond_broadcast函数则能唤醒等待该条件的所有线程。 条件变量解决生产者消费者问题 生产者消费者问题中，有一个缓冲区大小的概念。\n如果缓冲区内产品数量为0，则消费者无法消费，消费者线程必须等待； 如果缓冲区内产品数量达到最大值，则生产者不应继续生产，生产者线程应该等待。 之前用互斥量解决生产者消费者问题时，并没有考虑这一点。现在有了条件变量就可以解决这个问题了。程序如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int num = 0; const int buf_size = 10; //缓冲区大小 pthread_cond_t cond = PTHREAD_COND_INITIALIZER; pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; void *producer(void* arg){ while(1){ pthread_mutex_lock(\u0026amp;mutex); while(num \u0026gt;= buf_size){ pthread_cond_wait(\u0026amp;cond, \u0026amp;mutex); printf(\u0026#34;缓冲区已满，等待消费者消费。\\n\u0026#34;); } num += 1; printf(\u0026#34;生产一个产品，缓冲区当前产品数量：%d\\n\u0026#34;, num); sleep(1); //生产一个产品所需时间 pthread_cond_signal(\u0026amp;cond); printf(\u0026#34;通知消费者...\\n\u0026#34;); pthread_mutex_unlock(\u0026amp;mutex); sleep(1); //生产产品的频率 } } void *consumer(void* arg){ while(1){ pthread_mutex_lock(\u0026amp;mutex); while(num \u0026lt;= 0){ pthread_cond_wait(\u0026amp;cond, \u0026amp;mutex); printf(\u0026#34;缓冲区已空，等待生产者生产。\\n\u0026#34;); } num -= 1; printf(\u0026#34;消费一个产品，缓冲区当前产品数量：%d\\n\u0026#34;, num); sleep(1); pthread_cond_signal(\u0026amp;cond); printf(\u0026#34;通知生产者...\\n\u0026#34;); pthread_mutex_unlock(\u0026amp;mutex); } } int main(){ pthread_t producer_thread, consumer_thread; pthread_create(\u0026amp;producer_thread, NULL, \u0026amp;producer, NULL); pthread_create(\u0026amp;consumer_thread, NULL, \u0026amp;consumer, NULL); pthread_join(producer_thread, NULL); pthread_join(consumer_thread, NULL); } 程序执行结果：\n自旋锁 自旋锁与互斥量类似，但它不使线程进入阻塞态；而是在获取锁之前一直占用CPU，处于忙等（自旋）状态。\n自旋锁适用于锁被持有的时间短且线程不希望在重新调度上花费太多成本的情况。\nPOSIX自旋锁API 1 2 3 4 #include \u0026lt;pthread.h\u0026gt; int pthread_spin_init(pthread_spinlock_t *lock, int pshared); int pthread_spin_destroy(pthread_spinlock_t *lock); //两函数返回值：成功返回0；出错返回错误编号 pshared参数表示进程共享属性，表明自旋锁是如何获取的。 1 2 3 4 5 #include \u0026lt;pthread.h\u0026gt; int pthread_spin_lock(pthread_spinlock_t *lock); int pthread_spin_trylock(pthread_spinlock_t *lock); int pthread_spin_unlock(pthread_spinlock_t *lock); //三个函数返回值：成功返回0；出错返回错误编号 自旋锁解决生产者消费者问题 程序如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int num = 0; pthread_spinlock_t spinlock; void *producer(void* arg){ int times = 100000000; while(times--){ pthread_spin_lock(\u0026amp;spinlock); num += 1; pthread_spin_unlock(\u0026amp;spinlock); } } void *consumer(void* arg){ int times = 100000000; while(times--){ pthread_spin_lock(\u0026amp;spinlock); num -= 1; pthread_spin_unlock(\u0026amp;spinlock); } } int main(){ pthread_t thread_prod, thread_cons; pthread_create(\u0026amp;thread_prod, NULL, \u0026amp;producer, NULL); pthread_create(\u0026amp;thread_cons, NULL, \u0026amp;consumer, NULL); pthread_join(thread_prod, NULL); pthread_join(thread_cons, NULL); printf(\u0026#34;num = %d\\n\u0026#34;, num); } 由于我的环境是单核处理器，上边的程序别说1亿次循环，就是10次循环它也没能跑出来。\n单核处理器一般建议不要使用自旋锁。因为，在同一时间只有一个线程是处在运行状态，那如果运行线程发现无法获取锁，只能等待解锁，但因为自身不挂起，所以那个获取到锁的线程没有办法进入运行状态，只能等到运行线程把操作系统分给它的时间片用完，才能有机会被调度。这种情况下使用自旋锁的代价很高。\n屏障 屏障是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有的合作线程都到达某一点，然后从该点继续执行。\n1 2 3 4 5 #include \u0026lt;pthread.h\u0026gt; int pthread_barrier_init(pthread_barrier_t *restrict barrier, const pthread_barrierattr_t *restrict atrr, unsigned int count); int pthread_barrier_destroy(pthread_barrier_t *barrier); count参数指定必须到达屏障的线程数目。 1 2 #include \u0026lt;pthread.h\u0026gt; int pthread_barrier_wait(pthread_barrier_t *barrier); 用pthread_barrier_wait函数来表明线程已完成工作，准备等其他线程赶上来。 屏障这部分就不写实例了，一是没想到好的例子；二是屏障用的也比较少。\n信号量 信号量（Semaphore）本质上是一个计数器，用于为多个进程提供共享数据对象的访问。\n为了获得共享资源，进程需要执行下列操作：\n测试控制该资源的信号量； 若信号量值为正，则进程可以使用该资源。在这种情况下，进程会将信号量值减1，表示它使用了一个资源单位； 否则，若信号量值为0，则进程进入休眠状态，直至信号量值大于0。进程被唤醒后，返回步骤1。 当进程不再使用该共享资源时，该信号量值增1。如果有进程正在休眠等待此信号量，则唤醒它们。\n信号量通常是在内核中实现的。\nXSI信号量 使用XSI信号量时，首先通过semget函数获得一个信号量ID。\n1 2 3 #include \u0026lt;sys/sem.h\u0026gt; int semget(key_t key, int nsems, int flags); //返回值：成功返回信号量ID，出错返回-1 nsems参数指定该集合中的信号量数。 1 2 #include \u0026lt;sys/sem.h\u0026gt; int semctl(int semid, int semnum, int cmd, ... /* union semun arg */); semctl函数包含了多种信号量操作。 1 2 3 #include \u0026lt;sys/sem.h\u0026gt; int semop(int semid, struct sembuf semoparray[], size_t nops); //返回值：成功返回0；出错返回-1 semop函数自动执行信号量集合上的操作数组。 POSIX信号量 POSIX信号量相比XSI信号量有以下优点：\n性能更高； 没有信号量集； 删除时更加完美。 POSIX信号量有两种形式：命名的和未命名的。它们的差异在于创建和销毁的形式上。\n未命名的信号量只存在于内存中，并要求使用信号量的进程必须可以访问内存，这意味着其只能应用于同一进程中的线程，或不同进程中已经映射相同内存内容到它们地址空间中的线程； 命名信号量可通过名字访问，因此可以被任何已知它们名字的进程中的线程使用。 1 2 3 4 #include \u0026lt;semaphore.h\u0026gt; sem_t *sem_open(const char *name, int oflag, ... /* mode_t mode, unsigned int value */); //成功返回指向信号量的指针；出错返回SEM_FAILED sem_open函数创建一个新的命名信号量或使用一个现有信号量。 1 2 3 #include \u0026lt;semaphore.h\u0026gt; int sem_close(sem_t *sem); //返回值：成功返回0；出错返回-1 sem_close函数用来释放任何信号量相关的资源。 1 2 3 #include \u0026lt;semaphore.h\u0026gt; int sem_unlink(const char *name); //成功返回0；出错返回-1 sem_unlink函数销毁命名信号量。如果没有打开的信号量引用，则该信号量会被销毁；否则，销毁将延迟到最后一个打开的引用关闭。 1 2 3 4 #include \u0026lt;semaphore.h\u0026gt; int sem_trywait(sem_t *sem); int sem_wait(sem_t *sem); //两函数返回值：成功返回0；出错返回-1 sem_wait和sem_trywait函数来实现信号量的减1操作。sem_wait函数会阻塞，sem_trywait函数不会阻塞。 1 2 3 4 5 #include \u0026lt;semaphore.h\u0026gt; #include \u0026lt;time.h\u0026gt; int sem_timedwait(sem_t *restrict sem, const struct timespec *restrict tsptr); //成功返回0；出错返回-1 同样是实现信号量的减1操作，只是可以指定阻塞时间。 1 2 3 #include \u0026lt;semaphore.h\u0026gt; int sem_post(sem_t *sem); //成功返回0；出错返回-1 sem_post函数实现信号量的增1操作。 1 2 3 4 5 #include \u0026lt;semaphore.h\u0026gt; int sem_init(sem_t *sem, int pshared, unsigned int value); int sem_destroy(sem_t *sem); int sem_getvalue(sem_t *restrict sem, int *restrict valp); //三个函数返回值：成功返回0；出错返回-1 sem_init函数创建一个未命名信号量；pshared参数表明是否在多个进程中使用信号量，如果是则指定一个非0值；value参数指定信号量的初始值。 sem_destroy函数丢弃信号量； sem_getvalue函数用来获取信号量值。 如果一个信号量只有值0和1，那它就是二元信号量。当二元信号量是1时，它就是“解锁”的；是0时，它就是“加锁”的。\nPOSIX信号量解决生产者消费者问题 对于我们描述的生产者消费者问题，由于生产者和消费者是一个进程内的两个线程，所以我们采用未命名信号量解决该问题。\n将信号量初值置为1，即解锁状态。该信号量在执行过程中只有0和1两个值，即二元信号量。程序如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;semaphore.h\u0026gt; int num = 0; sem_t sem; void *producer(void* arg){ int times = 100000000;//循环一亿次 while(times--){ sem_wait(\u0026amp;sem);//减1操作，即加锁 num += 1;//每次生产一个产品 sem_post(\u0026amp;sem);//增1操作，即解锁 } } void *consumer(void* arg){ int times = 100000000; while(times--){ sem_wait(\u0026amp;sem);//减1操作，即加锁 num -= 1;//每次消费一个产品 sem_post(\u0026amp;sem);//增1操作，即解锁 } } int main(){ pthread_t thread_prod,thread_cons; sem_init(\u0026amp;sem, 0, 1); //信号量初始值置为1,即解锁态 pthread_create(\u0026amp;thread_prod, NULL, \u0026amp;producer, NULL); pthread_create(\u0026amp;thread_cons, NULL, \u0026amp;consumer, NULL); pthread_join(thread_prod, NULL); pthread_join(thread_cons, NULL); sem_destroy(\u0026amp;sem); printf(\u0026#34;num = %d\\n\u0026#34;, num); } 执行结果如下：\n对比可以发现，执行时间比互斥量要长。\n总结 通过上边对各种同步方式的描述，我们可以做出下述总结。\n互斥量（mutex）是最基本的线程同步方式，它只有两种状态（加锁和解锁）。尝试对互斥量加锁的线程如果发现互斥量已经被其他线程上锁了，那该线程就会由运行态进入阻塞态，即让出CPU，CPU可以调度其他线程运行，直到它想要的互斥量被其他线程释放了，CPU就可以把该线程转入就绪态准备调度其运行。\n自旋锁与互斥量类似，也是只有解锁和加锁两种状态，它与互斥量的区别在于，它不会阻塞线程。即尝试对自旋锁加锁的线程如果发现自旋锁已经被其他线程上锁了，那该线程将不会让出CPU，会一直处于运行态继续尝试获取该自旋锁，直到它的时间片耗尽让出CPU或者得到锁继续向下执行。\n读写锁适用于多读少写的情况，相比于互斥量，它把加锁态细分为读模式加锁和写模式加锁两种，从而允许更高程度的并行，允许多个读者同时访问共享资源，但写者将独占共享资源，所以读写锁也叫共享-互斥锁，即读模式共享，写模式互斥。\n信号量相当于对互斥量做了扩展，某种程度上也可以把互斥量看作是特殊的“二元信号量”，当然互斥量更加严格，对于互斥量，解铃还须系铃人，谁锁上的谁负责解开；而二元信号量允许A线程加锁（减1），B线程解锁（增1）。多值信号量允许多个线程同时访问共享资源。\n条件变量与互斥量配合使用，主要实现了一种通知机制。\n","date":"2021-05-12T00:48:23-07:00","permalink":"https://bitdove.github.io/posts/threads-sync/","title":"【一文读懂】线程同步"},{"content":"引言 所谓可靠传输，有以下四点要求：\n不损坏，即接收到的数据不存在比特差错； 不丢失，即接收到的数据无间隙； 不重复，即接收到的数据不重复； 不乱序，即接收到的数据是按次序的。 通信介质由于一些原因可能会造成比特差错和分组丢失。\n使用差错校正码，即添加一些冗余比特用于恢复比特差错； 重传机制：即重新传送信息，直到它被正确接收为止。重传可以解决比特差错和分组丢失。TCP就采用重传机制。 重传机制 通过重传机制解决比特差错和分组丢失，需要判断两个问题：\n是不是发生了分组丢失，即接收方是否已收到分组？ 是不是发生了比特差错，即接收方收到的分组是否与之前发送方发送的一样？ 对于检测是否发生了比特差错，可以通过校验和来完成；但是校验和只能检测，并不能实现差错纠正。\nACK机制 为了判断重传机制带来的第一个问题（即是否发生分组丢失），引入了ACK机制：\n接收方收到分组后，给发送方发送一个ACK，以确认自己收到了分组；发送方收到ACK后，再发送下一个分组，继续等待新分组的ACK，这个过程就这样进行下去。\n但ACK机制也带来了一些问题：\n发送方等待ACK应该等多长时间？ 这个问题比较复杂，暂时不讨论，到《TCP的超时与重传》再讨论。\n如果ACK丢失了怎么办？ 这个问题比较容易，超过了发送方等待ACK的时间，发送方就再把原分组发送一遍就可以了。当然这可能带来分组重复问题。\n如果分组接收到了，但是通过校验和检测到分组存在比特差错怎么办？ 这个也比较简单，接收方收到存在比特差错的分组后，将不发送ACK，时间一到，发送方重发完整到达的无差错的分组。\n序列号机制 从上边可以看出，对于ACK丢失的情况，发送方简单地重发原分组，这将导致接收方接收到重复的分组。\n为了解决分组重复问题，引入序列号机制来解决\n发送方发送分组时，每个分组都有一个唯一的序列号，这个序列号由分组自身一直携带着。接收方可以使用这个序列号来判断它是否已经收到过这个分组，如果是则丢弃它，保留之前的就好了。\n滑动窗口机制 到目前为止，以上的协议是可靠的，但是效率比较低，因为它是一个停等协议，即发送方注入一个分组到通信路径，然后停下来等待，直到接收到来自接收方给这个分组反馈的ACK，发送方才能发送下一个分组。\n为了提高吞吐量，我们可以允许发送方同时发送多个分组，这将带来更多需要考虑的问题：\n发送方每次应该发多少个分组？ 发送方应该保存哪些分组的副本已备重传？ 接收方的ACK机制如何区分哪些分组收到了，哪些分组还没收到？ 接收方收到分组的顺序与发送方的发送顺序不同，即乱序问题如何解决？ 为了解决这些问题，引入了滑动窗口机制。\n上图显示了一个发送方窗口，3号分组已被发送并确认，所以由发送方保存的它的副本可以被释放；7号分组在发送方已准备好，但还未被发送，因为它还没有进入窗口。\n现在我们可以想象，发送方下一步就接收到分组4的ACK，所以整个窗口向右滑动一个分组，变成下图：\n这意味着4号分组现在可以释放了，而7号分组可以被发送了。\n一般，发送方和接收方都有自己的滑动窗口结构。\n发送方的窗口记录着哪些分组可以被释放，哪些分组正在等待ACK，哪些分组还不能被发送；\n接收方的窗口记录着哪些分组已接收和确认，哪些分组是下一步期望接收的，以及哪些分组即使被接收也会因内存限制而被丢弃。\n滑动窗口机制又带来一些需要考虑的问题：\n窗口大小应该是多少？ 如果接收方或网络处理不过来发送方的数据率时该怎么办？ 流量控制和拥塞控制 为了解决滑动窗口机制带来的问题，引入了流量控制和拥塞控制。\n流量控制 流量控制：当接收方相对于发送方太慢时，强迫发送方慢一点。\n流量控制的主要形式为基于滑动窗口进行流量控制，在这种方法里：\n滑动窗口大小不固定，允许随时间而变动； 接收方通过窗口通告通知发送方更新自己的窗口大小； 窗口通告通常与ACK一起由同一个分组携带，即发送方在向右滑动窗口的同时调整窗口的大小。 拥塞控制 流量控制解决了接收方相对于发送方慢的问题，但是一般在发送方和接收方之间还有很多路由器，它们的内存有限，如果发送方发送的太快，快到超过了这之间某台路由器的承受能力，就会导致丢包。\n这个问题通过拥塞控制机制来解决。\n超时重传机制 为解决“发送方等待ACK应该等多长时间才能判定分组丢失并重发它”这个问题，引入了超时重传机制。\n直观上，发送方重新发送一个分组之前应等待以下时间的总和：\n发送分组所用的时间； 接收方处理分组的时间； 接收方发送一个ACK所用的时间； ACK到达发送方所用的时间； 发送方处理ACK所用的时间。 不幸的是，谁都不知道这些时间是多少，而且它们会随网络环境和主机负载而变化。\n所以采用的策略是：让协议实现尝试去估计这些时间，称为往返时间估计（RTT）。\nTCP中的可靠性 TCP服务模型\nTCP提供了一种面向连接的可靠的字节流服务。\n面向连接的，即通信双方需要建立一条端到端连接；\n字节流：应用层传下来的数据会被TCP打散成TCP认为的最佳大小的块来发送，一般使得每个报文段按照不会被分片的单个IP层数据报的大小来划分。\nTCP通过前述各种技术机制的变种，实现了可靠数据传输。\n序列号：在TCP中序列号实际代表了每个分组的第一个字节在整个字节流中的字节偏移，而非分组号；\n校验和：在TCP中用于检测传送中的比特差错；\n重传计时器：当TCP发送一组报文段时，它通常设置一个重传计时器，等待对方的ACK。TCP不会为每个报文段各自设置一个重传计时器，而是发送一个窗口的数据只设置一个重传计时器，当ACK到达时更新超时；\nACK机制：TCP的ACK是累积的，即指示字节号N的ACK到达意味着N（不含N）之前的所有字节都成功收到了。\n窗口通告：因为TCP提供的是双工服务，A给B发数据时的TCP报文段同时也包含了对B发给A的数据的ACK，同时每个报文段也包含一个窗口通告实现相反方向上的流量控制。\n乱序问题：TCP绝不会以杂乱次序给上层应用程序发数据。因此，TCP接收端可能会被迫先保持大序列号的数据不交给应用程序，直到缺失的小序列号报文段一一到达，空洞被填满再往应用程序交付数据。\nTCP头部结构 源/目的端口：与IP头部中的源/目的IP地址一起，唯一地标识了每个连接； 序列号：标识了TCP发送端到接收端的数据流的一个字节，该字节代表着包含该序列号的报文段的数据中的第一个字节； 确认号：其值是该确认号的发送方期待接收的下一个序列号，即最后被成功接收的数据字节的序列号加1； 头部长度：指出TCP头部的长度，以4字节为单位。作为一个4位字段，TCP头部被限制为最大60字节； 保留：4位，暂时没用，填充为0； CWR：1位，拥塞窗口减（发送方降低发送速率）； ECE：1位，ECN回显（发送方接收到了一个更早的拥塞通告）； URG：1位，紧急（使紧急指针字段有效）； ACK：1位，确认（使确认号字段有效）； PSH：1位，推送（接收方应尽快给应用程序传送这个数据）； RST：1位，重置连接； SYN：1位，用于初始化一个连接的同步序列号； FIN：1位，该报文段的发送方已经结束向对方发送数据； 窗口大小：窗口通告，以字节为单位通知对方更新窗口大小； TCP校验和：检测比特差错； 紧急指针：用于发送紧急数据，参考《APUE》带外数据； 选项：最常见的选项是MSS（最大端大小）； ","date":"2021-05-10T00:07:46-07:00","permalink":"https://bitdove.github.io/posts/tcp-introduction/","title":"【一文读懂】TCP协议（上）"},{"content":"引言 从今天开始，会陆续开更系列文章《一起学操作系统》，在这里说一下整个系列的写作思路。\n操作系统的功能有两个：\n提供抽象 管理资源 对于提供抽象这个功能，我总结为：操作系统提供了三个抽象\nCPU 抽象为 进程； 物理内存 抽象为 虚拟地址空间； IO设备（包括磁盘） 抽象为 文件系统。 对于管理资源这个功能，操作系统的任务是在相互竞争的程序间有序地控制对资源的分配，这里，我关注一点，即：\n死锁。 资源就是随着时间的推移，必须能获得、使用以及释放的任何东西。可以是硬件，也可以是一组信息（如数据库中的记录）。\n我会按照这个思路写这系列文章。今天先写第一部分，即将CPU抽象为进程，进程这一部分目前计划为四篇文章：\n进程与线程基础（本篇） 进程间通信问题：管道（PIPE和FIFO）、消息队列、信号量、共享存储、套接字 线程同步：互斥锁、读写锁、自旋锁、条件变量、屏障 进/线程调度 进程 为什么需要进程？ 我们早已习惯了一台计算机“同时”做很多事情，我们举一个例子，有一台Web服务器，它接收到一个网页请求，服务器检查后发现该请求需要的网页不在其缓存中，所以服务器会启动一个磁盘请求去获取该网页。但是，对CPU而言，磁盘请求是非常慢的，在这个过程中，会有其他请求到达服务器。如果存在多个磁盘，那么可以在响应第一个请求之前就向其他磁盘发出后续的请求。\n很明显，我们需要一种方法来模拟并控制这种并发，进程（尤其是线程）就是解决这个问题的。\n严格来讲，在某一个瞬间，一个CPU只能运行一个进程。所以对单核CPU来讲，我们看到的计算机“同时”运行多个进程其实是一种假象，是一种伪并发，这种伪并发是由于CPU在多个进程之间快速地切换，导致看上去就像多个进程同时运行一样。\n什么是进程？ 进程是一个正在执行的程序的实例。每个进程拥有自己的虚拟CPU，即拥有自己的寄存器、程序计数器（PC）等。\n进程和程序的区别：\n程序是一个静态概念，进程是一个动态概念； 我们写的程序经过编译链接生成可执行文件，到此为止，它都可以称为程序；而当把可执行文件跑起来，即装载到内存开始运行之后，它才变成一个进程； 自然，一个程序执行两次，算作两个进程。 进程组成 前面一直说的比较抽象，本小节将把进程这一概念落在实处。\n操作系统内核维护着一张进程表，每个进程占用其中一个表项，成为进程控制块（PCB）。在Linux内核下，PCB就是task_struct结构体，进程表就是一个由很多个task_struct结构体组成的链表。\nPCB即描述进程的数据结构。PCB是进程存在的唯一标志。\nPCB通常包含以下内容：\n进程描述信息 进程控制和管理信息 资源分配清单 CPU相关信息 进程ID（PID） 进程当前状态 代码段指针 通用寄存器值 用户ID（UID） 进程优先级 数据段指针 地址寄存器值（如堆栈指针寄存器ESP） 代码运行入口地址 堆栈段指针 控制寄存器值（如程序计数器PC） 程序的外存地址 文件描述符 标志寄存器值 进入内存时间 键盘 状态字（PSW） CPU占用时间 鼠标 信号量使用 暂且可以这么说，进程由代码段、数据段、PCB三部分组成。\n进程状态 进程有下图所示三种状态：\n运行态：该时刻进程实际占用CPU； 就绪态：可运行，但因为其他进程正在占用CPU而暂时不运行； 阻塞态：正在等待某种外部事件（如磁盘IO）发生，否则进程无法运行； 三种状态之间有四种可能的转换关系：\n运行态至阻塞态：进程因等待外部事件发生而不能继续运行下去； 运行态至就绪态：由进程调度程序引起，进程的时间片耗尽，调度程序选择其他进程运行； 就绪态至运行态：由进程调度程序引起，调度程序选择该进程运行； 阻塞态至就绪态：等待的外部事件发生，由阻塞态转为就绪态，等待调度程序的调度。 创建进程：fork 归根结底，新进程的创建都是由于一个已存在的进程执行了一个用于创建进程的系统调用而创建的。\n在UNIX系统中，有且仅有一个系统调用可以用来创建进程：fork。\n1 2 3 #include \u0026lt;unistd.h\u0026gt; pid_t fork(void); //返回值：子进程返回0，父进程返回子进程PID；若出错，返回-1。 由fork创建的新进程称为子进程。fork函数被调用一次，但返回两次：\n子进程的返回值是0； 父进程的返回值是新建子进程的进程ID。 为什么要把子进程的PID返回给父进程？\n因为一个进程可以有多个子进程，且没有函数可以使一个进程获得其所有子进程的PID。 为什么子进程中fork返回值为0？\n因为一个进程只会有一个父进程，子进程可以通过调用getppid来获得其父进程的PID； 且进程ID 0 总是由内核交换进程使用，所以一个子进程的进程ID不可能是0。 子进程和父进程继续执行fork之后的指令。子进程获得其父进程的虚拟地址空间中的数据段、堆、栈的副本，而代码段是父进程和子进程共享的。\n写时复制技术\n由于fork之后经常跟随着exec，所以现在很多实现并不真的给子进程一个父进程的数据段、堆、栈的副本，而采用写时复制技术作为替代。\n在该技术中，fork之后，父进程的数据段、堆、栈也是同子进程共享的，只是内核会把它们的访问权限变为只读。如果父进程和子进程中的任一个试图修改这些区域，则内核只为修改区域的那块内存制作一个副本，通常是虚拟内存的一个页。\n注：Windows中没有父子进程这种层次概念，所有进程地位相同。\n孤儿进程与僵尸进程 进程是一个动态概念，有创建就有终止。父进程为了决定下一步的对策，需要知道其子进程的死亡原因（终止状态）。具体是通过wait和waitpid两个函数来实现。\n1 2 3 4 #include \u0026lt;sys/wait.h\u0026gt; pid_t wait(int *statloc); pid_t waitpid(pid_t pid, int *statloc, int options); //两个函数返回值：若成功则返回进程ID；若出错则返回0或-1。 进程的终止状态存放在statloc指针所指向的内存单元内。\n调用wait或waitpid时可能发生什么：\n若其所有子进程都还在运行，则阻塞； 若一个子进程已终止，正等待父进程获取其终止状态，则取得该子进程的终止状态后立即返回； 若它没有任何子进程，则立即出错返回。 wait和waitpid的区别如下：\n若子进程都还在运行，wait使父进程阻塞；而waitpid有一选项，可使父进程不阻塞； wait等待的是其被调用之后第一个终止的子进程；而waitpid可以指定等待哪个进程的终止； 为了使父进程能够获得子进程的终止状态，一个进程终止之后并非完全消失，内核仍为每个终止子进程保存了一定量的信息。\n僵尸进程：一个已经终止，但是其父进程尚未对其进行善后处理（获取其终止信息、释放其仍占用的资源）的进程。\n僵尸进程的危害\n如果父进程不调用 wait/waitpid的话， 那么内核为每个终止子进程保存的一定量的信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程， 此即为僵尸进程的危害，应当避免 。\n解决僵尸进程\n僵尸进程的出现，追其根本原因，是其父进程出现了问题，在子进程终止后没有回收子进程的资源，而不是Linux系统的问题；此时运行的程序代码逻辑应该是有问题的，需要整改，如果出现僵尸进程，可以通过以下方法解决：\n直接杀掉其父进程，将此进程变成孤儿进程，交给 init 进程管理，init 进程回收此进程的资源；\n1 kill -9 + 父进程号 孤儿进程：在子进程终止之前，父进程先终止了，子进程则成为孤儿进程。\n孤儿进程会被init进程收养。操作过程大概是：在一个进程终止时，内核逐个检查所有活着的进程，以判断它是否是正要终止的进程的子进程，如果是，则该进程的父进程ID就更改为1（init进程）。\n线程 为什么需要线程？ 进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺点：\n进程在同一时间只能干一件事，如果进程在执行的过程中阻塞，整个进程就会挂起，即使有些工作不依赖于等待的资源，进程仍然不会执行。因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性。\n什么是线程？ 线程可以理解为进程中的一条执行流程。\n线程是CPU调度的最小单位。\n传统的进程只包含一个线程。线程是依赖进程而存在的。\n进程负责把资源集中到一起，而线程则是被CPU调度执行的实体。\n线程内容 同一进程内的所有线程共享该进程的虚拟地址空间，但每个线程拥有自己的栈。\n进程的虚拟地址空间如下图所示：\nPCB在上图中的Kernel Space中。\n线程共享的内容有：\n代码段、数据段； 堆（Heap）； PCB中的文件描述符，即线程共享进程的打开文件； PCB中的其他一些内容，我们暂时不关注。 线程私有的内容有：\n栈，即每个线程有自己的栈； PCB中的寄存器； PCB中某些其他内容，我们暂时不关注。 POSIX线程 1 2 3 4 5 6 #include \u0026lt;pthread.h\u0026gt; int pthread_create(pthread_t *restrict tidp, const pthread_attr_t *restrict attr, void *(*start_rtn)(void *), void *restrict arg); //若成功则返回0；若出错则返回错误编号。 pthread_create用于创建线程：\n新创建线程的线程ID会被设置为tidp指向的内存单元； attr参数用于定制线程属性，默认为NULL； 新建的线程从start_rtn函数的地址开始执行，该函数只有一个void*类型的参数arg； 若要传给start_rtn函数的参数超过一个，那么需要把参数放在一个结构体中，然后把该结构体的地址作为arg参数传给pthread_create函数。 restrict是C99中新增的关键字，它只用于修饰指针；该关键字用于告知编译器，所有修改该指针所指向内容的操作都必须基于该指针，即不存在其它进行修改操作的途径。\n1 2 3 #include \u0026lt;pthread.h\u0026gt; void pthread_exit(void *rval_ptr); int pthread_join(pthread_t thread, void **rval_ptr); //若成功则返回0；若出错则返回错误编号。 pthread_exit用于在不终止进程的情况下终止线程：\nrval_ptr指向的内存单元存放线程的终止状态。 pthread_join用于等待特定线程的终止，在此之前，调用该函数的线程将一直阻塞：\nthread用于指定所等待线程的线程ID； rval_ptr用于获取所等待线程的终止状态，若不感兴趣，可以设其为NULL。 多进程与多线程 多进程与多线程的优缺点 多进程的优点：\n编程相对容易：通常不需要考虑锁和同步资源的问题；\n更强的容错性：比起多线程的一个好处是一个进程崩溃了不会影响其他进程。；\n有内核保证的隔离：数据和错误隔离。 对于使用如C/C++这些语言编写的本地代码，错误隔离是非常有用的：采用多进程架构的程序一般可以做到一定程度的自恢复；（master守护进程监控所有worker进程，发现进程挂掉后将其重启）。\nchrome浏览器采用多进程方式。\n原因：1. 可能存在一些网页不符合编程规范，容易崩溃，采用多进程一个网页崩溃不会影响其他网页；而采用多线程会。\n​ 2.网页之间互相隔离，保证安全，不必担心某个网页中的恶意代码会取得存放在其他网页中的敏感信息。\n多线程的优点：\n创建速度快，方便高效的数据共享；\n较轻的上下文切换开销。\n","date":"2021-05-07T00:56:15-07:00","permalink":"https://bitdove.github.io/posts/basic-of-process-and-thread/","title":"【一文读懂】进程与线程"},{"content":"什么是DNS？ DNS是Domain Name System的首字母缩写，即域名系统。\n网络上的主机有两种标识方法：\n域名：如www.baidu.com。优点是人们喜欢，容易记；缺点是机器不喜欢，路由器无法处理。 IP地址：如39.156.69.79。优点是机器喜欢，容易处理；缺点是人们不喜欢，不好记。 为了折中人类和机器不同的偏好，我们需要一种能从域名转换到IP地址的服务，这就是DNS的主要任务。\nDNS协议采用客户端/服务器模型，DNS协议位于五层网络模型中的应用层，在进行域名解析时其传输层采用UDP协议，其知名端口号为53。\nDNS协议由两部分组成：\n域名解析，用于执行对DNS特定名称查询的查询/响应协议； 区域传输：用于交换数据库记录的协议。 对于域名解析，由于数据量小，DNS协议采用UDP协议，知名端口号为53；\n对于区域传输，由于数据量大，DNS协议采用TCP协议，知名端口号为53。\nDNS服务器层次结构 DNS使用了大量的DNS服务器，它们以层次方式组织并且分布在全世界范围内。不存在一台DNS服务器拥有因特网上所有域名的映射。\n大致说来，有3种类型的DNS服务器：\n根DNS服务器：根DNS服务器提供顶级域名DNS服务器的IP地址； 顶级域名DNS服务器：顶级域名DNS服务器提供权威DNS服务器的IP地址； 权威DNS服务器：权威DNS服务器提供该组织的可访问域名的IP地址。 比如百度在因特网上有很多可以访问的域名，如百度首页baidu.com、百度贴吧tieba.baidu.com、百度新闻news.baidu.com，百度的权威服务器负责提供这些域名的IP地址。百度可以自己建权威DNS服务器，也可以花钱让中国电信这样的ISP帮它维护权威DNS服务器。\n这三种类型的DNS服务器以下图的层次结构组织起来。\n还有一种DNS服务器，叫本地DNS服务器，不在上述的DNS服务器层次结构中。本地DNS服务器就是用DHCP获得的配置信息中的DNS服务器。本地DNS服务器通常离我们的主机比较近，通常不超过几个路由器的距离。\n当主机发岀DNS请求时，该请求被发往本地DNS服务器，它起着代理的作用，并将该请求转发到DNS服务器层次构中，后边将详细讨论。\nDNS缓存 为了改善时延性并减少在因特网上到处传输的DNS报文数，DNS广泛使用了缓存技术。\n在一个请求链中，当某DNS服务器接收一个DNS回答 (例如，包含某域名到IP地址的映射)时，它能将映射缓存在本地存储器中。这样下次如果有对同样域名的DNS查询到达该DNS服务器时，它可以从自己的缓存中找出该域名对应的IP地址，直接返回给请求者，而不用再去问其他DNS服务器。\n由于域名与IP的映射不是永久的，所以DNS缓存有一个生存时间（TTL）。\nDNS资源记录类型 虽然DNS通常用来将域名转换为对应的IP地址，但是它也有其他功能，区分这些功能的方法就是使用不同的资源记录类型。这里我们只关注以下四种资源记录类型：\nA：提供域名到IPv4地址的映射； AAAA：提供域名到IPv6地址的映射； NS：用来指定该域名由哪个DNS服务器来进行解析； CNAME：允许多个域名映射到同一IP地址。 对于CNAME，我记得，当时用GitHub建个人博客时用到过，默认的地址xgx127.github.io用CNAME映射到我买的域名xushark.com，然后用A记录把xushark.com映射到我的云服务器的IP地址。\nDNS工作流程 下面以一个简单例子来描述DNS的工作流程。本例中我们假设没有DNS缓存。\n假设主机cse.nyu.edu想知道主机gaia.cs.umass.edu的IP地址。\n主机cse.nyu.edu首先向它的本地DNS服务器dns. nyu. edu发送一个DNS查询报文。 DNS查询报文内封装有要查询的域名gaia.cs.umass.edu；\n由于假定无缓存，本地DNS服务器将查询报文转发到根DNS服务器；\n根DNS服务器注意到其edu前缀，向本地DNS服务器返回负责edu的顶级域名DNS服务器的IP地址列表；\n本地DNS服务器则再次向这些顶级域名DNS服务器之一发送查询报文；\n顶级域名DNS服务器（edu）注意到umass.edu前缀，并返回权威DNS服务器的IP地址进行响应，该权威DNS服务器是负责马\n萨诸塞大学的dns.umass.edu；\n本地DNS服务器向dns.umass.edu发送查询报文；\n权威DNS服务器（dns.umass.edu）用gaia. cs. umass. edu的IP地址进行响应；\n本地DNS服务器将gaia.cs.umass.edu的IP地址反馈给主机cse.nyu.edu。\n理论上讲，任何DNS查询既可以是迭代的也可以是递归的；\n实践上，通常遵循上图的模式，请求主机到本地DNS服务器的查询是递归的，其余的查询是迭代的。\nDNS消息格式 基本的DNS消息以固定的12字节头部开始，其后跟随4个可变长度的区段：问题（或查询）、回答、授权记录和额外信息。\n事务ID：由客户端设置，由服务器返回。客户端用它来匹配响应与查询； QR：0表示查询消息，1表示响应消息； OpCode：0表示标准查询（查询和响应），4表示通知，5表示更新，其他值弃用； AA：表示授权回答（与缓存回答相对）； TC：表示“可截断的”。使用UDP时，它表示当应答的总长度超过512字节时，只返回前512个字节； RD：表示“期望递归”。在查询中设置，在响应中返回。它告诉服务器执行递归查询； RA：表示“递归可用”。如果服务器支持递归查询，则在响应中设置该字段； Z：目前Z字段必须为0，为将来而保留； AD：若包含的信息是已授权的，则AD置1； CD：若禁用安全检查，则CD置1； RCODE：返回码字段，常见值如0（NoError）、3（NXDomain）； QDCOUNT、ANCOUNT、NSCOUNT、ARCOUNT：说明了组成DNS消息的问题、回答、授权和额外信息区段中的条目数目。对于查询消息，QDCOUNT通常为1，其他三个为0；对于应答消息，ANCOUNT至少为1； ","date":"2021-05-06T00:44:05-07:00","permalink":"https://bitdove.github.io/posts/dns-protocol/","title":"【一文读懂】DNS协议"},{"content":"何为DHCP？ DHCP是Dynamic Host Configuration Protocol的首字母缩写，即动态主机配置协议。\n任何连接到的互联网的主机或路由器都需要IP地址、子网掩码、默认网关、DNS服务器等配置信息，当一个网络中的主机或路由器数量很多时，采用人工来配置这些信息显然是低效且易错的。DHCP就是解决这个问题的。\nDHCP的主要作用是集中的管理、分配IP地址，使网络环境中的主机动态的获得IP地址、子网掩码、默认网关、DNS服务器地址等信息，并能够提升IP地址的使用率。\nDHCP采用客户端/服务器模型。客户端主机的IP地址等配置信息的动态分配任务由其自身发起，当DHCP服务器接收到来自客户端主机申请地址的信息时，才会向客户端主机发送相关的地址配置等信息，以实现客户端主机地址信息的动态配置。\nDHCP位于五层网络模型中的应用层，其传输层采用UDP协议。客户端端口号为68，服务器端口号为67。\nDHCP服务器可提供三种地址分配：自动分配、动态分配、手动分配。三者区别在于地址分配是否基于客户端的身份以及该地址是否可撤销或变更。我们只关注动态分配。\n动态分配：客户端从服务器的地址池中获得一个可撤销的IP地址。\n地址池和租用期 动态分配中，DHCP客户端请求分配一个IP地址时，DHCP服务器从其地址池中选择一个地址作为响应。\n地址池：专门为DHCP用途而分配的一个连续的IP地址范围。\n租用期：分配给客户端的IP地址只在一段特定时间内有效，这段时间称为租用期。\n租用期是可以延长的，即客户端可以续约。\nDHCP消息格式 Op：标识消息是请求消息（1）还是应答消息（2）； HW类型：硬件类型，基于ARP使用的值，对于以太网，该值为1； HW长度：存放硬件（MAC）地址的长度，对于以太网MAC地址，该值为6； 跳步数：保存消息传输过程中的中继次数。消息发送方将该值设置为0，并在每次中继时递增； 事务ID：由客户机选择的随机数，服务器将它复制到响应中，用于将请求和应答匹配起来； 秒数：由客户机设置，它是第一次尝试申请或重新申请地址经过的秒数； 标志：该字段16位中，目前只用了1位，称为广播标志。客户机可以在请求中设置该位，表示它们不能或不愿处理单播IP数据报，但可处理广播数据报（例如，客户机还没有IP地址的情况）。通过设置该位通知服务器和中继代理，广播地址可用于响应中。 ciaddr：如果客户机已有IP地址的话，客户机在发送请求时将自己的IP地址放在此处； yiaddr：由服务器填写，服务器把想要分配给客户机的IP地址放在此处； siaddr：一般是DHCP服务器的IP地址； giaddr：如果需要跨子网进行DHCP地址分配（DHCP服务器与客户机不在同一子网），则在此处填写经过的路由器的IP地址； chaddr：客户机的硬件地址，即MAC地址； sname：并非每次都要填写，表示服务器名； file：并非每次都要填写，表示启动文件路径； 选项：常见选项见下。 常见选项：\n子网掩码（1）、路由器地址（3）、域名服务器（6）、请求的IP地址（50）、地址租用期（51）、DHCP消息类型（53）、租约更新时间（58）、租约重新绑定时间（59）。\n选项可由DHCP选项字段携带，也可由sname和file字段携带，由sname和file携带时，称为选项超载。\nDHCP消息类型（53）是1字节长的选项，其常见可能值如下：\nDHCPDISCOVER（1）、DHCPOFFER（2）、DHCPREQUEST（3）、DHCPACK（5）、DHCPNAK（6）\nDHCP协议操作 接下来我将通过一个实际场景描述DHCP协议的基本工作流程。\n场景：小明在学校有一台笔记本电脑，一直用着学校的校园网。现在五一假期了，小明打算把笔记本带回家连上家里的网络打英雄联盟。我们假定校园网与小明家的网不是同一子网。\n小明的笔记本由校园网切换到家里的网络，其IP地址等配置信息自然要发生变化，这个过程就是由DHCP来完成的，下面来看一下DHCP如何完成这项工作。\n注：链路层以以太网为例。假定小明笔记本MAC地址为00:13:02:20:b9:18。\nDHCPREQUEST 由于小明的笔记本电脑会记住之前在校园网中使用的IP地址（假定为172.16.1.34），所以在连接到新的网络（小明家的网络）时，它首先通过一个DHCPREQUEST消息尝试继续使用该地址。该DHCPREQUEST消息封装如下图所示。\nOp为1代表这是一个DHCP请求；\nhtype为1代表是以太网；\nhlen为6是MAC地址的长度（以字节为单位）；\n跳步数设置为0，每次中继时递增；\n事务ID为随机生成，这里假定为0xdb23247d；\n标志为0x8000，即最高位为1，意味着该消息的响应应该通过广播地址发送。\nciaddr、yiaddr、siaddr、giaddr均为0.0.0.0；\nchaddr为小明笔记本的MAC地址00:13:02:20:b9:18；\nsname、file未指定；\n选项中指明了DHCP消息类型为DHCPREQUEST以及请求的IP地址为172.16.1.34。\n该DHCP消息被封装在UDP用户数据报中，其中UDP头部中源端口号填写为68，目的端口号填写为67；\n然后该UDP用户数据报被封装到IP数据报中，其中IP头部中的源IP地址填写为0.0.0.0，目的IP地址填写为广播地址255.255.255.255；\n然后该IP数据报被封装到以太网帧中，其中以太网帧中源MAC地址填为00:13:02:20:b9:18，目的MAC地址填为ff:ff:ff:ff:ff:ff:ff。\n由于客户机不知道它请求的地址是否分配成功，也不知道它所连接的新网络的网络前缀，所以它不得不使用这些广播地址。\nDHCPNAK 附近的DHCP服务器会收到客户机的DHCPREQUEST消息，由于连接到了新网络，172.16.1.34不在当前网络中，所以当前的DHCP服务器无法给小明的笔记本分配其请求的IP地址（172.16.1.34）。因此服务器会发送一个DHCPNAK消息，拒绝客户机的请求。\nOp为2代表这是一个DHCP应答；\nxid与之前的DHCPREQUEST消息中的一样，代表这是对该DHCPREQUEST消息的应答；\n选项中指明了DHCP消息类型为DHCPNAK、DHCP服务器标识符10.0.0.1、以及一个表示错误类型的文本字符串“wrong address”。\n该DHCP消息被封装在UDP用户数据报中，其中UDP头部中源端口号填写为67，目的端口号填写为68；\n然后该UDP用户数据报被封装到IP数据报中，其中IP头部中的源IP地址填写为10.0.0.1，目的IP地址填写为广播地址255.255.255.255；\n然后该IP数据报被封装到以太网帧中，其中以太网帧中源MAC地址填为00:04:5a:9f:9e:80，目的MAC地址填为ff:ff:ff:ff:ff:ff:ff。\n这里假定该DHCP服务器的IP地址为10.0.0.1，MAC地址为00:04:5a:9f:9e:80。\nDHCPDISCOVER 对IP地址172.16.1.34的请求被拒绝，所以此后客户机不再使用该IP地址，而是通过一个DHCPDISCOVER消息重新寻找新的IP地址。\nOp为1代表这是一个DHCP请求消息；\nxid为0x3a681b0b，是新的事务ID；\n选项中指明DHCP消息类型为DHCPDISCOVER；\n选项中还包含了之前使用的已请求的IP地址172.16.1.34；\n选项中的Parameter Request List客户机需要的配置信息，通常包含子网掩码、默认网关、DNS服务器地址等。\n该DHCP消息被封装在UDP用户数据报中，其中UDP头部中源端口号填写为68，目的端口号填写为67；\n然后该UDP用户数据报被封装到IP数据报中，其中IP头部中的源IP地址填写为0.0.0.0，目的IP地址填写为广播地址255.255.255.255；\n然后该IP数据报被封装到以太网帧中，其中以太网帧中源MAC地址填为00:13:02:20:b9:18，目的MAC地址填为ff:ff:ff:ff:ff:ff:ff。\nDHCPOFFER 在接收一个DHCPDISCOVER消息后，DHCP服务器会响应一个IP地址、租约和其他配置信息的确认，它们包含在一个DHCPOFFER消息中。（在本例中，DHCP服务器同时也是路由器和DNS服务器）\nOp为2代表这是一个DHCP应答消息；\nxid为0x3a681b0b，代表该应答与上一个DHCPDISCOVER请求消息所匹配；\nyiaddr为10.0.0.57，表示DHCP服务器计划分配给客户机的IP地址；\nsiaddr为10.0.0.1，是该DHCP服务器的IP地址；\n选项中指明了消息类型为DHCPOFFER，同时包含了服务器提供给客户机的配置信息，包括：\n提供的IP地址的租用期、更新、重新绑定的超时时间，分别为12小时、6小时、10.5小时； 子网掩码255.255.255.128； 默认网关10.0.0.1； DNS服务器10.0.0.1。 该DHCP消息被封装在UDP用户数据报中，其中UDP头部中源端口号填写为67，目的端口号填写为68；\n然后该UDP用户数据报被封装到IP数据报中，其中IP头部中的源IP地址填写为10.0.0.1，目的IP地址填写为广播地址255.255.255.255；\n然后该IP数据报被封装到以太网帧中，其中以太网帧中源MAC地址填为00:04:5a:9f:9e:80，目的MAC地址填为ff:ff:ff:ff:ff:ff:ff。\nDHCPREQUEST 当客户机收到一个DHCPOFFER消息，并决定租用服务器提供的IP地址10.0.0.57，它会发送第二个DHCPREQUEST消息。\nOp为1代表这是一个DHCP请求消息；\nxid与之前相同，代表该消息与之前的匹配；\nciaddr、yiaddr、siaddr、giaddr均为0.0.0.0；\n选项中指明DHCP消息类型为DHCPREQUEST、请求的IP地址10.0.0.57、DHCP服务器标识符10.0.0.1。\n该DHCP消息被封装在UDP用户数据报中，其中UDP头部中源端口号填写为68，目的端口号填写为67；\n然后该UDP用户数据报被封装到IP数据报中，其中IP头部中的源IP地址填写为0.0.0.0，目的IP地址填写为广播地址255.255.255.255；\n然后该IP数据报被封装到以太网帧中，其中以太网帧中源MAC地址填为00:13:02:20:b9:18，目的MAC地址填为ff:ff:ff:ff:ff:ff:ff。\n该DHCPREQUEST消息仍采用广播方式发送，选项中的服务器标识符字段用于避免其他DHCP服务器提交地址绑定。\nDHCPACK 当选中的DHCP服务器接收到DHCPREQUEST消息并同意绑定，它会使用一个DHCPACK消息来响应。\nDHCPACK消息与之前的DHCPOFFER消息非常相似。\n该DHCP消息被封装在UDP用户数据报中，其中UDP头部中源端口号填写为67，目的端口号填写为68；\n然后该UDP用户数据报被封装到IP数据报中，其中IP头部中的源IP地址填写为10.0.0.1，目的IP地址填写为广播地址255.255.255.255；\n然后该IP数据报被封装到以太网帧中，其中以太网帧中源MAC地址填为00:04:5a:9f:9e:80，目的MAC地址填为ff:ff:ff:ff:ff:ff:ff。\n检测冲突 至此，小明的笔记本电脑已获得了IP地址10.0.0.57。但是在使用这个IP地址之前，为了避免该IP地址已被其他主机使用，还要进行冲突检测。冲突检测有两种方法：免费ARP和ACD。\n免费ARP DHCP客户端（小明的笔记本）会向网络中发送一条用于IP地址冲突检测的ARP请求消息，称为免费ARP。\n该ARP消息中：\n源IP地址和目标IP地址都是客户机自己的IP地址（10.0.0.57）；\n源MAC地址为DHCP客户端的MAC地址（00:13:02:20:b9:18）；\n目标MAC地址为广播地址（ff:ff:ff:ff:ff:ff）。\n我们不希望这个ARP请求得到回应，因为是自己请求解析自己，如果网络上没有一个相同的自己（冒牌货，实际上就是地址冲突），那么这个ARP请求永远不可能得到回应；如果有主机回应了这个ARP请求，就表示网络上有两台主机正在使用相同的IP地址，即发生IP冲突。此时，DHCP客户端不会使用该IP地址（10.0.0.57），并会给DHCP服务器发送一个DHCPDECLINE的消息，通知该地址不可使用。\nACD ACD即IPv4地址冲突检测，相较于免费ARP，ACD是一种更先进的IP冲突检测方法。\nACD定义了ARP探测分组和ARP通告分组。\n在获得候选IP地址10.0.0.57后，小明的笔记本发送一个ARP探测分组，用于查看候选IP地址是否被其他主机所使用。\nARP探测分组是一个ARP请求分组，其消息格式中：\n源IP地址填为0.0.0.0（避免候选IP地址被另一台主机使用时的缓存污染）；\n源MAC地址为小明笔记本的MAC地址（00:13:02:20:b9:18）；\n目的IP地址为候选IP地址（10.0.0.57）；\n目的MAC地址为广播地址（ff:ff:ff:ff:ff:ff）。\n该ARP探测分组封装到以太网帧中，通过广播地址向网络中的所有主机发送，相当于小明的笔记本向网络中的主机发问“谁有IP地址10.0.0.57对应的MAC地址啊？有的话告诉我！”。\n在发送ARP探测分组时，小明的笔记本可能接收到ARP应答或请求。如果收到了ARP探测分组对应的ARP应答，说明候选IP地址已经被其他主机占用了；如果收到了其他主机发送的ARP探测请求，且其目的IP地址中包含相同的候选地址，表明存在其他主机也正在尝试获得候选IP地址。在这两种情况下，系统会显示地址冲突，并尝试其他可选IP地址。\n如果小明的笔记本没有发现冲突，它会发送ARP通告分组，以表明它现在使用这个候选IP地址。\nARP通告分组中：\n源IP地址填为10.0.0.57；\n源MAC地址为小明笔记本的MAC地址（00:13:02:20:b9:18）；\n目的IP地址为候选IP地址（10.0.0.57）；\n目的MAC地址为广播地址（ff:ff:ff:ff:ff:ff）。\nACD是一个持续的过程，当小明的笔记本通告它正使用的IP地址后，它会继续检查收到的ARP请求或应答，查看自己的IP地址是否出现在这些ARP消息的源IP地址字段中，如果是，说明其他主机与自己在使用相同的地址，然后采取进一步措施，或放弃IP或保留IP并防御，当然也可能不理会冲突。\nDHCP状态机 下面附上DHCP客户机的状态机。\n虚线和INIT状态表示协议开始。\n租用时间（T）：在不更新租约的情况下地址可被租用的时间上限。\n更新时间（T1）：客户机从获得租约到尝试要求服务器更新租约的时间。\n重新绑定时间（T2）：客户机尝试要求DHCP服务器更新其地址的时间。\n在默认情况下，T1=T/2，T2=7T/8。\n","date":"2021-05-05T00:37:38-07:00","permalink":"https://bitdove.github.io/posts/dhcp-protocol/","title":"【一文读懂】DHCP协议"}]